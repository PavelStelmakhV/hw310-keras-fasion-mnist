{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmdM5D9MBhmCzxn3UhKMcx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavelStelmakhV/hw310-keras-fasion-mnist/blob/main/keras_fasion_mnist_hw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQL6wYJUms6Y",
        "outputId": "374862e1-dc8c-4bd4-9dac-caadc4902cb7"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 12941722264357940721\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "vv7w0bgAVQPO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tf_keras\n",
        "\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import regularizers\n",
        "from keras import callbacks\n",
        "from keras import initializers\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10"
      ],
      "metadata": {
        "id": "RvT1uYJsa5cn"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "mOpywsNAzfGB"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drow_hist(data):\n",
        "  plt.figure(figsize=(8,6), dpi= 80)\n",
        "  _ = plt.hist(data,\n",
        "              bins=num_classes,\n",
        "              stacked=True,\n",
        "              density=False,\n",
        "              range=(0,10),\n",
        "              rwidth=0.9,\n",
        "              )"
      ],
      "metadata": {
        "id": "NjEvuOvomEoT"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create validation data\n",
        "val_size = 6600\n",
        "\n",
        "x_val = x_train[-val_size:, :, :]\n",
        "x_train = x_train[:-val_size, :, :]\n",
        "\n",
        "y_val = y_train[-val_size:]\n",
        "y_train = y_train[:-val_size]"
      ],
      "metadata": {
        "id": "jAs92sDoVU89"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mirror train image\n",
        "# x_train_add = np.rot90(x_train, k=1, axes=(1,2))\n",
        "# x_train_add = np.transpose(x_train_add, (0, 2, 1))"
      ],
      "metadata": {
        "id": "UHNuw-3D_v7x"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train_add = y_train.copy()"
      ],
      "metadata": {
        "id": "TNDXV8RfZbt1"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # remove boots image from addition data [5, 7, 9]\n",
        "# for i in [5, 7, 9]:\n",
        "#     index = np.where(y_train_add == i )\n",
        "#     x_train_add = np.delete(x_train_add, index , axis=0)\n",
        "#     y_train_add = np.delete(y_train_add, index , axis=0)"
      ],
      "metadata": {
        "id": "506yp4e5UqKp"
      },
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train_add.shape"
      ],
      "metadata": {
        "id": "WB-PVgBb116E"
      },
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train_add.shape"
      ],
      "metadata": {
        "id": "MjteIWwr2V-N"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train = np.concatenate([\n",
        "#     x_train,\n",
        "#     x_train_add[:10000:, :, :]\n",
        "# ])"
      ],
      "metadata": {
        "id": "C25g0-L5PuhV"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train = np.concatenate([\n",
        "#     y_train,\n",
        "#     y_train_add[:10000]\n",
        "# ])"
      ],
      "metadata": {
        "id": "JiyI9CE-RWnR"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drow_hist(y_train)"
      ],
      "metadata": {
        "id": "j0FZ4_7DpRVw"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure()\n",
        "# plt.imshow(x_train[7])\n",
        "# plt.colorbar()\n",
        "# plt.grid(False)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "mq_QalIABCeU"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure()\n",
        "# plt.imshow(x_train_add[0])\n",
        "# plt.colorbar()\n",
        "# plt.grid(False)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "CDLNL7Zw3HEc"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "x_val = x_val.astype('float32') / 255\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_val = to_categorical(y_val)"
      ],
      "metadata": {
        "id": "t2gucjsJ0KUi"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "#                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# plt.figure(figsize=(10,10))\n",
        "# for i in range(25):\n",
        "#     plt.subplot(5,5,i+1)\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "#     plt.grid(False)\n",
        "#     plt.imshow(x_train[i+50000], cmap=plt.cm.binary)\n",
        "#     plt.xlabel(class_names[int(y_train[i+50000])])\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "h4LveKxM4hyC"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize=(10,10))\n",
        "# for i in range(25):\n",
        "#     plt.subplot(5,5,i+1)\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "#     plt.grid(False)\n",
        "#     plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "#     plt.xlabel(class_names[int(y_train[i])])\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "hljEDYd55d8Q"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_init_tanh = initializers.glorot_normal(seed=111)\n",
        "w_init_relu = initializers.HeNormal(seed=66)\n",
        "# w_init_relu = initializers.HeUniform(seed=24)\n",
        "b_init = initializers.Zeros()"
      ],
      "metadata": {
        "id": "yL9QTEtBGy4N"
      },
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def layer_relu(model, neurons, drop_out):\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(layers.Dense(neurons,\n",
        "                       activation='relu',\n",
        "                       kernel_initializer=w_init_relu,\n",
        "                       bias_initializer=b_init))\n",
        "  model.add(layers.Dropout(drop_out))\n",
        "  print(drop_out)\n",
        "  return model"
      ],
      "metadata": {
        "id": "ZZgs_25rKBCp"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def layer_tanh(model, neurons, drop_out):\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(layers.Dense(neurons,\n",
        "                        activation='tanh',\n",
        "                        kernel_initializer=w_init_tanh,\n",
        "                        bias_initializer=b_init))\n",
        "  model.add(layers.Dropout(drop_out))\n",
        "  return model"
      ],
      "metadata": {
        "id": "90JLLnkBR50t"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "neurons = 256\n",
        "drop_out = 0.5\n",
        "\n",
        "model.add(layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(layers.Dropout(0.1))\n",
        "\n",
        "model = layer_relu(model, neurons*1, drop_out)\n",
        "model = layer_tanh(model, neurons*2, drop_out)\n",
        "model = layer_relu(model, neurons*2, drop_out)\n",
        "# model = layer_relu(model, neurons*2)\n",
        "\n",
        "\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "atS39i4d0aqW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2635ea6e-63d7-4fbe-fff0-8859240169d7"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "tZO7hl7pM63y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.0004,\n",
        "                                      beta_1=0.9,\n",
        "                                      beta_2=0.999,\n",
        "                                      epsilon=1e-06\n",
        ")\n",
        "# optimizer = tf.keras.optimizers.experimental.RMSprop(learning_rate=0.0005,\n",
        "#                                                     rho=0.5,\n",
        "#                                                     momentum=-16,\n",
        "#                                                     epsilon=1e-07,\n",
        "#                                                     centered=False,\n",
        "#                                                     weight_decay=None,\n",
        "#                                                     clipnorm=None,\n",
        "#                                                     clipvalue=None,\n",
        "#                                                     global_clipnorm=None,\n",
        "#                                                     use_ema=False,\n",
        "#                                                     ema_momentum=0.99,\n",
        "#                                                     ema_overwrite_frequency=100,\n",
        "#                                                     jit_compile=True,\n",
        "#                                                     name='RMSprop',\n",
        "# )"
      ],
      "metadata": {
        "id": "EzfnaqIZlfy8"
      },
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "KHmBptvOM95Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(#optimizer='adam',\n",
        "              # optimizer='adamax',\n",
        "              optimizer=optimizer,\n",
        "              # optimizer='rmsprop',\n",
        "              # optimizer='sgd',\n",
        "              # optimizer='adadelta',\n",
        "              # loss='binary_crossentropy',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['categorical_accuracy']) # sparse_categorical_accuracy"
      ],
      "metadata": {
        "id": "hENVaAC7ilNY"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# callback = callbacks.EarlyStopping(monitor='val_loss',\n",
        "#                                    patience=15,\n",
        "#                                    restore_best_weights=True,\n",
        "#                                    )\n",
        "es = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=60)\n",
        "mc = callbacks.ModelCheckpoint('best_model.h5', monitor='categorical_accuracy', mode='max', verbose=0, save_best_only=True)\n"
      ],
      "metadata": {
        "id": "5ihU4exVlsjm"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=1000,\n",
        "                    batch_size=128,\n",
        "                    # callbacks=[callback],\n",
        "                    callbacks=[mc, es],\n",
        "                    verbose=1, #многословие\n",
        "                    # validation_split=0.2\n",
        "                    validation_data=(x_val, y_val)\n",
        "                    )\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "FH8HcMNm233I",
        "outputId": "246603dd-1190-4032-fa09-287e440ef836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "418/418 [==============================] - 16s 30ms/step - loss: 1.0555 - categorical_accuracy: 0.6583 - val_loss: 0.4948 - val_categorical_accuracy: 0.8218\n",
            "Epoch 2/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.6577 - categorical_accuracy: 0.7718 - val_loss: 0.4425 - val_categorical_accuracy: 0.8377\n",
            "Epoch 3/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.5658 - categorical_accuracy: 0.7984 - val_loss: 0.4117 - val_categorical_accuracy: 0.8482\n",
            "Epoch 4/1000\n",
            "418/418 [==============================] - 11s 27ms/step - loss: 0.5127 - categorical_accuracy: 0.8141 - val_loss: 0.3994 - val_categorical_accuracy: 0.8511\n",
            "Epoch 5/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.4813 - categorical_accuracy: 0.8247 - val_loss: 0.3827 - val_categorical_accuracy: 0.8608\n",
            "Epoch 6/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.4574 - categorical_accuracy: 0.8333 - val_loss: 0.3654 - val_categorical_accuracy: 0.8659\n",
            "Epoch 7/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.4410 - categorical_accuracy: 0.8394 - val_loss: 0.3556 - val_categorical_accuracy: 0.8674\n",
            "Epoch 8/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.4257 - categorical_accuracy: 0.8453 - val_loss: 0.3518 - val_categorical_accuracy: 0.8677\n",
            "Epoch 9/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.4144 - categorical_accuracy: 0.8475 - val_loss: 0.3453 - val_categorical_accuracy: 0.8708\n",
            "Epoch 10/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.4048 - categorical_accuracy: 0.8513 - val_loss: 0.3330 - val_categorical_accuracy: 0.8785\n",
            "Epoch 11/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3937 - categorical_accuracy: 0.8556 - val_loss: 0.3351 - val_categorical_accuracy: 0.8805\n",
            "Epoch 12/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.3863 - categorical_accuracy: 0.8584 - val_loss: 0.3243 - val_categorical_accuracy: 0.8800\n",
            "Epoch 13/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3795 - categorical_accuracy: 0.8609 - val_loss: 0.3263 - val_categorical_accuracy: 0.8789\n",
            "Epoch 14/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.3789 - categorical_accuracy: 0.8621 - val_loss: 0.3172 - val_categorical_accuracy: 0.8818\n",
            "Epoch 15/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3715 - categorical_accuracy: 0.8627 - val_loss: 0.3141 - val_categorical_accuracy: 0.8839\n",
            "Epoch 16/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3618 - categorical_accuracy: 0.8669 - val_loss: 0.3090 - val_categorical_accuracy: 0.8852\n",
            "Epoch 17/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.3612 - categorical_accuracy: 0.8653 - val_loss: 0.3169 - val_categorical_accuracy: 0.8842\n",
            "Epoch 18/1000\n",
            "418/418 [==============================] - 11s 26ms/step - loss: 0.3549 - categorical_accuracy: 0.8699 - val_loss: 0.3089 - val_categorical_accuracy: 0.8877\n",
            "Epoch 19/1000\n",
            "418/418 [==============================] - 11s 27ms/step - loss: 0.3477 - categorical_accuracy: 0.8709 - val_loss: 0.3065 - val_categorical_accuracy: 0.8862\n",
            "Epoch 20/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.3493 - categorical_accuracy: 0.8719 - val_loss: 0.3048 - val_categorical_accuracy: 0.8880\n",
            "Epoch 21/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.3460 - categorical_accuracy: 0.8726 - val_loss: 0.3045 - val_categorical_accuracy: 0.8886\n",
            "Epoch 22/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3384 - categorical_accuracy: 0.8750 - val_loss: 0.3050 - val_categorical_accuracy: 0.8877\n",
            "Epoch 23/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.3356 - categorical_accuracy: 0.8737 - val_loss: 0.2994 - val_categorical_accuracy: 0.8889\n",
            "Epoch 24/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3325 - categorical_accuracy: 0.8766 - val_loss: 0.3001 - val_categorical_accuracy: 0.8914\n",
            "Epoch 25/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.3309 - categorical_accuracy: 0.8777 - val_loss: 0.2986 - val_categorical_accuracy: 0.8885\n",
            "Epoch 26/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3265 - categorical_accuracy: 0.8788 - val_loss: 0.2962 - val_categorical_accuracy: 0.8915\n",
            "Epoch 27/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3269 - categorical_accuracy: 0.8783 - val_loss: 0.3003 - val_categorical_accuracy: 0.8885\n",
            "Epoch 28/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3246 - categorical_accuracy: 0.8794 - val_loss: 0.2971 - val_categorical_accuracy: 0.8888\n",
            "Epoch 29/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3205 - categorical_accuracy: 0.8814 - val_loss: 0.2983 - val_categorical_accuracy: 0.8942\n",
            "Epoch 30/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.3210 - categorical_accuracy: 0.8809 - val_loss: 0.2937 - val_categorical_accuracy: 0.8920\n",
            "Epoch 31/1000\n",
            "418/418 [==============================] - 11s 27ms/step - loss: 0.3192 - categorical_accuracy: 0.8826 - val_loss: 0.2966 - val_categorical_accuracy: 0.8941\n",
            "Epoch 32/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.3156 - categorical_accuracy: 0.8835 - val_loss: 0.2964 - val_categorical_accuracy: 0.8930\n",
            "Epoch 33/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3136 - categorical_accuracy: 0.8836 - val_loss: 0.2885 - val_categorical_accuracy: 0.8956\n",
            "Epoch 34/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.3130 - categorical_accuracy: 0.8831 - val_loss: 0.2885 - val_categorical_accuracy: 0.8945\n",
            "Epoch 35/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.3124 - categorical_accuracy: 0.8840 - val_loss: 0.2884 - val_categorical_accuracy: 0.8959\n",
            "Epoch 36/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3100 - categorical_accuracy: 0.8852 - val_loss: 0.2912 - val_categorical_accuracy: 0.8938\n",
            "Epoch 37/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3047 - categorical_accuracy: 0.8861 - val_loss: 0.2914 - val_categorical_accuracy: 0.8945\n",
            "Epoch 38/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3073 - categorical_accuracy: 0.8849 - val_loss: 0.2859 - val_categorical_accuracy: 0.8961\n",
            "Epoch 39/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.3033 - categorical_accuracy: 0.8872 - val_loss: 0.2909 - val_categorical_accuracy: 0.8976\n",
            "Epoch 40/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3037 - categorical_accuracy: 0.8868 - val_loss: 0.2843 - val_categorical_accuracy: 0.8948\n",
            "Epoch 41/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.3026 - categorical_accuracy: 0.8876 - val_loss: 0.2867 - val_categorical_accuracy: 0.8950\n",
            "Epoch 42/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2977 - categorical_accuracy: 0.8877 - val_loss: 0.2876 - val_categorical_accuracy: 0.8995\n",
            "Epoch 43/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2989 - categorical_accuracy: 0.8887 - val_loss: 0.2875 - val_categorical_accuracy: 0.8962\n",
            "Epoch 44/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2947 - categorical_accuracy: 0.8902 - val_loss: 0.2845 - val_categorical_accuracy: 0.8985\n",
            "Epoch 45/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2924 - categorical_accuracy: 0.8914 - val_loss: 0.2861 - val_categorical_accuracy: 0.8958\n",
            "Epoch 46/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2951 - categorical_accuracy: 0.8899 - val_loss: 0.2820 - val_categorical_accuracy: 0.9000\n",
            "Epoch 47/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2923 - categorical_accuracy: 0.8910 - val_loss: 0.2877 - val_categorical_accuracy: 0.8962\n",
            "Epoch 48/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2947 - categorical_accuracy: 0.8897 - val_loss: 0.2777 - val_categorical_accuracy: 0.8985\n",
            "Epoch 49/1000\n",
            "418/418 [==============================] - 11s 27ms/step - loss: 0.2931 - categorical_accuracy: 0.8919 - val_loss: 0.2782 - val_categorical_accuracy: 0.9003\n",
            "Epoch 50/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2876 - categorical_accuracy: 0.8930 - val_loss: 0.2815 - val_categorical_accuracy: 0.8985\n",
            "Epoch 51/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2909 - categorical_accuracy: 0.8919 - val_loss: 0.2821 - val_categorical_accuracy: 0.8973\n",
            "Epoch 52/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2877 - categorical_accuracy: 0.8938 - val_loss: 0.2815 - val_categorical_accuracy: 0.9020\n",
            "Epoch 53/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2899 - categorical_accuracy: 0.8933 - val_loss: 0.2826 - val_categorical_accuracy: 0.8977\n",
            "Epoch 54/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2817 - categorical_accuracy: 0.8952 - val_loss: 0.2797 - val_categorical_accuracy: 0.9009\n",
            "Epoch 55/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2858 - categorical_accuracy: 0.8917 - val_loss: 0.2809 - val_categorical_accuracy: 0.9009\n",
            "Epoch 56/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2863 - categorical_accuracy: 0.8931 - val_loss: 0.2786 - val_categorical_accuracy: 0.8985\n",
            "Epoch 57/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2814 - categorical_accuracy: 0.8940 - val_loss: 0.2796 - val_categorical_accuracy: 0.8983\n",
            "Epoch 58/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2823 - categorical_accuracy: 0.8939 - val_loss: 0.2777 - val_categorical_accuracy: 0.9006\n",
            "Epoch 59/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2767 - categorical_accuracy: 0.8981 - val_loss: 0.2778 - val_categorical_accuracy: 0.9003\n",
            "Epoch 60/1000\n",
            "418/418 [==============================] - 13s 31ms/step - loss: 0.2798 - categorical_accuracy: 0.8966 - val_loss: 0.2794 - val_categorical_accuracy: 0.9003\n",
            "Epoch 61/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2773 - categorical_accuracy: 0.8963 - val_loss: 0.2798 - val_categorical_accuracy: 0.9020\n",
            "Epoch 62/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2792 - categorical_accuracy: 0.8961 - val_loss: 0.2747 - val_categorical_accuracy: 0.9003\n",
            "Epoch 63/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2789 - categorical_accuracy: 0.8964 - val_loss: 0.2786 - val_categorical_accuracy: 0.8992\n",
            "Epoch 64/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2748 - categorical_accuracy: 0.8957 - val_loss: 0.2794 - val_categorical_accuracy: 0.8992\n",
            "Epoch 65/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2770 - categorical_accuracy: 0.8987 - val_loss: 0.2763 - val_categorical_accuracy: 0.9009\n",
            "Epoch 66/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2765 - categorical_accuracy: 0.8963 - val_loss: 0.2764 - val_categorical_accuracy: 0.9006\n",
            "Epoch 67/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2733 - categorical_accuracy: 0.8974 - val_loss: 0.2766 - val_categorical_accuracy: 0.9036\n",
            "Epoch 68/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2763 - categorical_accuracy: 0.8982 - val_loss: 0.2755 - val_categorical_accuracy: 0.9015\n",
            "Epoch 69/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2705 - categorical_accuracy: 0.8992 - val_loss: 0.2782 - val_categorical_accuracy: 0.9012\n",
            "Epoch 70/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2698 - categorical_accuracy: 0.9004 - val_loss: 0.2766 - val_categorical_accuracy: 0.9021\n",
            "Epoch 71/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2730 - categorical_accuracy: 0.8985 - val_loss: 0.2731 - val_categorical_accuracy: 0.9014\n",
            "Epoch 72/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2738 - categorical_accuracy: 0.8995 - val_loss: 0.2787 - val_categorical_accuracy: 0.9017\n",
            "Epoch 73/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2725 - categorical_accuracy: 0.8992 - val_loss: 0.2833 - val_categorical_accuracy: 0.8992\n",
            "Epoch 74/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2686 - categorical_accuracy: 0.9014 - val_loss: 0.2762 - val_categorical_accuracy: 0.9014\n",
            "Epoch 75/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2660 - categorical_accuracy: 0.9018 - val_loss: 0.2777 - val_categorical_accuracy: 0.9050\n",
            "Epoch 76/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2675 - categorical_accuracy: 0.9002 - val_loss: 0.2791 - val_categorical_accuracy: 0.9027\n",
            "Epoch 77/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2665 - categorical_accuracy: 0.8994 - val_loss: 0.2694 - val_categorical_accuracy: 0.9045\n",
            "Epoch 78/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2677 - categorical_accuracy: 0.9012 - val_loss: 0.2762 - val_categorical_accuracy: 0.9008\n",
            "Epoch 79/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2674 - categorical_accuracy: 0.9011 - val_loss: 0.2752 - val_categorical_accuracy: 0.9030\n",
            "Epoch 80/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2679 - categorical_accuracy: 0.9006 - val_loss: 0.2755 - val_categorical_accuracy: 0.9012\n",
            "Epoch 81/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2608 - categorical_accuracy: 0.9031 - val_loss: 0.2753 - val_categorical_accuracy: 0.9026\n",
            "Epoch 82/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2640 - categorical_accuracy: 0.9031 - val_loss: 0.2766 - val_categorical_accuracy: 0.9020\n",
            "Epoch 83/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2637 - categorical_accuracy: 0.9028 - val_loss: 0.2780 - val_categorical_accuracy: 0.9030\n",
            "Epoch 84/1000\n",
            "418/418 [==============================] - 11s 27ms/step - loss: 0.2667 - categorical_accuracy: 0.9016 - val_loss: 0.2738 - val_categorical_accuracy: 0.9006\n",
            "Epoch 85/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2626 - categorical_accuracy: 0.9014 - val_loss: 0.2721 - val_categorical_accuracy: 0.9047\n",
            "Epoch 86/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2621 - categorical_accuracy: 0.9027 - val_loss: 0.2764 - val_categorical_accuracy: 0.9021\n",
            "Epoch 87/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2619 - categorical_accuracy: 0.9030 - val_loss: 0.2785 - val_categorical_accuracy: 0.9038\n",
            "Epoch 88/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2624 - categorical_accuracy: 0.9026 - val_loss: 0.2723 - val_categorical_accuracy: 0.9035\n",
            "Epoch 89/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2623 - categorical_accuracy: 0.9026 - val_loss: 0.2711 - val_categorical_accuracy: 0.9024\n",
            "Epoch 90/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2617 - categorical_accuracy: 0.9024 - val_loss: 0.2706 - val_categorical_accuracy: 0.9048\n",
            "Epoch 91/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2583 - categorical_accuracy: 0.9027 - val_loss: 0.2762 - val_categorical_accuracy: 0.9041\n",
            "Epoch 92/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2612 - categorical_accuracy: 0.9025 - val_loss: 0.2711 - val_categorical_accuracy: 0.9024\n",
            "Epoch 93/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2585 - categorical_accuracy: 0.9037 - val_loss: 0.2766 - val_categorical_accuracy: 0.9026\n",
            "Epoch 94/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2584 - categorical_accuracy: 0.9032 - val_loss: 0.2734 - val_categorical_accuracy: 0.9026\n",
            "Epoch 95/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2560 - categorical_accuracy: 0.9046 - val_loss: 0.2717 - val_categorical_accuracy: 0.9021\n",
            "Epoch 96/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2576 - categorical_accuracy: 0.9046 - val_loss: 0.2797 - val_categorical_accuracy: 0.9024\n",
            "Epoch 97/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2529 - categorical_accuracy: 0.9050 - val_loss: 0.2737 - val_categorical_accuracy: 0.9033\n",
            "Epoch 98/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2601 - categorical_accuracy: 0.9026 - val_loss: 0.2741 - val_categorical_accuracy: 0.9023\n",
            "Epoch 99/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2541 - categorical_accuracy: 0.9059 - val_loss: 0.2719 - val_categorical_accuracy: 0.9035\n",
            "Epoch 100/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2531 - categorical_accuracy: 0.9051 - val_loss: 0.2764 - val_categorical_accuracy: 0.9026\n",
            "Epoch 101/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2576 - categorical_accuracy: 0.9043 - val_loss: 0.2745 - val_categorical_accuracy: 0.9018\n",
            "Epoch 102/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2525 - categorical_accuracy: 0.9060 - val_loss: 0.2741 - val_categorical_accuracy: 0.9032\n",
            "Epoch 103/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2570 - categorical_accuracy: 0.9045 - val_loss: 0.2660 - val_categorical_accuracy: 0.9070\n",
            "Epoch 104/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2546 - categorical_accuracy: 0.9054 - val_loss: 0.2779 - val_categorical_accuracy: 0.9041\n",
            "Epoch 105/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2561 - categorical_accuracy: 0.9040 - val_loss: 0.2729 - val_categorical_accuracy: 0.9045\n",
            "Epoch 106/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2547 - categorical_accuracy: 0.9039 - val_loss: 0.2681 - val_categorical_accuracy: 0.9035\n",
            "Epoch 107/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2530 - categorical_accuracy: 0.9070 - val_loss: 0.2731 - val_categorical_accuracy: 0.9045\n",
            "Epoch 108/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2534 - categorical_accuracy: 0.9065 - val_loss: 0.2772 - val_categorical_accuracy: 0.9020\n",
            "Epoch 109/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2494 - categorical_accuracy: 0.9074 - val_loss: 0.2764 - val_categorical_accuracy: 0.9027\n",
            "Epoch 110/1000\n",
            "418/418 [==============================] - 13s 31ms/step - loss: 0.2488 - categorical_accuracy: 0.9082 - val_loss: 0.2754 - val_categorical_accuracy: 0.9027\n",
            "Epoch 111/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2519 - categorical_accuracy: 0.9064 - val_loss: 0.2746 - val_categorical_accuracy: 0.9015\n",
            "Epoch 112/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2504 - categorical_accuracy: 0.9061 - val_loss: 0.2742 - val_categorical_accuracy: 0.9029\n",
            "Epoch 113/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2533 - categorical_accuracy: 0.9060 - val_loss: 0.2763 - val_categorical_accuracy: 0.9033\n",
            "Epoch 114/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2512 - categorical_accuracy: 0.9069 - val_loss: 0.2719 - val_categorical_accuracy: 0.9038\n",
            "Epoch 115/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2518 - categorical_accuracy: 0.9072 - val_loss: 0.2729 - val_categorical_accuracy: 0.9052\n",
            "Epoch 116/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2478 - categorical_accuracy: 0.9071 - val_loss: 0.2755 - val_categorical_accuracy: 0.9042\n",
            "Epoch 117/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2475 - categorical_accuracy: 0.9072 - val_loss: 0.2702 - val_categorical_accuracy: 0.9039\n",
            "Epoch 118/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2451 - categorical_accuracy: 0.9086 - val_loss: 0.2742 - val_categorical_accuracy: 0.9042\n",
            "Epoch 119/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2451 - categorical_accuracy: 0.9087 - val_loss: 0.2719 - val_categorical_accuracy: 0.9023\n",
            "Epoch 120/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2499 - categorical_accuracy: 0.9071 - val_loss: 0.2799 - val_categorical_accuracy: 0.8992\n",
            "Epoch 121/1000\n",
            "418/418 [==============================] - 11s 27ms/step - loss: 0.2507 - categorical_accuracy: 0.9071 - val_loss: 0.2693 - val_categorical_accuracy: 0.9058\n",
            "Epoch 122/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2455 - categorical_accuracy: 0.9078 - val_loss: 0.2709 - val_categorical_accuracy: 0.9050\n",
            "Epoch 123/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2461 - categorical_accuracy: 0.9088 - val_loss: 0.2733 - val_categorical_accuracy: 0.9041\n",
            "Epoch 124/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2441 - categorical_accuracy: 0.9093 - val_loss: 0.2740 - val_categorical_accuracy: 0.9058\n",
            "Epoch 125/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2487 - categorical_accuracy: 0.9069 - val_loss: 0.2707 - val_categorical_accuracy: 0.9033\n",
            "Epoch 126/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2440 - categorical_accuracy: 0.9075 - val_loss: 0.2815 - val_categorical_accuracy: 0.9033\n",
            "Epoch 127/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2484 - categorical_accuracy: 0.9081 - val_loss: 0.2721 - val_categorical_accuracy: 0.9036\n",
            "Epoch 128/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2429 - categorical_accuracy: 0.9107 - val_loss: 0.2734 - val_categorical_accuracy: 0.9068\n",
            "Epoch 129/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2430 - categorical_accuracy: 0.9100 - val_loss: 0.2802 - val_categorical_accuracy: 0.9027\n",
            "Epoch 130/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2443 - categorical_accuracy: 0.9090 - val_loss: 0.2758 - val_categorical_accuracy: 0.9064\n",
            "Epoch 131/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2439 - categorical_accuracy: 0.9093 - val_loss: 0.2793 - val_categorical_accuracy: 0.9036\n",
            "Epoch 132/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2444 - categorical_accuracy: 0.9085 - val_loss: 0.2812 - val_categorical_accuracy: 0.9008\n",
            "Epoch 133/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2438 - categorical_accuracy: 0.9106 - val_loss: 0.2807 - val_categorical_accuracy: 0.9035\n",
            "Epoch 134/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2388 - categorical_accuracy: 0.9104 - val_loss: 0.2799 - val_categorical_accuracy: 0.9015\n",
            "Epoch 135/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2414 - categorical_accuracy: 0.9097 - val_loss: 0.2769 - val_categorical_accuracy: 0.9026\n",
            "Epoch 136/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2424 - categorical_accuracy: 0.9089 - val_loss: 0.2741 - val_categorical_accuracy: 0.9041\n",
            "Epoch 137/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2432 - categorical_accuracy: 0.9085 - val_loss: 0.2726 - val_categorical_accuracy: 0.9029\n",
            "Epoch 138/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2433 - categorical_accuracy: 0.9095 - val_loss: 0.2768 - val_categorical_accuracy: 0.9030\n",
            "Epoch 139/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2407 - categorical_accuracy: 0.9103 - val_loss: 0.2685 - val_categorical_accuracy: 0.9050\n",
            "Epoch 140/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2422 - categorical_accuracy: 0.9096 - val_loss: 0.2694 - val_categorical_accuracy: 0.9047\n",
            "Epoch 141/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2436 - categorical_accuracy: 0.9087 - val_loss: 0.2712 - val_categorical_accuracy: 0.9035\n",
            "Epoch 142/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2441 - categorical_accuracy: 0.9097 - val_loss: 0.2669 - val_categorical_accuracy: 0.9042\n",
            "Epoch 143/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2376 - categorical_accuracy: 0.9115 - val_loss: 0.2737 - val_categorical_accuracy: 0.9048\n",
            "Epoch 144/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2399 - categorical_accuracy: 0.9104 - val_loss: 0.2652 - val_categorical_accuracy: 0.9038\n",
            "Epoch 145/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2396 - categorical_accuracy: 0.9098 - val_loss: 0.2740 - val_categorical_accuracy: 0.9056\n",
            "Epoch 146/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2428 - categorical_accuracy: 0.9099 - val_loss: 0.2703 - val_categorical_accuracy: 0.9062\n",
            "Epoch 147/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2399 - categorical_accuracy: 0.9108 - val_loss: 0.2751 - val_categorical_accuracy: 0.9045\n",
            "Epoch 148/1000\n",
            "418/418 [==============================] - 13s 31ms/step - loss: 0.2378 - categorical_accuracy: 0.9130 - val_loss: 0.2700 - val_categorical_accuracy: 0.9041\n",
            "Epoch 149/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2393 - categorical_accuracy: 0.9104 - val_loss: 0.2676 - val_categorical_accuracy: 0.9052\n",
            "Epoch 150/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2363 - categorical_accuracy: 0.9122 - val_loss: 0.2736 - val_categorical_accuracy: 0.9041\n",
            "Epoch 151/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2369 - categorical_accuracy: 0.9111 - val_loss: 0.2650 - val_categorical_accuracy: 0.9065\n",
            "Epoch 152/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2382 - categorical_accuracy: 0.9116 - val_loss: 0.2673 - val_categorical_accuracy: 0.9035\n",
            "Epoch 153/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2398 - categorical_accuracy: 0.9108 - val_loss: 0.2679 - val_categorical_accuracy: 0.9079\n",
            "Epoch 154/1000\n",
            "418/418 [==============================] - 13s 31ms/step - loss: 0.2395 - categorical_accuracy: 0.9104 - val_loss: 0.2676 - val_categorical_accuracy: 0.9050\n",
            "Epoch 155/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2370 - categorical_accuracy: 0.9116 - val_loss: 0.2756 - val_categorical_accuracy: 0.9056\n",
            "Epoch 156/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2350 - categorical_accuracy: 0.9127 - val_loss: 0.2733 - val_categorical_accuracy: 0.9067\n",
            "Epoch 157/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2365 - categorical_accuracy: 0.9116 - val_loss: 0.2706 - val_categorical_accuracy: 0.9052\n",
            "Epoch 158/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2368 - categorical_accuracy: 0.9112 - val_loss: 0.2696 - val_categorical_accuracy: 0.9076\n",
            "Epoch 159/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2364 - categorical_accuracy: 0.9129 - val_loss: 0.2737 - val_categorical_accuracy: 0.9055\n",
            "Epoch 160/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2361 - categorical_accuracy: 0.9120 - val_loss: 0.2686 - val_categorical_accuracy: 0.9067\n",
            "Epoch 161/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2331 - categorical_accuracy: 0.9138 - val_loss: 0.2695 - val_categorical_accuracy: 0.9064\n",
            "Epoch 162/1000\n",
            "418/418 [==============================] - 12s 28ms/step - loss: 0.2360 - categorical_accuracy: 0.9120 - val_loss: 0.2681 - val_categorical_accuracy: 0.9052\n",
            "Epoch 163/1000\n",
            "418/418 [==============================] - 13s 31ms/step - loss: 0.2354 - categorical_accuracy: 0.9121 - val_loss: 0.2676 - val_categorical_accuracy: 0.9041\n",
            "Epoch 164/1000\n",
            "418/418 [==============================] - 13s 31ms/step - loss: 0.2313 - categorical_accuracy: 0.9142 - val_loss: 0.2773 - val_categorical_accuracy: 0.9055\n",
            "Epoch 165/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2336 - categorical_accuracy: 0.9118 - val_loss: 0.2705 - val_categorical_accuracy: 0.9064\n",
            "Epoch 166/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2321 - categorical_accuracy: 0.9127 - val_loss: 0.2757 - val_categorical_accuracy: 0.9050\n",
            "Epoch 167/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2357 - categorical_accuracy: 0.9124 - val_loss: 0.2707 - val_categorical_accuracy: 0.9064\n",
            "Epoch 168/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2316 - categorical_accuracy: 0.9144 - val_loss: 0.2719 - val_categorical_accuracy: 0.9061\n",
            "Epoch 169/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2338 - categorical_accuracy: 0.9143 - val_loss: 0.2706 - val_categorical_accuracy: 0.9055\n",
            "Epoch 170/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2373 - categorical_accuracy: 0.9117 - val_loss: 0.2672 - val_categorical_accuracy: 0.9058\n",
            "Epoch 171/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2343 - categorical_accuracy: 0.9128 - val_loss: 0.2718 - val_categorical_accuracy: 0.9048\n",
            "Epoch 172/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2335 - categorical_accuracy: 0.9119 - val_loss: 0.2733 - val_categorical_accuracy: 0.9047\n",
            "Epoch 173/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2325 - categorical_accuracy: 0.9125 - val_loss: 0.2708 - val_categorical_accuracy: 0.9039\n",
            "Epoch 174/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2340 - categorical_accuracy: 0.9133 - val_loss: 0.2734 - val_categorical_accuracy: 0.9047\n",
            "Epoch 175/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2314 - categorical_accuracy: 0.9135 - val_loss: 0.2712 - val_categorical_accuracy: 0.9070\n",
            "Epoch 176/1000\n",
            "418/418 [==============================] - 11s 27ms/step - loss: 0.2304 - categorical_accuracy: 0.9161 - val_loss: 0.2725 - val_categorical_accuracy: 0.9056\n",
            "Epoch 177/1000\n",
            "418/418 [==============================] - 11s 27ms/step - loss: 0.2285 - categorical_accuracy: 0.9143 - val_loss: 0.2737 - val_categorical_accuracy: 0.9035\n",
            "Epoch 178/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2310 - categorical_accuracy: 0.9137 - val_loss: 0.2686 - val_categorical_accuracy: 0.9062\n",
            "Epoch 179/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2311 - categorical_accuracy: 0.9156 - val_loss: 0.2707 - val_categorical_accuracy: 0.9056\n",
            "Epoch 180/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2299 - categorical_accuracy: 0.9156 - val_loss: 0.2715 - val_categorical_accuracy: 0.9071\n",
            "Epoch 181/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2328 - categorical_accuracy: 0.9130 - val_loss: 0.2718 - val_categorical_accuracy: 0.9073\n",
            "Epoch 182/1000\n",
            "418/418 [==============================] - 13s 30ms/step - loss: 0.2325 - categorical_accuracy: 0.9124 - val_loss: 0.2653 - val_categorical_accuracy: 0.9077\n",
            "Epoch 183/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2304 - categorical_accuracy: 0.9128 - val_loss: 0.2683 - val_categorical_accuracy: 0.9076\n",
            "Epoch 184/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2310 - categorical_accuracy: 0.9138 - val_loss: 0.2733 - val_categorical_accuracy: 0.9068\n",
            "Epoch 185/1000\n",
            "418/418 [==============================] - 12s 29ms/step - loss: 0.2290 - categorical_accuracy: 0.9142 - val_loss: 0.2743 - val_categorical_accuracy: 0.9050\n",
            "Epoch 186/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2301 - categorical_accuracy: 0.9130 - val_loss: 0.2771 - val_categorical_accuracy: 0.9061\n",
            "Epoch 187/1000\n",
            "418/418 [==============================] - 12s 30ms/step - loss: 0.2301 - categorical_accuracy: 0.9143 - val_loss: 0.2720 - val_categorical_accuracy: 0.9045\n",
            "Epoch 188/1000\n",
            "370/418 [=========================>....] - ETA: 1s - loss: 0.2336 - categorical_accuracy: 0.9141"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nhistory dict:', list(history.history.keys()))"
      ],
      "metadata": {
        "id": "CxRE-B_Q6Sii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.evaluate(x_test, y_test)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "YXpwRRTvTBNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = load_model('best_model.h5')\n",
        "result = saved_model.evaluate(x_test, y_test)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "dpaZAW0vp1AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.models import load_model\n",
        "# saved_model = load_model('best_model.h5')\n",
        "# # _, train_acc = saved_model.evaluate(x_train, y_train, verbose=0)\n",
        "# _, test_acc = saved_model.evaluate(x_test, y_test, verbose=0)\n",
        "# print('Test: %.3f' % (test_acc))"
      ],
      "metadata": {
        "id": "DR_MS9DABo_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['loss']) + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
        "# plt.ylim (0.2, 0.5)\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "1\n",
        "plt.clf()\n",
        "plt.figure(figsize=(10, 5))\n",
        "val_acc_values = history_dict['categorical_accuracy']\n",
        "plt.plot(epochs, history_dict['categorical_accuracy'], 'bo', label='Training acc')\n",
        "plt.plot(epochs, history_dict['val_categorical_accuracy'], 'r', label='Validation acc')\n",
        "plt.ylim (0.86, 0.94)\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "2Ll_5sGlXKMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probability_model = tf.keras.Sequential([model,\n",
        "                                         tf.keras.layers.Softmax()])"
      ],
      "metadata": {
        "id": "VzOdKAT_uV-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = probability_model.predict(x_test)"
      ],
      "metadata": {
        "id": "f4is3NFruYom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0]"
      ],
      "metadata": {
        "id": "82cigvlZudz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "6RsQPHyYuNGe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}