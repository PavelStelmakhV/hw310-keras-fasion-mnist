{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFQDuQpTHufx/MbEV0Y5xS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavelStelmakhV/hw310-keras-fasion-mnist/blob/main/keras_fasion_mnist_hw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "vv7w0bgAVQPO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras import callbacks\n",
        "from keras import initializers\n",
        "from keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "mOpywsNAzfGB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "# x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "# Перемешаем тренировочные данные\n",
        "# train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "# train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "t2gucjsJ0KUi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]"
      ],
      "metadata": {
        "id": "fLPNXab5dHwO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bU5TK5YdlnU5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_init = initializers.glorot_normal()\n",
        "b_init = initializers.Zeros()"
      ],
      "metadata": {
        "id": "yL9QTEtBGy4N"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "drop_out = 0.30\n",
        "lern_rat = 0.001\n",
        "neurons = 128\n",
        "\n",
        "model.add(layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(layers.Dropout(0.35))\n",
        "\n",
        "model.add(layers.Dense(neurons * 1, activation='relu', kernel_initializer=w_init, bias_initializer=b_init)) #, kernel_regularizer=regularizers.l2(lern_rat)\n",
        "model.add(BatchNormalization())\n",
        "# model.add(layers.Dropout(drop_out))\n",
        "model.add(layers.Dense(neurons * 2, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(drop_out))\n",
        "\n",
        "model.add(layers.Dense(neurons * 4, activation='tanh'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(drop_out * 1.5))\n",
        "\n",
        "# model.add(layers.Dense(neurons * 8, activation='tanh'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(layers.Dropout(drop_out * 2))\n",
        "\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "atS39i4d0aqW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EzfnaqIZlfy8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(#optimizer='adam',\n",
        "              optimizer='adamax',\n",
        "              # optimizer='nadam',\n",
        "              # optimizer='rmsprop',\n",
        "              # optimizer='sgd',\n",
        "              # optimizer='adadelta',\n",
        "              # loss='binary_crossentropy',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy']) # sparse_categorical_accuracy"
      ],
      "metadata": {
        "id": "hENVaAC7ilNY"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.random((1, 28, 28))\n",
        "a = model.predict(x)\n",
        "_ = plt.hist(np.transpose(a))"
      ],
      "metadata": {
        "id": "RFgZHNNFMa8p",
        "outputId": "047dbece-44b3-4ae6-c424-cbccaea7c0c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "UDP8OKKZ8oQa",
        "outputId": "b8c2f92e-783c-4aa0-90e7-d6d4e564705c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback = callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                   patience=100,\n",
        "                                   restore_best_weights=True,\n",
        "                                  #  baseline=0.25,\n",
        "                                   )\n",
        "es = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "mc = callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n"
      ],
      "metadata": {
        "id": "5ihU4exVlsjm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(train_images, train_labels, epochs=20)\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=1000,\n",
        "                    batch_size=128,\n",
        "                    # callbacks=[callback],\n",
        "                    callbacks=[es, mc],\n",
        "                    verbose=1, #многословие\n",
        "                    validation_data=(x_val, y_val))\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "FH8HcMNm233I",
        "outputId": "659238a7-9412-4e25-9e7a-1fc6dbb229ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9436 - accuracy: 0.6857\n",
            "Epoch 1: val_accuracy improved from -inf to 0.81840, saving model to best_model.h5\n",
            "391/391 [==============================] - 5s 8ms/step - loss: 0.9421 - accuracy: 0.6861 - val_loss: 0.5236 - val_accuracy: 0.8184\n",
            "Epoch 2/1000\n",
            " 20/391 [>.............................] - ETA: 1s - loss: 0.7131 - accuracy: 0.7523"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "390/391 [============================>.] - ETA: 0s - loss: 0.6588 - accuracy: 0.7682\n",
            "Epoch 2: val_accuracy improved from 0.81840 to 0.83960, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6586 - accuracy: 0.7682 - val_loss: 0.4444 - val_accuracy: 0.8396\n",
            "Epoch 3/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.5792 - accuracy: 0.7919\n",
            "Epoch 3: val_accuracy improved from 0.83960 to 0.84010, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.5790 - accuracy: 0.7920 - val_loss: 0.4451 - val_accuracy: 0.8401\n",
            "Epoch 4/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.5309 - accuracy: 0.8069\n",
            "Epoch 4: val_accuracy improved from 0.84010 to 0.85320, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.5308 - accuracy: 0.8068 - val_loss: 0.4009 - val_accuracy: 0.8532\n",
            "Epoch 5/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.4960 - accuracy: 0.8197\n",
            "Epoch 5: val_accuracy improved from 0.85320 to 0.85400, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.4959 - accuracy: 0.8199 - val_loss: 0.4026 - val_accuracy: 0.8540\n",
            "Epoch 6/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.4693 - accuracy: 0.8279\n",
            "Epoch 6: val_accuracy improved from 0.85400 to 0.86000, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4692 - accuracy: 0.8279 - val_loss: 0.3816 - val_accuracy: 0.8600\n",
            "Epoch 7/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.4509 - accuracy: 0.8330\n",
            "Epoch 7: val_accuracy did not improve from 0.86000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4510 - accuracy: 0.8331 - val_loss: 0.3791 - val_accuracy: 0.8580\n",
            "Epoch 8/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.4332 - accuracy: 0.8404\n",
            "Epoch 8: val_accuracy improved from 0.86000 to 0.86720, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4332 - accuracy: 0.8404 - val_loss: 0.3543 - val_accuracy: 0.8672\n",
            "Epoch 9/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.4233 - accuracy: 0.8437\n",
            "Epoch 9: val_accuracy did not improve from 0.86720\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4229 - accuracy: 0.8438 - val_loss: 0.3612 - val_accuracy: 0.8665\n",
            "Epoch 10/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.4131 - accuracy: 0.8474\n",
            "Epoch 10: val_accuracy improved from 0.86720 to 0.86980, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4131 - accuracy: 0.8474 - val_loss: 0.3495 - val_accuracy: 0.8698\n",
            "Epoch 11/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.4066 - accuracy: 0.8495\n",
            "Epoch 11: val_accuracy improved from 0.86980 to 0.87080, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4061 - accuracy: 0.8498 - val_loss: 0.3415 - val_accuracy: 0.8708\n",
            "Epoch 12/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.3997 - accuracy: 0.8517\n",
            "Epoch 12: val_accuracy improved from 0.87080 to 0.87230, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3998 - accuracy: 0.8517 - val_loss: 0.3496 - val_accuracy: 0.8723\n",
            "Epoch 13/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.3939 - accuracy: 0.8530\n",
            "Epoch 13: val_accuracy did not improve from 0.87230\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3936 - accuracy: 0.8530 - val_loss: 0.3515 - val_accuracy: 0.8685\n",
            "Epoch 14/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8553\n",
            "Epoch 14: val_accuracy improved from 0.87230 to 0.87940, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3851 - accuracy: 0.8552 - val_loss: 0.3243 - val_accuracy: 0.8794\n",
            "Epoch 15/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8566\n",
            "Epoch 15: val_accuracy did not improve from 0.87940\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3825 - accuracy: 0.8564 - val_loss: 0.3324 - val_accuracy: 0.8762\n",
            "Epoch 16/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8592\n",
            "Epoch 16: val_accuracy improved from 0.87940 to 0.87990, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.3790 - accuracy: 0.8592 - val_loss: 0.3242 - val_accuracy: 0.8799\n",
            "Epoch 17/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.3733 - accuracy: 0.8602\n",
            "Epoch 17: val_accuracy did not improve from 0.87990\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3722 - accuracy: 0.8609 - val_loss: 0.3343 - val_accuracy: 0.8756\n",
            "Epoch 18/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.3652 - accuracy: 0.8633\n",
            "Epoch 18: val_accuracy did not improve from 0.87990\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3649 - accuracy: 0.8634 - val_loss: 0.3320 - val_accuracy: 0.8773\n",
            "Epoch 19/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.3645 - accuracy: 0.8632\n",
            "Epoch 19: val_accuracy did not improve from 0.87990\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3638 - accuracy: 0.8635 - val_loss: 0.3235 - val_accuracy: 0.8787\n",
            "Epoch 20/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.3602 - accuracy: 0.8652\n",
            "Epoch 20: val_accuracy did not improve from 0.87990\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3599 - accuracy: 0.8653 - val_loss: 0.3295 - val_accuracy: 0.8781\n",
            "Epoch 21/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.3589 - accuracy: 0.8651\n",
            "Epoch 21: val_accuracy improved from 0.87990 to 0.88720, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.3588 - accuracy: 0.8651 - val_loss: 0.3114 - val_accuracy: 0.8872\n",
            "Epoch 22/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.3532 - accuracy: 0.8677\n",
            "Epoch 22: val_accuracy did not improve from 0.88720\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3532 - accuracy: 0.8677 - val_loss: 0.3176 - val_accuracy: 0.8837\n",
            "Epoch 23/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.3517 - accuracy: 0.8681\n",
            "Epoch 23: val_accuracy did not improve from 0.88720\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3513 - accuracy: 0.8684 - val_loss: 0.3151 - val_accuracy: 0.8836\n",
            "Epoch 24/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.3459 - accuracy: 0.8714\n",
            "Epoch 24: val_accuracy did not improve from 0.88720\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3464 - accuracy: 0.8712 - val_loss: 0.3071 - val_accuracy: 0.8868\n",
            "Epoch 25/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.3461 - accuracy: 0.8690\n",
            "Epoch 25: val_accuracy did not improve from 0.88720\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3454 - accuracy: 0.8694 - val_loss: 0.3076 - val_accuracy: 0.8857\n",
            "Epoch 26/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.3420 - accuracy: 0.8713\n",
            "Epoch 26: val_accuracy did not improve from 0.88720\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.3417 - accuracy: 0.8715 - val_loss: 0.3135 - val_accuracy: 0.8834\n",
            "Epoch 27/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.3392 - accuracy: 0.8734\n",
            "Epoch 27: val_accuracy improved from 0.88720 to 0.88900, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.3388 - accuracy: 0.8736 - val_loss: 0.2994 - val_accuracy: 0.8890\n",
            "Epoch 28/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.3361 - accuracy: 0.8753\n",
            "Epoch 28: val_accuracy improved from 0.88900 to 0.88990, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3363 - accuracy: 0.8752 - val_loss: 0.3029 - val_accuracy: 0.8899\n",
            "Epoch 29/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.3331 - accuracy: 0.8739\n",
            "Epoch 29: val_accuracy did not improve from 0.88990\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3333 - accuracy: 0.8737 - val_loss: 0.3044 - val_accuracy: 0.8872\n",
            "Epoch 30/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.3327 - accuracy: 0.8756\n",
            "Epoch 30: val_accuracy improved from 0.88990 to 0.89080, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3334 - accuracy: 0.8753 - val_loss: 0.2979 - val_accuracy: 0.8908\n",
            "Epoch 31/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.8757\n",
            "Epoch 31: val_accuracy did not improve from 0.89080\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.3330 - accuracy: 0.8758 - val_loss: 0.3037 - val_accuracy: 0.8869\n",
            "Epoch 32/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.3269 - accuracy: 0.8777\n",
            "Epoch 32: val_accuracy did not improve from 0.89080\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.3275 - accuracy: 0.8773 - val_loss: 0.3066 - val_accuracy: 0.8850\n",
            "Epoch 33/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.3249 - accuracy: 0.8774\n",
            "Epoch 33: val_accuracy did not improve from 0.89080\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3255 - accuracy: 0.8773 - val_loss: 0.2980 - val_accuracy: 0.8899\n",
            "Epoch 34/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.8777\n",
            "Epoch 34: val_accuracy did not improve from 0.89080\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3227 - accuracy: 0.8779 - val_loss: 0.3080 - val_accuracy: 0.8857\n",
            "Epoch 35/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8784\n",
            "Epoch 35: val_accuracy did not improve from 0.89080\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3233 - accuracy: 0.8784 - val_loss: 0.3054 - val_accuracy: 0.8863\n",
            "Epoch 36/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.3216 - accuracy: 0.8786\n",
            "Epoch 36: val_accuracy did not improve from 0.89080\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3217 - accuracy: 0.8786 - val_loss: 0.2970 - val_accuracy: 0.8891\n",
            "Epoch 37/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.3185 - accuracy: 0.8811\n",
            "Epoch 37: val_accuracy improved from 0.89080 to 0.89110, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.3185 - accuracy: 0.8811 - val_loss: 0.2953 - val_accuracy: 0.8911\n",
            "Epoch 38/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.3207 - accuracy: 0.8778\n",
            "Epoch 38: val_accuracy did not improve from 0.89110\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3212 - accuracy: 0.8778 - val_loss: 0.2985 - val_accuracy: 0.8898\n",
            "Epoch 39/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.3197 - accuracy: 0.8805\n",
            "Epoch 39: val_accuracy improved from 0.89110 to 0.89300, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3201 - accuracy: 0.8803 - val_loss: 0.2908 - val_accuracy: 0.8930\n",
            "Epoch 40/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.3157 - accuracy: 0.8814\n",
            "Epoch 40: val_accuracy improved from 0.89300 to 0.89380, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3154 - accuracy: 0.8815 - val_loss: 0.2937 - val_accuracy: 0.8938\n",
            "Epoch 41/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.8812\n",
            "Epoch 41: val_accuracy did not improve from 0.89380\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3137 - accuracy: 0.8812 - val_loss: 0.2936 - val_accuracy: 0.8930\n",
            "Epoch 42/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.3123 - accuracy: 0.8813\n",
            "Epoch 42: val_accuracy did not improve from 0.89380\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.3118 - accuracy: 0.8815 - val_loss: 0.2928 - val_accuracy: 0.8891\n",
            "Epoch 43/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.3098 - accuracy: 0.8829\n",
            "Epoch 43: val_accuracy improved from 0.89380 to 0.89640, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3091 - accuracy: 0.8832 - val_loss: 0.2875 - val_accuracy: 0.8964\n",
            "Epoch 44/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.3096 - accuracy: 0.8840\n",
            "Epoch 44: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.3099 - accuracy: 0.8840 - val_loss: 0.2918 - val_accuracy: 0.8907\n",
            "Epoch 45/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.3087 - accuracy: 0.8835\n",
            "Epoch 45: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.3084 - accuracy: 0.8836 - val_loss: 0.2863 - val_accuracy: 0.8950\n",
            "Epoch 46/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.3043 - accuracy: 0.8858\n",
            "Epoch 46: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3040 - accuracy: 0.8860 - val_loss: 0.2879 - val_accuracy: 0.8942\n",
            "Epoch 47/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.8844\n",
            "Epoch 47: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.3054 - accuracy: 0.8842 - val_loss: 0.2945 - val_accuracy: 0.8906\n",
            "Epoch 48/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.3045 - accuracy: 0.8855\n",
            "Epoch 48: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3045 - accuracy: 0.8855 - val_loss: 0.2979 - val_accuracy: 0.8890\n",
            "Epoch 49/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.3027 - accuracy: 0.8855\n",
            "Epoch 49: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3028 - accuracy: 0.8855 - val_loss: 0.2839 - val_accuracy: 0.8944\n",
            "Epoch 50/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.3014 - accuracy: 0.8876\n",
            "Epoch 50: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3020 - accuracy: 0.8874 - val_loss: 0.2967 - val_accuracy: 0.8910\n",
            "Epoch 51/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.3019 - accuracy: 0.8858\n",
            "Epoch 51: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3020 - accuracy: 0.8856 - val_loss: 0.2914 - val_accuracy: 0.8924\n",
            "Epoch 52/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.8878\n",
            "Epoch 52: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2991 - accuracy: 0.8877 - val_loss: 0.2893 - val_accuracy: 0.8930\n",
            "Epoch 53/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2994 - accuracy: 0.8868\n",
            "Epoch 53: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2997 - accuracy: 0.8867 - val_loss: 0.2887 - val_accuracy: 0.8946\n",
            "Epoch 54/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.8877\n",
            "Epoch 54: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2968 - accuracy: 0.8875 - val_loss: 0.2885 - val_accuracy: 0.8943\n",
            "Epoch 55/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2973 - accuracy: 0.8876\n",
            "Epoch 55: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2975 - accuracy: 0.8875 - val_loss: 0.2915 - val_accuracy: 0.8925\n",
            "Epoch 56/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2950 - accuracy: 0.8904\n",
            "Epoch 56: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2948 - accuracy: 0.8904 - val_loss: 0.3000 - val_accuracy: 0.8895\n",
            "Epoch 57/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2948 - accuracy: 0.8885\n",
            "Epoch 57: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2952 - accuracy: 0.8885 - val_loss: 0.2973 - val_accuracy: 0.8898\n",
            "Epoch 58/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.8893\n",
            "Epoch 58: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2928 - accuracy: 0.8892 - val_loss: 0.2810 - val_accuracy: 0.8960\n",
            "Epoch 59/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2924 - accuracy: 0.8906\n",
            "Epoch 59: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2928 - accuracy: 0.8904 - val_loss: 0.2809 - val_accuracy: 0.8945\n",
            "Epoch 60/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2937 - accuracy: 0.8890\n",
            "Epoch 60: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2935 - accuracy: 0.8890 - val_loss: 0.2830 - val_accuracy: 0.8950\n",
            "Epoch 61/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2926 - accuracy: 0.8895\n",
            "Epoch 61: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2924 - accuracy: 0.8896 - val_loss: 0.2824 - val_accuracy: 0.8941\n",
            "Epoch 62/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.8902\n",
            "Epoch 62: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2890 - accuracy: 0.8901 - val_loss: 0.2856 - val_accuracy: 0.8923\n",
            "Epoch 63/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2874 - accuracy: 0.8914\n",
            "Epoch 63: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2873 - accuracy: 0.8914 - val_loss: 0.2868 - val_accuracy: 0.8943\n",
            "Epoch 64/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2898 - accuracy: 0.8901\n",
            "Epoch 64: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2893 - accuracy: 0.8902 - val_loss: 0.2865 - val_accuracy: 0.8953\n",
            "Epoch 65/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.8928\n",
            "Epoch 65: val_accuracy did not improve from 0.89640\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2861 - accuracy: 0.8924 - val_loss: 0.2842 - val_accuracy: 0.8938\n",
            "Epoch 66/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2867 - accuracy: 0.8905\n",
            "Epoch 66: val_accuracy improved from 0.89640 to 0.89650, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2873 - accuracy: 0.8904 - val_loss: 0.2809 - val_accuracy: 0.8965\n",
            "Epoch 67/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2851 - accuracy: 0.8915\n",
            "Epoch 67: val_accuracy did not improve from 0.89650\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2851 - accuracy: 0.8917 - val_loss: 0.2917 - val_accuracy: 0.8934\n",
            "Epoch 68/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2817 - accuracy: 0.8936\n",
            "Epoch 68: val_accuracy did not improve from 0.89650\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2816 - accuracy: 0.8936 - val_loss: 0.2898 - val_accuracy: 0.8925\n",
            "Epoch 69/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.2792 - accuracy: 0.8959\n",
            "Epoch 69: val_accuracy did not improve from 0.89650\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2795 - accuracy: 0.8955 - val_loss: 0.2803 - val_accuracy: 0.8950\n",
            "Epoch 70/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2841 - accuracy: 0.8952\n",
            "Epoch 70: val_accuracy improved from 0.89650 to 0.89800, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2838 - accuracy: 0.8952 - val_loss: 0.2768 - val_accuracy: 0.8980\n",
            "Epoch 71/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2813 - accuracy: 0.8931\n",
            "Epoch 71: val_accuracy did not improve from 0.89800\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2812 - accuracy: 0.8931 - val_loss: 0.2821 - val_accuracy: 0.8969\n",
            "Epoch 72/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.8903\n",
            "Epoch 72: val_accuracy did not improve from 0.89800\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2853 - accuracy: 0.8903 - val_loss: 0.2832 - val_accuracy: 0.8956\n",
            "Epoch 73/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2817 - accuracy: 0.8926\n",
            "Epoch 73: val_accuracy did not improve from 0.89800\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2820 - accuracy: 0.8924 - val_loss: 0.2785 - val_accuracy: 0.8949\n",
            "Epoch 74/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2838 - accuracy: 0.8923\n",
            "Epoch 74: val_accuracy did not improve from 0.89800\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2840 - accuracy: 0.8922 - val_loss: 0.2825 - val_accuracy: 0.8946\n",
            "Epoch 75/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2809 - accuracy: 0.8940\n",
            "Epoch 75: val_accuracy did not improve from 0.89800\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2810 - accuracy: 0.8940 - val_loss: 0.2815 - val_accuracy: 0.8953\n",
            "Epoch 76/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2768 - accuracy: 0.8955\n",
            "Epoch 76: val_accuracy did not improve from 0.89800\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2768 - accuracy: 0.8955 - val_loss: 0.2825 - val_accuracy: 0.8951\n",
            "Epoch 77/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2766 - accuracy: 0.8950\n",
            "Epoch 77: val_accuracy did not improve from 0.89800\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2765 - accuracy: 0.8951 - val_loss: 0.2782 - val_accuracy: 0.8975\n",
            "Epoch 78/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2762 - accuracy: 0.8956\n",
            "Epoch 78: val_accuracy did not improve from 0.89800\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2762 - accuracy: 0.8956 - val_loss: 0.2799 - val_accuracy: 0.8965\n",
            "Epoch 79/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.8948\n",
            "Epoch 79: val_accuracy improved from 0.89800 to 0.89860, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2777 - accuracy: 0.8949 - val_loss: 0.2741 - val_accuracy: 0.8986\n",
            "Epoch 80/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2762 - accuracy: 0.8948\n",
            "Epoch 80: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2763 - accuracy: 0.8948 - val_loss: 0.2807 - val_accuracy: 0.8958\n",
            "Epoch 81/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2759 - accuracy: 0.8956\n",
            "Epoch 81: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2762 - accuracy: 0.8956 - val_loss: 0.2857 - val_accuracy: 0.8952\n",
            "Epoch 82/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2767 - accuracy: 0.8942\n",
            "Epoch 82: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2767 - accuracy: 0.8941 - val_loss: 0.2784 - val_accuracy: 0.8973\n",
            "Epoch 83/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2706 - accuracy: 0.8973\n",
            "Epoch 83: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2707 - accuracy: 0.8973 - val_loss: 0.2956 - val_accuracy: 0.8923\n",
            "Epoch 84/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.8966\n",
            "Epoch 84: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2733 - accuracy: 0.8964 - val_loss: 0.2882 - val_accuracy: 0.8949\n",
            "Epoch 85/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2736 - accuracy: 0.8962\n",
            "Epoch 85: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2737 - accuracy: 0.8961 - val_loss: 0.2867 - val_accuracy: 0.8942\n",
            "Epoch 86/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.8967\n",
            "Epoch 86: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2733 - accuracy: 0.8967 - val_loss: 0.2833 - val_accuracy: 0.8952\n",
            "Epoch 87/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.8974\n",
            "Epoch 87: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2710 - accuracy: 0.8974 - val_loss: 0.2845 - val_accuracy: 0.8944\n",
            "Epoch 88/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2716 - accuracy: 0.8968\n",
            "Epoch 88: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2717 - accuracy: 0.8967 - val_loss: 0.2791 - val_accuracy: 0.8975\n",
            "Epoch 89/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.8987\n",
            "Epoch 89: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2677 - accuracy: 0.8986 - val_loss: 0.2838 - val_accuracy: 0.8943\n",
            "Epoch 90/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2682 - accuracy: 0.8992\n",
            "Epoch 90: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2676 - accuracy: 0.8994 - val_loss: 0.2741 - val_accuracy: 0.8973\n",
            "Epoch 91/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.2698 - accuracy: 0.8981\n",
            "Epoch 91: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2696 - accuracy: 0.8979 - val_loss: 0.2856 - val_accuracy: 0.8941\n",
            "Epoch 92/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2696 - accuracy: 0.8973\n",
            "Epoch 92: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2698 - accuracy: 0.8973 - val_loss: 0.2798 - val_accuracy: 0.8971\n",
            "Epoch 93/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.8994\n",
            "Epoch 93: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2656 - accuracy: 0.8993 - val_loss: 0.2837 - val_accuracy: 0.8954\n",
            "Epoch 94/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2661 - accuracy: 0.8983\n",
            "Epoch 94: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2659 - accuracy: 0.8984 - val_loss: 0.2860 - val_accuracy: 0.8974\n",
            "Epoch 95/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2694 - accuracy: 0.8981\n",
            "Epoch 95: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2694 - accuracy: 0.8981 - val_loss: 0.2743 - val_accuracy: 0.8978\n",
            "Epoch 96/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2653 - accuracy: 0.9002\n",
            "Epoch 96: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2658 - accuracy: 0.9000 - val_loss: 0.2733 - val_accuracy: 0.8983\n",
            "Epoch 97/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2648 - accuracy: 0.9006\n",
            "Epoch 97: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2648 - accuracy: 0.9004 - val_loss: 0.2841 - val_accuracy: 0.8956\n",
            "Epoch 98/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2646 - accuracy: 0.8985\n",
            "Epoch 98: val_accuracy did not improve from 0.89860\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2652 - accuracy: 0.8983 - val_loss: 0.2750 - val_accuracy: 0.8976\n",
            "Epoch 99/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.8999\n",
            "Epoch 99: val_accuracy improved from 0.89860 to 0.89950, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2620 - accuracy: 0.9001 - val_loss: 0.2768 - val_accuracy: 0.8995\n",
            "Epoch 100/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.8990\n",
            "Epoch 100: val_accuracy did not improve from 0.89950\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2659 - accuracy: 0.8991 - val_loss: 0.2805 - val_accuracy: 0.8970\n",
            "Epoch 101/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2603 - accuracy: 0.8995\n",
            "Epoch 101: val_accuracy did not improve from 0.89950\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2602 - accuracy: 0.8996 - val_loss: 0.2778 - val_accuracy: 0.8985\n",
            "Epoch 102/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.9004\n",
            "Epoch 102: val_accuracy did not improve from 0.89950\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2621 - accuracy: 0.9004 - val_loss: 0.2782 - val_accuracy: 0.8959\n",
            "Epoch 103/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2651 - accuracy: 0.8989\n",
            "Epoch 103: val_accuracy did not improve from 0.89950\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2651 - accuracy: 0.8989 - val_loss: 0.2775 - val_accuracy: 0.8995\n",
            "Epoch 104/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2611 - accuracy: 0.9008\n",
            "Epoch 104: val_accuracy did not improve from 0.89950\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2611 - accuracy: 0.9008 - val_loss: 0.2817 - val_accuracy: 0.8980\n",
            "Epoch 105/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2605 - accuracy: 0.9005\n",
            "Epoch 105: val_accuracy improved from 0.89950 to 0.90020, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2609 - accuracy: 0.9005 - val_loss: 0.2744 - val_accuracy: 0.9002\n",
            "Epoch 106/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2606 - accuracy: 0.9020\n",
            "Epoch 106: val_accuracy did not improve from 0.90020\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2605 - accuracy: 0.9021 - val_loss: 0.2758 - val_accuracy: 0.8978\n",
            "Epoch 107/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2608 - accuracy: 0.9008\n",
            "Epoch 107: val_accuracy did not improve from 0.90020\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2606 - accuracy: 0.9010 - val_loss: 0.2749 - val_accuracy: 0.8990\n",
            "Epoch 108/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2610 - accuracy: 0.8990\n",
            "Epoch 108: val_accuracy did not improve from 0.90020\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2610 - accuracy: 0.8990 - val_loss: 0.2761 - val_accuracy: 0.8993\n",
            "Epoch 109/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2607 - accuracy: 0.8995\n",
            "Epoch 109: val_accuracy did not improve from 0.90020\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2613 - accuracy: 0.8993 - val_loss: 0.2811 - val_accuracy: 0.8956\n",
            "Epoch 110/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2569 - accuracy: 0.9022\n",
            "Epoch 110: val_accuracy did not improve from 0.90020\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2572 - accuracy: 0.9021 - val_loss: 0.2813 - val_accuracy: 0.8971\n",
            "Epoch 111/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2602 - accuracy: 0.9006\n",
            "Epoch 111: val_accuracy did not improve from 0.90020\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2595 - accuracy: 0.9008 - val_loss: 0.2775 - val_accuracy: 0.8989\n",
            "Epoch 112/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2575 - accuracy: 0.9018\n",
            "Epoch 112: val_accuracy did not improve from 0.90020\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2571 - accuracy: 0.9019 - val_loss: 0.2799 - val_accuracy: 0.8984\n",
            "Epoch 113/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2571 - accuracy: 0.9014\n",
            "Epoch 113: val_accuracy did not improve from 0.90020\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2569 - accuracy: 0.9014 - val_loss: 0.2785 - val_accuracy: 0.9002\n",
            "Epoch 114/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2591 - accuracy: 0.9019\n",
            "Epoch 114: val_accuracy did not improve from 0.90020\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2590 - accuracy: 0.9018 - val_loss: 0.2832 - val_accuracy: 0.8976\n",
            "Epoch 115/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2604 - accuracy: 0.9012\n",
            "Epoch 115: val_accuracy did not improve from 0.90020\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2599 - accuracy: 0.9014 - val_loss: 0.2842 - val_accuracy: 0.8984\n",
            "Epoch 116/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2563 - accuracy: 0.9020\n",
            "Epoch 116: val_accuracy improved from 0.90020 to 0.90070, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2561 - accuracy: 0.9021 - val_loss: 0.2784 - val_accuracy: 0.9007\n",
            "Epoch 117/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2570 - accuracy: 0.9028\n",
            "Epoch 117: val_accuracy did not improve from 0.90070\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2574 - accuracy: 0.9028 - val_loss: 0.2787 - val_accuracy: 0.8988\n",
            "Epoch 118/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2575 - accuracy: 0.9020\n",
            "Epoch 118: val_accuracy did not improve from 0.90070\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2575 - accuracy: 0.9020 - val_loss: 0.2768 - val_accuracy: 0.8998\n",
            "Epoch 119/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2575 - accuracy: 0.9019\n",
            "Epoch 119: val_accuracy did not improve from 0.90070\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2575 - accuracy: 0.9019 - val_loss: 0.2815 - val_accuracy: 0.8976\n",
            "Epoch 120/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2581 - accuracy: 0.9016\n",
            "Epoch 120: val_accuracy did not improve from 0.90070\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2577 - accuracy: 0.9018 - val_loss: 0.2784 - val_accuracy: 0.8983\n",
            "Epoch 121/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2537 - accuracy: 0.9030\n",
            "Epoch 121: val_accuracy did not improve from 0.90070\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2537 - accuracy: 0.9030 - val_loss: 0.2797 - val_accuracy: 0.8992\n",
            "Epoch 122/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2525 - accuracy: 0.9036\n",
            "Epoch 122: val_accuracy did not improve from 0.90070\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2528 - accuracy: 0.9033 - val_loss: 0.2816 - val_accuracy: 0.8973\n",
            "Epoch 123/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2527 - accuracy: 0.9025\n",
            "Epoch 123: val_accuracy did not improve from 0.90070\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2520 - accuracy: 0.9028 - val_loss: 0.2774 - val_accuracy: 0.8985\n",
            "Epoch 124/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2546 - accuracy: 0.9038\n",
            "Epoch 124: val_accuracy did not improve from 0.90070\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2543 - accuracy: 0.9040 - val_loss: 0.2782 - val_accuracy: 0.8995\n",
            "Epoch 125/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.9045\n",
            "Epoch 125: val_accuracy did not improve from 0.90070\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2506 - accuracy: 0.9044 - val_loss: 0.2764 - val_accuracy: 0.8998\n",
            "Epoch 126/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.9023\n",
            "Epoch 126: val_accuracy improved from 0.90070 to 0.90120, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2551 - accuracy: 0.9021 - val_loss: 0.2759 - val_accuracy: 0.9012\n",
            "Epoch 127/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2539 - accuracy: 0.9031\n",
            "Epoch 127: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2539 - accuracy: 0.9031 - val_loss: 0.2820 - val_accuracy: 0.8985\n",
            "Epoch 128/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2495 - accuracy: 0.9041\n",
            "Epoch 128: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2498 - accuracy: 0.9041 - val_loss: 0.2741 - val_accuracy: 0.9006\n",
            "Epoch 129/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9031\n",
            "Epoch 129: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2514 - accuracy: 0.9031 - val_loss: 0.2775 - val_accuracy: 0.8994\n",
            "Epoch 130/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2498 - accuracy: 0.9039\n",
            "Epoch 130: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2497 - accuracy: 0.9040 - val_loss: 0.2767 - val_accuracy: 0.9002\n",
            "Epoch 131/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2497 - accuracy: 0.9046\n",
            "Epoch 131: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2501 - accuracy: 0.9045 - val_loss: 0.2725 - val_accuracy: 0.8999\n",
            "Epoch 132/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2498 - accuracy: 0.9050\n",
            "Epoch 132: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2499 - accuracy: 0.9049 - val_loss: 0.2765 - val_accuracy: 0.8996\n",
            "Epoch 133/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2502 - accuracy: 0.9047\n",
            "Epoch 133: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2501 - accuracy: 0.9049 - val_loss: 0.2761 - val_accuracy: 0.8967\n",
            "Epoch 134/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2491 - accuracy: 0.9053\n",
            "Epoch 134: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2494 - accuracy: 0.9050 - val_loss: 0.2771 - val_accuracy: 0.8990\n",
            "Epoch 135/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2509 - accuracy: 0.9048\n",
            "Epoch 135: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2510 - accuracy: 0.9048 - val_loss: 0.2773 - val_accuracy: 0.8971\n",
            "Epoch 136/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2510 - accuracy: 0.9041\n",
            "Epoch 136: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2511 - accuracy: 0.9041 - val_loss: 0.2841 - val_accuracy: 0.8968\n",
            "Epoch 137/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2525 - accuracy: 0.9041\n",
            "Epoch 137: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2524 - accuracy: 0.9040 - val_loss: 0.2749 - val_accuracy: 0.8995\n",
            "Epoch 138/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2483 - accuracy: 0.9051\n",
            "Epoch 138: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2479 - accuracy: 0.9052 - val_loss: 0.2721 - val_accuracy: 0.9004\n",
            "Epoch 139/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2463 - accuracy: 0.9071\n",
            "Epoch 139: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2463 - accuracy: 0.9071 - val_loss: 0.2731 - val_accuracy: 0.8997\n",
            "Epoch 140/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2521 - accuracy: 0.9033\n",
            "Epoch 140: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2517 - accuracy: 0.9033 - val_loss: 0.2737 - val_accuracy: 0.8996\n",
            "Epoch 141/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2481 - accuracy: 0.9049\n",
            "Epoch 141: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2482 - accuracy: 0.9051 - val_loss: 0.2752 - val_accuracy: 0.8998\n",
            "Epoch 142/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.9063\n",
            "Epoch 142: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2478 - accuracy: 0.9063 - val_loss: 0.2756 - val_accuracy: 0.8985\n",
            "Epoch 143/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2457 - accuracy: 0.9065\n",
            "Epoch 143: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2455 - accuracy: 0.9065 - val_loss: 0.2803 - val_accuracy: 0.8958\n",
            "Epoch 144/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2492 - accuracy: 0.9069\n",
            "Epoch 144: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2492 - accuracy: 0.9067 - val_loss: 0.2769 - val_accuracy: 0.8989\n",
            "Epoch 145/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.2465 - accuracy: 0.9058\n",
            "Epoch 145: val_accuracy did not improve from 0.90120\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2461 - accuracy: 0.9059 - val_loss: 0.2747 - val_accuracy: 0.8977\n",
            "Epoch 146/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.9063\n",
            "Epoch 146: val_accuracy improved from 0.90120 to 0.90310, saving model to best_model.h5\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2471 - accuracy: 0.9063 - val_loss: 0.2711 - val_accuracy: 0.9031\n",
            "Epoch 147/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.9071\n",
            "Epoch 147: val_accuracy did not improve from 0.90310\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2444 - accuracy: 0.9071 - val_loss: 0.2818 - val_accuracy: 0.8979\n",
            "Epoch 148/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2441 - accuracy: 0.9066\n",
            "Epoch 148: val_accuracy did not improve from 0.90310\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2439 - accuracy: 0.9068 - val_loss: 0.2758 - val_accuracy: 0.9015\n",
            "Epoch 149/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2461 - accuracy: 0.9060\n",
            "Epoch 149: val_accuracy did not improve from 0.90310\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2462 - accuracy: 0.9059 - val_loss: 0.2764 - val_accuracy: 0.8990\n",
            "Epoch 150/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9071\n",
            "Epoch 150: val_accuracy did not improve from 0.90310\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2449 - accuracy: 0.9071 - val_loss: 0.2746 - val_accuracy: 0.8999\n",
            "Epoch 151/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.9067\n",
            "Epoch 151: val_accuracy did not improve from 0.90310\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2453 - accuracy: 0.9067 - val_loss: 0.2713 - val_accuracy: 0.9017\n",
            "Epoch 152/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.9055\n",
            "Epoch 152: val_accuracy did not improve from 0.90310\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2451 - accuracy: 0.9055 - val_loss: 0.2779 - val_accuracy: 0.8994\n",
            "Epoch 153/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2431 - accuracy: 0.9085\n",
            "Epoch 153: val_accuracy improved from 0.90310 to 0.90460, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2431 - accuracy: 0.9085 - val_loss: 0.2693 - val_accuracy: 0.9046\n",
            "Epoch 154/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2423 - accuracy: 0.9071\n",
            "Epoch 154: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2430 - accuracy: 0.9071 - val_loss: 0.2737 - val_accuracy: 0.8994\n",
            "Epoch 155/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.9072\n",
            "Epoch 155: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2425 - accuracy: 0.9071 - val_loss: 0.2697 - val_accuracy: 0.9009\n",
            "Epoch 156/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.9084\n",
            "Epoch 156: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2424 - accuracy: 0.9086 - val_loss: 0.2765 - val_accuracy: 0.8991\n",
            "Epoch 157/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2425 - accuracy: 0.9071\n",
            "Epoch 157: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2424 - accuracy: 0.9071 - val_loss: 0.2809 - val_accuracy: 0.8999\n",
            "Epoch 158/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.2443 - accuracy: 0.9056\n",
            "Epoch 158: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2436 - accuracy: 0.9059 - val_loss: 0.2794 - val_accuracy: 0.8981\n",
            "Epoch 159/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9086\n",
            "Epoch 159: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2406 - accuracy: 0.9083 - val_loss: 0.2713 - val_accuracy: 0.9005\n",
            "Epoch 160/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2415 - accuracy: 0.9084\n",
            "Epoch 160: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2415 - accuracy: 0.9084 - val_loss: 0.2857 - val_accuracy: 0.8954\n",
            "Epoch 161/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2421 - accuracy: 0.9080\n",
            "Epoch 161: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2421 - accuracy: 0.9080 - val_loss: 0.2704 - val_accuracy: 0.9024\n",
            "Epoch 162/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.9077\n",
            "Epoch 162: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2426 - accuracy: 0.9074 - val_loss: 0.2709 - val_accuracy: 0.9024\n",
            "Epoch 163/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2391 - accuracy: 0.9081\n",
            "Epoch 163: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2393 - accuracy: 0.9080 - val_loss: 0.2702 - val_accuracy: 0.9021\n",
            "Epoch 164/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9074\n",
            "Epoch 164: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2420 - accuracy: 0.9073 - val_loss: 0.2755 - val_accuracy: 0.9003\n",
            "Epoch 165/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9091\n",
            "Epoch 165: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2399 - accuracy: 0.9089 - val_loss: 0.2737 - val_accuracy: 0.9012\n",
            "Epoch 166/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2406 - accuracy: 0.9080\n",
            "Epoch 166: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2405 - accuracy: 0.9081 - val_loss: 0.2690 - val_accuracy: 0.9019\n",
            "Epoch 167/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.9091\n",
            "Epoch 167: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2386 - accuracy: 0.9091 - val_loss: 0.2716 - val_accuracy: 0.9017\n",
            "Epoch 168/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2378 - accuracy: 0.9087\n",
            "Epoch 168: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2377 - accuracy: 0.9087 - val_loss: 0.2729 - val_accuracy: 0.9028\n",
            "Epoch 169/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.9090\n",
            "Epoch 169: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2390 - accuracy: 0.9090 - val_loss: 0.2748 - val_accuracy: 0.9020\n",
            "Epoch 170/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2409 - accuracy: 0.9084\n",
            "Epoch 170: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2415 - accuracy: 0.9083 - val_loss: 0.2741 - val_accuracy: 0.9012\n",
            "Epoch 171/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2366 - accuracy: 0.9104\n",
            "Epoch 171: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2370 - accuracy: 0.9103 - val_loss: 0.2724 - val_accuracy: 0.9000\n",
            "Epoch 172/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2374 - accuracy: 0.9088\n",
            "Epoch 172: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2373 - accuracy: 0.9089 - val_loss: 0.2848 - val_accuracy: 0.8956\n",
            "Epoch 173/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2368 - accuracy: 0.9098\n",
            "Epoch 173: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2369 - accuracy: 0.9097 - val_loss: 0.2818 - val_accuracy: 0.9002\n",
            "Epoch 174/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2414 - accuracy: 0.9073\n",
            "Epoch 174: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2411 - accuracy: 0.9075 - val_loss: 0.2727 - val_accuracy: 0.9015\n",
            "Epoch 175/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.9091\n",
            "Epoch 175: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2361 - accuracy: 0.9092 - val_loss: 0.2737 - val_accuracy: 0.9029\n",
            "Epoch 176/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2398 - accuracy: 0.9090\n",
            "Epoch 176: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2399 - accuracy: 0.9090 - val_loss: 0.2753 - val_accuracy: 0.9033\n",
            "Epoch 177/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.9108\n",
            "Epoch 177: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2355 - accuracy: 0.9110 - val_loss: 0.2731 - val_accuracy: 0.9019\n",
            "Epoch 178/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2408 - accuracy: 0.9088\n",
            "Epoch 178: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2410 - accuracy: 0.9087 - val_loss: 0.2724 - val_accuracy: 0.9023\n",
            "Epoch 179/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9109\n",
            "Epoch 179: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2346 - accuracy: 0.9109 - val_loss: 0.2752 - val_accuracy: 0.9022\n",
            "Epoch 180/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.9089\n",
            "Epoch 180: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2395 - accuracy: 0.9089 - val_loss: 0.2780 - val_accuracy: 0.9009\n",
            "Epoch 181/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2352 - accuracy: 0.9108\n",
            "Epoch 181: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2351 - accuracy: 0.9107 - val_loss: 0.2699 - val_accuracy: 0.9019\n",
            "Epoch 182/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2353 - accuracy: 0.9098\n",
            "Epoch 182: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2353 - accuracy: 0.9098 - val_loss: 0.2780 - val_accuracy: 0.9003\n",
            "Epoch 183/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2377 - accuracy: 0.9088\n",
            "Epoch 183: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2374 - accuracy: 0.9090 - val_loss: 0.2643 - val_accuracy: 0.9024\n",
            "Epoch 184/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9119\n",
            "Epoch 184: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2331 - accuracy: 0.9119 - val_loss: 0.2733 - val_accuracy: 0.9005\n",
            "Epoch 185/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2348 - accuracy: 0.9114\n",
            "Epoch 185: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2346 - accuracy: 0.9115 - val_loss: 0.2721 - val_accuracy: 0.9023\n",
            "Epoch 186/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.9104\n",
            "Epoch 186: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2335 - accuracy: 0.9105 - val_loss: 0.2758 - val_accuracy: 0.9005\n",
            "Epoch 187/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2341 - accuracy: 0.9101\n",
            "Epoch 187: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2342 - accuracy: 0.9101 - val_loss: 0.2736 - val_accuracy: 0.9029\n",
            "Epoch 188/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2371 - accuracy: 0.9089\n",
            "Epoch 188: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2372 - accuracy: 0.9088 - val_loss: 0.2702 - val_accuracy: 0.9026\n",
            "Epoch 189/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2371 - accuracy: 0.9104\n",
            "Epoch 189: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2371 - accuracy: 0.9103 - val_loss: 0.2690 - val_accuracy: 0.9041\n",
            "Epoch 190/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.9107\n",
            "Epoch 190: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2338 - accuracy: 0.9105 - val_loss: 0.2795 - val_accuracy: 0.9000\n",
            "Epoch 191/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2345 - accuracy: 0.9107\n",
            "Epoch 191: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2345 - accuracy: 0.9108 - val_loss: 0.2763 - val_accuracy: 0.9014\n",
            "Epoch 192/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2322 - accuracy: 0.9105\n",
            "Epoch 192: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2321 - accuracy: 0.9106 - val_loss: 0.2820 - val_accuracy: 0.8989\n",
            "Epoch 193/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2315 - accuracy: 0.9105\n",
            "Epoch 193: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2319 - accuracy: 0.9104 - val_loss: 0.2732 - val_accuracy: 0.9036\n",
            "Epoch 194/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9099\n",
            "Epoch 194: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2334 - accuracy: 0.9098 - val_loss: 0.2737 - val_accuracy: 0.9002\n",
            "Epoch 195/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2331 - accuracy: 0.9112\n",
            "Epoch 195: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2333 - accuracy: 0.9111 - val_loss: 0.2775 - val_accuracy: 0.9009\n",
            "Epoch 196/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2341 - accuracy: 0.9106\n",
            "Epoch 196: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2339 - accuracy: 0.9108 - val_loss: 0.2762 - val_accuracy: 0.9004\n",
            "Epoch 197/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2315 - accuracy: 0.9115\n",
            "Epoch 197: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2316 - accuracy: 0.9116 - val_loss: 0.2761 - val_accuracy: 0.9008\n",
            "Epoch 198/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2346 - accuracy: 0.9100\n",
            "Epoch 198: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2346 - accuracy: 0.9100 - val_loss: 0.2760 - val_accuracy: 0.9001\n",
            "Epoch 199/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2317 - accuracy: 0.9100\n",
            "Epoch 199: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2318 - accuracy: 0.9099 - val_loss: 0.2731 - val_accuracy: 0.9043\n",
            "Epoch 200/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2346 - accuracy: 0.9096\n",
            "Epoch 200: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2342 - accuracy: 0.9098 - val_loss: 0.2763 - val_accuracy: 0.9011\n",
            "Epoch 201/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2310 - accuracy: 0.9112\n",
            "Epoch 201: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2315 - accuracy: 0.9109 - val_loss: 0.2762 - val_accuracy: 0.9016\n",
            "Epoch 202/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2330 - accuracy: 0.9110\n",
            "Epoch 202: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2333 - accuracy: 0.9110 - val_loss: 0.2720 - val_accuracy: 0.9036\n",
            "Epoch 203/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2344 - accuracy: 0.9097\n",
            "Epoch 203: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2344 - accuracy: 0.9096 - val_loss: 0.2708 - val_accuracy: 0.9019\n",
            "Epoch 204/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2314 - accuracy: 0.9110\n",
            "Epoch 204: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2314 - accuracy: 0.9111 - val_loss: 0.2716 - val_accuracy: 0.9015\n",
            "Epoch 205/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.2323 - accuracy: 0.9115\n",
            "Epoch 205: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2324 - accuracy: 0.9113 - val_loss: 0.2775 - val_accuracy: 0.9008\n",
            "Epoch 206/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2323 - accuracy: 0.9114\n",
            "Epoch 206: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2324 - accuracy: 0.9114 - val_loss: 0.2739 - val_accuracy: 0.9020\n",
            "Epoch 207/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2310 - accuracy: 0.9108\n",
            "Epoch 207: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2311 - accuracy: 0.9109 - val_loss: 0.2769 - val_accuracy: 0.8997\n",
            "Epoch 208/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2325 - accuracy: 0.9103\n",
            "Epoch 208: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2318 - accuracy: 0.9105 - val_loss: 0.2779 - val_accuracy: 0.9006\n",
            "Epoch 209/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2293 - accuracy: 0.9117\n",
            "Epoch 209: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2294 - accuracy: 0.9117 - val_loss: 0.2742 - val_accuracy: 0.9031\n",
            "Epoch 210/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2332 - accuracy: 0.9121\n",
            "Epoch 210: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2332 - accuracy: 0.9122 - val_loss: 0.2771 - val_accuracy: 0.9011\n",
            "Epoch 211/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2315 - accuracy: 0.9113\n",
            "Epoch 211: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2314 - accuracy: 0.9112 - val_loss: 0.2732 - val_accuracy: 0.9032\n",
            "Epoch 212/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2307 - accuracy: 0.9130\n",
            "Epoch 212: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2305 - accuracy: 0.9130 - val_loss: 0.2708 - val_accuracy: 0.9042\n",
            "Epoch 213/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.2305 - accuracy: 0.9121\n",
            "Epoch 213: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2307 - accuracy: 0.9119 - val_loss: 0.2718 - val_accuracy: 0.9039\n",
            "Epoch 214/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2310 - accuracy: 0.9113\n",
            "Epoch 214: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2305 - accuracy: 0.9115 - val_loss: 0.2844 - val_accuracy: 0.8989\n",
            "Epoch 215/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2310 - accuracy: 0.9106\n",
            "Epoch 215: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2312 - accuracy: 0.9104 - val_loss: 0.2719 - val_accuracy: 0.9032\n",
            "Epoch 216/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2298 - accuracy: 0.9139\n",
            "Epoch 216: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2295 - accuracy: 0.9139 - val_loss: 0.2728 - val_accuracy: 0.9026\n",
            "Epoch 217/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2297 - accuracy: 0.9129\n",
            "Epoch 217: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2301 - accuracy: 0.9127 - val_loss: 0.2708 - val_accuracy: 0.9046\n",
            "Epoch 218/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9123\n",
            "Epoch 218: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2284 - accuracy: 0.9123 - val_loss: 0.2711 - val_accuracy: 0.9022\n",
            "Epoch 219/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9112\n",
            "Epoch 219: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2291 - accuracy: 0.9112 - val_loss: 0.2766 - val_accuracy: 0.9023\n",
            "Epoch 220/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.2280 - accuracy: 0.9111\n",
            "Epoch 220: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2275 - accuracy: 0.9113 - val_loss: 0.2803 - val_accuracy: 0.9009\n",
            "Epoch 221/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2299 - accuracy: 0.9129\n",
            "Epoch 221: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2299 - accuracy: 0.9129 - val_loss: 0.2732 - val_accuracy: 0.9005\n",
            "Epoch 222/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2260 - accuracy: 0.9143\n",
            "Epoch 222: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2264 - accuracy: 0.9142 - val_loss: 0.2743 - val_accuracy: 0.9021\n",
            "Epoch 223/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2277 - accuracy: 0.9120\n",
            "Epoch 223: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2285 - accuracy: 0.9117 - val_loss: 0.2778 - val_accuracy: 0.9008\n",
            "Epoch 224/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2298 - accuracy: 0.9119\n",
            "Epoch 224: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2298 - accuracy: 0.9119 - val_loss: 0.2772 - val_accuracy: 0.9035\n",
            "Epoch 225/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2276 - accuracy: 0.9130\n",
            "Epoch 225: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2277 - accuracy: 0.9129 - val_loss: 0.2737 - val_accuracy: 0.9010\n",
            "Epoch 226/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9130\n",
            "Epoch 226: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2278 - accuracy: 0.9130 - val_loss: 0.2715 - val_accuracy: 0.9035\n",
            "Epoch 227/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2303 - accuracy: 0.9109\n",
            "Epoch 227: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2303 - accuracy: 0.9109 - val_loss: 0.2670 - val_accuracy: 0.9042\n",
            "Epoch 228/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.9124\n",
            "Epoch 228: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2285 - accuracy: 0.9124 - val_loss: 0.2750 - val_accuracy: 0.9028\n",
            "Epoch 229/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2278 - accuracy: 0.9137\n",
            "Epoch 229: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2276 - accuracy: 0.9138 - val_loss: 0.2737 - val_accuracy: 0.9032\n",
            "Epoch 230/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2265 - accuracy: 0.9129\n",
            "Epoch 230: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2268 - accuracy: 0.9128 - val_loss: 0.2701 - val_accuracy: 0.9040\n",
            "Epoch 231/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2255 - accuracy: 0.9146\n",
            "Epoch 231: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2260 - accuracy: 0.9145 - val_loss: 0.2756 - val_accuracy: 0.9020\n",
            "Epoch 232/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2274 - accuracy: 0.9127\n",
            "Epoch 232: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2272 - accuracy: 0.9128 - val_loss: 0.2716 - val_accuracy: 0.9029\n",
            "Epoch 233/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2256 - accuracy: 0.9122\n",
            "Epoch 233: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2256 - accuracy: 0.9123 - val_loss: 0.2727 - val_accuracy: 0.9032\n",
            "Epoch 234/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2258 - accuracy: 0.9133\n",
            "Epoch 234: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2255 - accuracy: 0.9134 - val_loss: 0.2712 - val_accuracy: 0.9020\n",
            "Epoch 235/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.9140\n",
            "Epoch 235: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2295 - accuracy: 0.9139 - val_loss: 0.2760 - val_accuracy: 0.9012\n",
            "Epoch 236/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2275 - accuracy: 0.9132\n",
            "Epoch 236: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2273 - accuracy: 0.9134 - val_loss: 0.2773 - val_accuracy: 0.9018\n",
            "Epoch 237/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2274 - accuracy: 0.9132\n",
            "Epoch 237: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2276 - accuracy: 0.9132 - val_loss: 0.2722 - val_accuracy: 0.9011\n",
            "Epoch 238/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2263 - accuracy: 0.9133\n",
            "Epoch 238: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2263 - accuracy: 0.9132 - val_loss: 0.2709 - val_accuracy: 0.9034\n",
            "Epoch 239/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2270 - accuracy: 0.9126\n",
            "Epoch 239: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2266 - accuracy: 0.9128 - val_loss: 0.2761 - val_accuracy: 0.9026\n",
            "Epoch 240/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2253 - accuracy: 0.9139\n",
            "Epoch 240: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2252 - accuracy: 0.9139 - val_loss: 0.2672 - val_accuracy: 0.9033\n",
            "Epoch 241/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2233 - accuracy: 0.9156\n",
            "Epoch 241: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2233 - accuracy: 0.9156 - val_loss: 0.2752 - val_accuracy: 0.9012\n",
            "Epoch 242/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.9149\n",
            "Epoch 242: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2229 - accuracy: 0.9147 - val_loss: 0.2744 - val_accuracy: 0.9017\n",
            "Epoch 243/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.9137\n",
            "Epoch 243: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2256 - accuracy: 0.9137 - val_loss: 0.2680 - val_accuracy: 0.9041\n",
            "Epoch 244/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2251 - accuracy: 0.9141\n",
            "Epoch 244: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2249 - accuracy: 0.9142 - val_loss: 0.2757 - val_accuracy: 0.9020\n",
            "Epoch 245/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2247 - accuracy: 0.9148\n",
            "Epoch 245: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2247 - accuracy: 0.9148 - val_loss: 0.2774 - val_accuracy: 0.9007\n",
            "Epoch 246/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.2261 - accuracy: 0.9149\n",
            "Epoch 246: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2259 - accuracy: 0.9152 - val_loss: 0.2740 - val_accuracy: 0.9023\n",
            "Epoch 247/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2242 - accuracy: 0.9138\n",
            "Epoch 247: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2243 - accuracy: 0.9138 - val_loss: 0.2753 - val_accuracy: 0.9015\n",
            "Epoch 248/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2227 - accuracy: 0.9161\n",
            "Epoch 248: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2226 - accuracy: 0.9161 - val_loss: 0.2820 - val_accuracy: 0.8999\n",
            "Epoch 249/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2249 - accuracy: 0.9127\n",
            "Epoch 249: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2249 - accuracy: 0.9126 - val_loss: 0.2746 - val_accuracy: 0.9043\n",
            "Epoch 250/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.2251 - accuracy: 0.9143\n",
            "Epoch 250: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2253 - accuracy: 0.9144 - val_loss: 0.2759 - val_accuracy: 0.9015\n",
            "Epoch 251/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2252 - accuracy: 0.9126\n",
            "Epoch 251: val_accuracy did not improve from 0.90460\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2250 - accuracy: 0.9128 - val_loss: 0.2760 - val_accuracy: 0.9036\n",
            "Epoch 252/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2221 - accuracy: 0.9141\n",
            "Epoch 252: val_accuracy improved from 0.90460 to 0.90580, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2223 - accuracy: 0.9141 - val_loss: 0.2755 - val_accuracy: 0.9058\n",
            "Epoch 253/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2222 - accuracy: 0.9145\n",
            "Epoch 253: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2226 - accuracy: 0.9144 - val_loss: 0.2740 - val_accuracy: 0.9026\n",
            "Epoch 254/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2227 - accuracy: 0.9145\n",
            "Epoch 254: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2226 - accuracy: 0.9145 - val_loss: 0.2698 - val_accuracy: 0.9053\n",
            "Epoch 255/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9157\n",
            "Epoch 255: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2212 - accuracy: 0.9157 - val_loss: 0.2764 - val_accuracy: 0.9035\n",
            "Epoch 256/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2202 - accuracy: 0.9156\n",
            "Epoch 256: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2199 - accuracy: 0.9157 - val_loss: 0.2812 - val_accuracy: 0.9014\n",
            "Epoch 257/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2231 - accuracy: 0.9148\n",
            "Epoch 257: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2230 - accuracy: 0.9148 - val_loss: 0.2715 - val_accuracy: 0.9054\n",
            "Epoch 258/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2218 - accuracy: 0.9151\n",
            "Epoch 258: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2220 - accuracy: 0.9151 - val_loss: 0.2715 - val_accuracy: 0.9046\n",
            "Epoch 259/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2226 - accuracy: 0.9154\n",
            "Epoch 259: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2227 - accuracy: 0.9153 - val_loss: 0.2825 - val_accuracy: 0.9009\n",
            "Epoch 260/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2210 - accuracy: 0.9148\n",
            "Epoch 260: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2215 - accuracy: 0.9146 - val_loss: 0.2725 - val_accuracy: 0.9043\n",
            "Epoch 261/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2227 - accuracy: 0.9148\n",
            "Epoch 261: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2228 - accuracy: 0.9149 - val_loss: 0.2728 - val_accuracy: 0.9042\n",
            "Epoch 262/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2209 - accuracy: 0.9150\n",
            "Epoch 262: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2210 - accuracy: 0.9149 - val_loss: 0.2719 - val_accuracy: 0.9043\n",
            "Epoch 263/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2222 - accuracy: 0.9147\n",
            "Epoch 263: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2222 - accuracy: 0.9147 - val_loss: 0.2757 - val_accuracy: 0.9026\n",
            "Epoch 264/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2213 - accuracy: 0.9158\n",
            "Epoch 264: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2211 - accuracy: 0.9159 - val_loss: 0.2762 - val_accuracy: 0.9040\n",
            "Epoch 265/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.9152\n",
            "Epoch 265: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2218 - accuracy: 0.9152 - val_loss: 0.2696 - val_accuracy: 0.9045\n",
            "Epoch 266/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.9156\n",
            "Epoch 266: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2198 - accuracy: 0.9157 - val_loss: 0.2756 - val_accuracy: 0.9034\n",
            "Epoch 267/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2221 - accuracy: 0.9135\n",
            "Epoch 267: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2216 - accuracy: 0.9137 - val_loss: 0.2754 - val_accuracy: 0.9022\n",
            "Epoch 268/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2202 - accuracy: 0.9165\n",
            "Epoch 268: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2203 - accuracy: 0.9164 - val_loss: 0.2734 - val_accuracy: 0.9037\n",
            "Epoch 269/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9155\n",
            "Epoch 269: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2218 - accuracy: 0.9152 - val_loss: 0.2687 - val_accuracy: 0.9035\n",
            "Epoch 270/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.9160\n",
            "Epoch 270: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2211 - accuracy: 0.9160 - val_loss: 0.2760 - val_accuracy: 0.9019\n",
            "Epoch 271/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2188 - accuracy: 0.9152\n",
            "Epoch 271: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2182 - accuracy: 0.9154 - val_loss: 0.2717 - val_accuracy: 0.9021\n",
            "Epoch 272/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2206 - accuracy: 0.9147\n",
            "Epoch 272: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2209 - accuracy: 0.9146 - val_loss: 0.2743 - val_accuracy: 0.9019\n",
            "Epoch 273/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9168\n",
            "Epoch 273: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2176 - accuracy: 0.9167 - val_loss: 0.2733 - val_accuracy: 0.9022\n",
            "Epoch 274/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9158\n",
            "Epoch 274: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2205 - accuracy: 0.9155 - val_loss: 0.2749 - val_accuracy: 0.9043\n",
            "Epoch 275/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2202 - accuracy: 0.9149\n",
            "Epoch 275: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2206 - accuracy: 0.9149 - val_loss: 0.2742 - val_accuracy: 0.9045\n",
            "Epoch 276/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.9158\n",
            "Epoch 276: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2176 - accuracy: 0.9158 - val_loss: 0.2703 - val_accuracy: 0.9041\n",
            "Epoch 277/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9153\n",
            "Epoch 277: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2197 - accuracy: 0.9154 - val_loss: 0.2655 - val_accuracy: 0.9046\n",
            "Epoch 278/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9155\n",
            "Epoch 278: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2172 - accuracy: 0.9154 - val_loss: 0.2840 - val_accuracy: 0.8991\n",
            "Epoch 279/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2200 - accuracy: 0.9172\n",
            "Epoch 279: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2203 - accuracy: 0.9172 - val_loss: 0.2793 - val_accuracy: 0.9019\n",
            "Epoch 280/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9156\n",
            "Epoch 280: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2199 - accuracy: 0.9156 - val_loss: 0.2727 - val_accuracy: 0.9050\n",
            "Epoch 281/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9160\n",
            "Epoch 281: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2188 - accuracy: 0.9160 - val_loss: 0.2772 - val_accuracy: 0.9026\n",
            "Epoch 282/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9158\n",
            "Epoch 282: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2192 - accuracy: 0.9157 - val_loss: 0.2696 - val_accuracy: 0.9049\n",
            "Epoch 283/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.9158\n",
            "Epoch 283: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2193 - accuracy: 0.9158 - val_loss: 0.2761 - val_accuracy: 0.9033\n",
            "Epoch 284/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2186 - accuracy: 0.9159\n",
            "Epoch 284: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2184 - accuracy: 0.9159 - val_loss: 0.2727 - val_accuracy: 0.9045\n",
            "Epoch 285/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9151\n",
            "Epoch 285: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2207 - accuracy: 0.9153 - val_loss: 0.2716 - val_accuracy: 0.9052\n",
            "Epoch 286/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9173\n",
            "Epoch 286: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2158 - accuracy: 0.9174 - val_loss: 0.2730 - val_accuracy: 0.9046\n",
            "Epoch 287/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.9157\n",
            "Epoch 287: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2193 - accuracy: 0.9157 - val_loss: 0.2766 - val_accuracy: 0.9050\n",
            "Epoch 288/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2184 - accuracy: 0.9163\n",
            "Epoch 288: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2187 - accuracy: 0.9162 - val_loss: 0.2781 - val_accuracy: 0.9032\n",
            "Epoch 289/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2145 - accuracy: 0.9171\n",
            "Epoch 289: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2146 - accuracy: 0.9171 - val_loss: 0.2747 - val_accuracy: 0.9029\n",
            "Epoch 290/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2180 - accuracy: 0.9162\n",
            "Epoch 290: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2181 - accuracy: 0.9161 - val_loss: 0.2732 - val_accuracy: 0.9033\n",
            "Epoch 291/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.9158\n",
            "Epoch 291: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2202 - accuracy: 0.9158 - val_loss: 0.2756 - val_accuracy: 0.8997\n",
            "Epoch 292/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9164\n",
            "Epoch 292: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2170 - accuracy: 0.9164 - val_loss: 0.2788 - val_accuracy: 0.9025\n",
            "Epoch 293/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2179 - accuracy: 0.9159\n",
            "Epoch 293: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2180 - accuracy: 0.9158 - val_loss: 0.2766 - val_accuracy: 0.9017\n",
            "Epoch 294/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.9158\n",
            "Epoch 294: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2191 - accuracy: 0.9158 - val_loss: 0.2721 - val_accuracy: 0.9050\n",
            "Epoch 295/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.9172\n",
            "Epoch 295: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2169 - accuracy: 0.9172 - val_loss: 0.2751 - val_accuracy: 0.9031\n",
            "Epoch 296/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2173 - accuracy: 0.9170\n",
            "Epoch 296: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2176 - accuracy: 0.9168 - val_loss: 0.2832 - val_accuracy: 0.9015\n",
            "Epoch 297/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9162\n",
            "Epoch 297: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2175 - accuracy: 0.9162 - val_loss: 0.2774 - val_accuracy: 0.9019\n",
            "Epoch 298/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2175 - accuracy: 0.9162\n",
            "Epoch 298: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2175 - accuracy: 0.9163 - val_loss: 0.2773 - val_accuracy: 0.9009\n",
            "Epoch 299/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9170\n",
            "Epoch 299: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2171 - accuracy: 0.9167 - val_loss: 0.2789 - val_accuracy: 0.9031\n",
            "Epoch 300/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2138 - accuracy: 0.9189\n",
            "Epoch 300: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2138 - accuracy: 0.9189 - val_loss: 0.2762 - val_accuracy: 0.9035\n",
            "Epoch 301/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2143 - accuracy: 0.9182\n",
            "Epoch 301: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2140 - accuracy: 0.9183 - val_loss: 0.2730 - val_accuracy: 0.9033\n",
            "Epoch 302/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9166\n",
            "Epoch 302: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2168 - accuracy: 0.9165 - val_loss: 0.2772 - val_accuracy: 0.9009\n",
            "Epoch 303/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2139 - accuracy: 0.9196\n",
            "Epoch 303: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2143 - accuracy: 0.9194 - val_loss: 0.2792 - val_accuracy: 0.9013\n",
            "Epoch 304/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2173 - accuracy: 0.9163\n",
            "Epoch 304: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2174 - accuracy: 0.9163 - val_loss: 0.2768 - val_accuracy: 0.9021\n",
            "Epoch 305/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2147 - accuracy: 0.9182\n",
            "Epoch 305: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2147 - accuracy: 0.9181 - val_loss: 0.2753 - val_accuracy: 0.9018\n",
            "Epoch 306/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2151 - accuracy: 0.9162\n",
            "Epoch 306: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2151 - accuracy: 0.9162 - val_loss: 0.2731 - val_accuracy: 0.9049\n",
            "Epoch 307/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9184\n",
            "Epoch 307: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2134 - accuracy: 0.9185 - val_loss: 0.2745 - val_accuracy: 0.9035\n",
            "Epoch 308/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9165\n",
            "Epoch 308: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2165 - accuracy: 0.9166 - val_loss: 0.2740 - val_accuracy: 0.9036\n",
            "Epoch 309/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9173\n",
            "Epoch 309: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2158 - accuracy: 0.9174 - val_loss: 0.2751 - val_accuracy: 0.9056\n",
            "Epoch 310/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.9181\n",
            "Epoch 310: val_accuracy did not improve from 0.90580\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2165 - accuracy: 0.9181 - val_loss: 0.2727 - val_accuracy: 0.9030\n",
            "Epoch 311/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9147\n",
            "Epoch 311: val_accuracy improved from 0.90580 to 0.90610, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2186 - accuracy: 0.9145 - val_loss: 0.2705 - val_accuracy: 0.9061\n",
            "Epoch 312/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2153 - accuracy: 0.9187\n",
            "Epoch 312: val_accuracy did not improve from 0.90610\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2152 - accuracy: 0.9187 - val_loss: 0.2699 - val_accuracy: 0.9054\n",
            "Epoch 313/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2131 - accuracy: 0.9191\n",
            "Epoch 313: val_accuracy did not improve from 0.90610\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2131 - accuracy: 0.9191 - val_loss: 0.2748 - val_accuracy: 0.9027\n",
            "Epoch 314/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9170\n",
            "Epoch 314: val_accuracy did not improve from 0.90610\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2162 - accuracy: 0.9170 - val_loss: 0.2750 - val_accuracy: 0.9004\n",
            "Epoch 315/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9167\n",
            "Epoch 315: val_accuracy did not improve from 0.90610\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2181 - accuracy: 0.9169 - val_loss: 0.2769 - val_accuracy: 0.9024\n",
            "Epoch 316/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9163\n",
            "Epoch 316: val_accuracy did not improve from 0.90610\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2171 - accuracy: 0.9163 - val_loss: 0.2697 - val_accuracy: 0.9058\n",
            "Epoch 317/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2126 - accuracy: 0.9187\n",
            "Epoch 317: val_accuracy did not improve from 0.90610\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2132 - accuracy: 0.9186 - val_loss: 0.2727 - val_accuracy: 0.9041\n",
            "Epoch 318/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9176\n",
            "Epoch 318: val_accuracy did not improve from 0.90610\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2138 - accuracy: 0.9175 - val_loss: 0.2685 - val_accuracy: 0.9051\n",
            "Epoch 319/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2132 - accuracy: 0.9175\n",
            "Epoch 319: val_accuracy did not improve from 0.90610\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2131 - accuracy: 0.9175 - val_loss: 0.2744 - val_accuracy: 0.9021\n",
            "Epoch 320/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9174\n",
            "Epoch 320: val_accuracy did not improve from 0.90610\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2175 - accuracy: 0.9169 - val_loss: 0.2757 - val_accuracy: 0.9042\n",
            "Epoch 321/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2127 - accuracy: 0.9179\n",
            "Epoch 321: val_accuracy did not improve from 0.90610\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2129 - accuracy: 0.9179 - val_loss: 0.2774 - val_accuracy: 0.9040\n",
            "Epoch 322/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2140 - accuracy: 0.9172\n",
            "Epoch 322: val_accuracy did not improve from 0.90610\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2142 - accuracy: 0.9173 - val_loss: 0.2787 - val_accuracy: 0.9040\n",
            "Epoch 323/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9166\n",
            "Epoch 323: val_accuracy improved from 0.90610 to 0.90630, saving model to best_model.h5\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2168 - accuracy: 0.9165 - val_loss: 0.2709 - val_accuracy: 0.9063\n",
            "Epoch 324/1000\n",
            "382/391 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9173\n",
            "Epoch 324: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2161 - accuracy: 0.9174 - val_loss: 0.2711 - val_accuracy: 0.9059\n",
            "Epoch 325/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2148 - accuracy: 0.9189\n",
            "Epoch 325: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2150 - accuracy: 0.9188 - val_loss: 0.2751 - val_accuracy: 0.9046\n",
            "Epoch 326/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2120 - accuracy: 0.9188\n",
            "Epoch 326: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2123 - accuracy: 0.9185 - val_loss: 0.2802 - val_accuracy: 0.9029\n",
            "Epoch 327/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2166 - accuracy: 0.9163\n",
            "Epoch 327: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2165 - accuracy: 0.9163 - val_loss: 0.2746 - val_accuracy: 0.9057\n",
            "Epoch 328/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2125 - accuracy: 0.9179\n",
            "Epoch 328: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2125 - accuracy: 0.9178 - val_loss: 0.2712 - val_accuracy: 0.9042\n",
            "Epoch 329/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2134 - accuracy: 0.9178\n",
            "Epoch 329: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2135 - accuracy: 0.9177 - val_loss: 0.2764 - val_accuracy: 0.9038\n",
            "Epoch 330/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2157 - accuracy: 0.9174\n",
            "Epoch 330: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2156 - accuracy: 0.9174 - val_loss: 0.2780 - val_accuracy: 0.9014\n",
            "Epoch 331/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2122 - accuracy: 0.9182\n",
            "Epoch 331: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2122 - accuracy: 0.9182 - val_loss: 0.2758 - val_accuracy: 0.9029\n",
            "Epoch 332/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2127 - accuracy: 0.9186\n",
            "Epoch 332: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2127 - accuracy: 0.9186 - val_loss: 0.2708 - val_accuracy: 0.9062\n",
            "Epoch 333/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2132 - accuracy: 0.9182\n",
            "Epoch 333: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2131 - accuracy: 0.9183 - val_loss: 0.2759 - val_accuracy: 0.9020\n",
            "Epoch 334/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2127 - accuracy: 0.9197\n",
            "Epoch 334: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2130 - accuracy: 0.9197 - val_loss: 0.2767 - val_accuracy: 0.9043\n",
            "Epoch 335/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2096 - accuracy: 0.9200\n",
            "Epoch 335: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2100 - accuracy: 0.9200 - val_loss: 0.2783 - val_accuracy: 0.9020\n",
            "Epoch 336/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9180\n",
            "Epoch 336: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2141 - accuracy: 0.9180 - val_loss: 0.2769 - val_accuracy: 0.9041\n",
            "Epoch 337/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9176\n",
            "Epoch 337: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2141 - accuracy: 0.9174 - val_loss: 0.2738 - val_accuracy: 0.9045\n",
            "Epoch 338/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2127 - accuracy: 0.9184\n",
            "Epoch 338: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2127 - accuracy: 0.9183 - val_loss: 0.2772 - val_accuracy: 0.9055\n",
            "Epoch 339/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2134 - accuracy: 0.9184\n",
            "Epoch 339: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2133 - accuracy: 0.9184 - val_loss: 0.2794 - val_accuracy: 0.9026\n",
            "Epoch 340/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2143 - accuracy: 0.9176\n",
            "Epoch 340: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2138 - accuracy: 0.9180 - val_loss: 0.2774 - val_accuracy: 0.9018\n",
            "Epoch 341/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2150 - accuracy: 0.9186\n",
            "Epoch 341: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2149 - accuracy: 0.9186 - val_loss: 0.2759 - val_accuracy: 0.9011\n",
            "Epoch 342/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2138 - accuracy: 0.9187\n",
            "Epoch 342: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2139 - accuracy: 0.9186 - val_loss: 0.2750 - val_accuracy: 0.9042\n",
            "Epoch 343/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9191\n",
            "Epoch 343: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2093 - accuracy: 0.9190 - val_loss: 0.2760 - val_accuracy: 0.9018\n",
            "Epoch 344/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2084 - accuracy: 0.9210\n",
            "Epoch 344: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2084 - accuracy: 0.9210 - val_loss: 0.2759 - val_accuracy: 0.9054\n",
            "Epoch 345/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9175\n",
            "Epoch 345: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2134 - accuracy: 0.9176 - val_loss: 0.2729 - val_accuracy: 0.9049\n",
            "Epoch 346/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2119 - accuracy: 0.9180\n",
            "Epoch 346: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2124 - accuracy: 0.9178 - val_loss: 0.2730 - val_accuracy: 0.9051\n",
            "Epoch 347/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.9178\n",
            "Epoch 347: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2115 - accuracy: 0.9178 - val_loss: 0.2776 - val_accuracy: 0.9029\n",
            "Epoch 348/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2108 - accuracy: 0.9201\n",
            "Epoch 348: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2110 - accuracy: 0.9200 - val_loss: 0.2728 - val_accuracy: 0.9026\n",
            "Epoch 349/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2152 - accuracy: 0.9186\n",
            "Epoch 349: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2150 - accuracy: 0.9187 - val_loss: 0.2756 - val_accuracy: 0.9030\n",
            "Epoch 350/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.9188\n",
            "Epoch 350: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2125 - accuracy: 0.9188 - val_loss: 0.2756 - val_accuracy: 0.9020\n",
            "Epoch 351/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2084 - accuracy: 0.9204\n",
            "Epoch 351: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2091 - accuracy: 0.9203 - val_loss: 0.2721 - val_accuracy: 0.9041\n",
            "Epoch 352/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2106 - accuracy: 0.9194\n",
            "Epoch 352: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2107 - accuracy: 0.9193 - val_loss: 0.2806 - val_accuracy: 0.9017\n",
            "Epoch 353/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2091 - accuracy: 0.9199\n",
            "Epoch 353: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2088 - accuracy: 0.9203 - val_loss: 0.2728 - val_accuracy: 0.9059\n",
            "Epoch 354/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2130 - accuracy: 0.9184\n",
            "Epoch 354: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2130 - accuracy: 0.9183 - val_loss: 0.2732 - val_accuracy: 0.9023\n",
            "Epoch 355/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9208\n",
            "Epoch 355: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2091 - accuracy: 0.9208 - val_loss: 0.2721 - val_accuracy: 0.9028\n",
            "Epoch 356/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.9191\n",
            "Epoch 356: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2095 - accuracy: 0.9191 - val_loss: 0.2752 - val_accuracy: 0.9034\n",
            "Epoch 357/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.9195\n",
            "Epoch 357: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2095 - accuracy: 0.9195 - val_loss: 0.2746 - val_accuracy: 0.9044\n",
            "Epoch 358/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9198\n",
            "Epoch 358: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2104 - accuracy: 0.9198 - val_loss: 0.2752 - val_accuracy: 0.9020\n",
            "Epoch 359/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2086 - accuracy: 0.9194\n",
            "Epoch 359: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2089 - accuracy: 0.9193 - val_loss: 0.2793 - val_accuracy: 0.9035\n",
            "Epoch 360/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2132 - accuracy: 0.9187\n",
            "Epoch 360: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2132 - accuracy: 0.9186 - val_loss: 0.2812 - val_accuracy: 0.9005\n",
            "Epoch 361/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2129 - accuracy: 0.9182\n",
            "Epoch 361: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2126 - accuracy: 0.9184 - val_loss: 0.2727 - val_accuracy: 0.9057\n",
            "Epoch 362/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2107 - accuracy: 0.9197\n",
            "Epoch 362: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2107 - accuracy: 0.9197 - val_loss: 0.2733 - val_accuracy: 0.9034\n",
            "Epoch 363/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2086 - accuracy: 0.9197\n",
            "Epoch 363: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2085 - accuracy: 0.9197 - val_loss: 0.2753 - val_accuracy: 0.9029\n",
            "Epoch 364/1000\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.2120 - accuracy: 0.9196\n",
            "Epoch 364: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2119 - accuracy: 0.9196 - val_loss: 0.2728 - val_accuracy: 0.9031\n",
            "Epoch 365/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2131 - accuracy: 0.9186\n",
            "Epoch 365: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2131 - accuracy: 0.9186 - val_loss: 0.2732 - val_accuracy: 0.9043\n",
            "Epoch 366/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2108 - accuracy: 0.9202\n",
            "Epoch 366: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2112 - accuracy: 0.9201 - val_loss: 0.2749 - val_accuracy: 0.9036\n",
            "Epoch 367/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2084 - accuracy: 0.9192\n",
            "Epoch 367: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2089 - accuracy: 0.9191 - val_loss: 0.2748 - val_accuracy: 0.9059\n",
            "Epoch 368/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.9179\n",
            "Epoch 368: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2115 - accuracy: 0.9179 - val_loss: 0.2765 - val_accuracy: 0.9033\n",
            "Epoch 369/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9185\n",
            "Epoch 369: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2117 - accuracy: 0.9185 - val_loss: 0.2733 - val_accuracy: 0.9046\n",
            "Epoch 370/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.9179\n",
            "Epoch 370: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2104 - accuracy: 0.9179 - val_loss: 0.2708 - val_accuracy: 0.9033\n",
            "Epoch 371/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.9197\n",
            "Epoch 371: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2099 - accuracy: 0.9197 - val_loss: 0.2748 - val_accuracy: 0.9039\n",
            "Epoch 372/1000\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.2122 - accuracy: 0.9182\n",
            "Epoch 372: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2121 - accuracy: 0.9182 - val_loss: 0.2729 - val_accuracy: 0.9060\n",
            "Epoch 373/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2097 - accuracy: 0.9192\n",
            "Epoch 373: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2095 - accuracy: 0.9192 - val_loss: 0.2696 - val_accuracy: 0.9063\n",
            "Epoch 374/1000\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.2065 - accuracy: 0.9193\n",
            "Epoch 374: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2066 - accuracy: 0.9192 - val_loss: 0.2742 - val_accuracy: 0.9056\n",
            "Epoch 375/1000\n",
            "384/391 [============================>.] - ETA: 0s - loss: 0.2106 - accuracy: 0.9195\n",
            "Epoch 375: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2106 - accuracy: 0.9195 - val_loss: 0.2732 - val_accuracy: 0.9049\n",
            "Epoch 376/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2080 - accuracy: 0.9204\n",
            "Epoch 376: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2081 - accuracy: 0.9203 - val_loss: 0.2750 - val_accuracy: 0.9016\n",
            "Epoch 377/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2077 - accuracy: 0.9209\n",
            "Epoch 377: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2075 - accuracy: 0.9210 - val_loss: 0.2716 - val_accuracy: 0.9044\n",
            "Epoch 378/1000\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2083 - accuracy: 0.9203\n",
            "Epoch 378: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2082 - accuracy: 0.9204 - val_loss: 0.2776 - val_accuracy: 0.9042\n",
            "Epoch 379/1000\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2061 - accuracy: 0.9223\n",
            "Epoch 379: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2066 - accuracy: 0.9221 - val_loss: 0.2758 - val_accuracy: 0.9036\n",
            "Epoch 380/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.9195\n",
            "Epoch 380: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2112 - accuracy: 0.9195 - val_loss: 0.2766 - val_accuracy: 0.9033\n",
            "Epoch 381/1000\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.2085 - accuracy: 0.9215\n",
            "Epoch 381: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2084 - accuracy: 0.9215 - val_loss: 0.2722 - val_accuracy: 0.9057\n",
            "Epoch 382/1000\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.9197\n",
            "Epoch 382: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2082 - accuracy: 0.9197 - val_loss: 0.2758 - val_accuracy: 0.9045\n",
            "Epoch 383/1000\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2091 - accuracy: 0.9196\n",
            "Epoch 383: val_accuracy did not improve from 0.90630\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2093 - accuracy: 0.9195 - val_loss: 0.2717 - val_accuracy: 0.9062\n",
            "Epoch 383: early stopping\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2975 - accuracy: 0.8970\n",
            "\n",
            "Test accuracy: 0.8970000147819519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nhistory dict:', list(history.history.keys()))"
      ],
      "metadata": {
        "id": "CxRE-B_Q6Sii",
        "outputId": "bad2ee87-94da-4a40-dc02-c130657ba2ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "history dict: ['loss', 'accuracy', 'val_loss', 'val_accuracy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.evaluate(x_test, y_test)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "YXpwRRTvTBNg",
        "outputId": "d49ac708-b727-4b7f-b7f7-0dda59c94e62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2975 - accuracy: 0.8970\n",
            "[0.2975074350833893, 0.8970000147819519]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['loss']) + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.clf()\n",
        "plt.figure(figsize=(10, 5))\n",
        "val_acc_values = history_dict['accuracy']\n",
        "plt.plot(epochs, history_dict['accuracy'], 'bo', label='Training acc')\n",
        "plt.plot(epochs, history_dict['val_accuracy'], 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "2Ll_5sGlXKMH",
        "outputId": "f428555d-4c71-4511-e980-43bb113852e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2AAAAHWCAYAAAARnurlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACXw0lEQVR4nOzdd3hTVR8H8G+abtoySildtCwZMmXJKCBbEMECsmSp8KogFEQBZSugiMgQwcFURgUqLkCGLGXKFpCNQCmjZZSWzuS8fxxu0jRpm7Tp7eD7eZ48Te449+TkJr2/e5ZGCCFAREREREREec4hvzNARERERET0pGAARkREREREpBIGYERERERERCphAEZERERERKQSBmBEREREREQqYQBGRERERESkEgZgREREREREKmEARkREREREpBIGYERERERERCphAEZEpKKBAwciJCQkR/tOnjwZGo3GvhkqYK5cuQKNRoNly5apetydO3dCo9Fg586dhmXWflZ5leeQkBAMHDjQrmkSEVH+YwBGRARAo9FY9Uh/gU6UW3v37sXkyZNx//79/M4KERGpxDG/M0BEVBB89913Jq9XrFiBrVu3mi2vVq1aro7zzTffQK/X52jf8ePHY+zYsbk6PlkvN5+Vtfbu3YspU6Zg4MCBKFGihMm6s2fPwsGB90mJiIoaBmBERABeeeUVk9f79+/H1q1bzZZn9OjRI7i7u1t9HCcnpxzlDwAcHR3h6MifbbXk5rOyBxcXl3w9fmGRkJCAYsWK5Xc2iIisxltrRERWatmyJWrUqIHDhw+jefPmcHd3x/vvvw8A+Omnn9CpUyf4+/vDxcUFFStWxIcffgidTmeSRsZ+RUr/oVmzZuHrr79GxYoV4eLiggYNGuDQoUMm+1rqA6bRaDBs2DBs2LABNWrUgIuLC55++mls3rzZLP87d+5E/fr14erqiooVK+Krr76yul/Znj170KNHD5QrVw4uLi4ICgrCyJEjkZiYaPb+PDw8EBUVha5du8LDwwM+Pj4YPXq0WVncv38fAwcORPHixVGiRAkMGDDAqqZ4f//9NzQaDZYvX2627vfff4dGo8Gvv/4KAPjvv//w1ltvoUqVKnBzc4O3tzd69OiBK1euZHscS33ArM3ziRMnMHDgQFSoUAGurq4oW7YsXn31VcTGxhq2mTx5Mt59910AQPny5Q3NXJW8WeoDdunSJfTo0QOlSpWCu7s7nn32Wfz2228m2yj92X744QdMmzYNgYGBcHV1RevWrXHhwoVs37ctZXb//n2MHDkSISEhcHFxQWBgIPr374+YmBjDNklJSZg8eTKeeuopuLq6ws/PD2FhYbh48aJJfjM277XUt045vy5evIiOHTvC09MTffv2BWD9OQoA//77L15++WX4+PjAzc0NVapUwQcffAAA2LFjBzQaDX788Uez/VatWgWNRoN9+/ZlW45ERJnhrVQiIhvExsbi+eefR69evfDKK6/A19cXALBs2TJ4eHhg1KhR8PDwwB9//IGJEyciLi4On376abbprlq1Cg8fPsT//vc/aDQazJw5E2FhYbh06VK2NTF//vknIiMj8dZbb8HT0xPz5s1Dt27dcPXqVXh7ewMAjh49ig4dOsDPzw9TpkyBTqfD1KlT4ePjY9X7Xrt2LR49eoQ333wT3t7eOHjwIObPn4/r169j7dq1JtvqdDq0b98ejRo1wqxZs7Bt2zZ89tlnqFixIt58800AgBACXbp0wZ9//ok33ngD1apVw48//ogBAwZkm5f69eujQoUK+OGHH8y2j4iIQMmSJdG+fXsAwKFDh7B371706tULgYGBuHLlChYuXIiWLVvi9OnTNtVe2pLnrVu34tKlSxg0aBDKli2LU6dO4euvv8apU6ewf/9+aDQahIWF4dy5c1i9ejU+//xzlC5dGgAy/Uxu3bqFJk2a4NGjRxg+fDi8vb2xfPlyvPjii1i3bh1eeuklk+0//vhjODg4YPTo0Xjw4AFmzpyJvn374sCBA1m+T2vLLD4+HqGhoThz5gxeffVVPPPMM4iJicHPP/+M69evo3Tp0tDpdHjhhRewfft29OrVCyNGjMDDhw+xdetW/PPPP6hYsaLV5a9IS0tD+/bt0axZM8yaNcuQH2vP0RMnTiA0NBROTk4YMmQIQkJCcPHiRfzyyy+YNm0aWrZsiaCgIKxcudKsTFeuXImKFSuicePGNuebiMhAEBGRmaFDh4qMP5EtWrQQAMSiRYvMtn/06JHZsv/973/C3d1dJCUlGZYNGDBABAcHG15fvnxZABDe3t7i7t27huU//fSTACB++eUXw7JJkyaZ5QmAcHZ2FhcuXDAsO378uAAg5s+fb1jWuXNn4e7uLqKiogzLzp8/LxwdHc3StMTS+5sxY4bQaDTiv//+M3l/AMTUqVNNtq1bt66oV6+e4fWGDRsEADFz5kzDsrS0NBEaGioAiKVLl2aZn3HjxgknJyeTMktOThYlSpQQr776apb53rdvnwAgVqxYYVi2Y8cOAUDs2LHD5L2k/6xsybOl465evVoAELt37zYs+/TTTwUAcfnyZbPtg4ODxYABAwyvw8PDBQCxZ88ew7KHDx+K8uXLi5CQEKHT6UzeS7Vq1URycrJh27lz5woA4uTJk2bHSs/aMps4caIAICIjI8221+v1QgghlixZIgCI2bNnZ7qNpbIXwvjdSF+uyvk1duxYq/Jt6Rxt3ry58PT0NFmWPj9CyPPLxcVF3L9/37Ds9u3bwtHRUUyaNMnsOEREtmATRCIiG7i4uGDQoEFmy93c3AzPHz58iJiYGISGhuLRo0f4999/s023Z8+eKFmypOF1aGgoANnkLDtt2rQxqUmoVasWvLy8DPvqdDps27YNXbt2hb+/v2G7SpUq4fnnn882fcD0/SUkJCAmJgZNmjSBEAJHjx412/6NN94weR0aGmryXjZu3AhHR0dDjRgAaLVavP3221blp2fPnkhNTUVkZKRh2ZYtW3D//n307NnTYr5TU1MRGxuLSpUqoUSJEjhy5IhVx8pJntMfNykpCTExMXj22WcBwObjpj9+w4YN0axZM8MyDw8PDBkyBFeuXMHp06dNth80aBCcnZ0Nr609p6wts/Xr16N27dpmtUQADM1a169fj9KlS1sso9xMqZD+M7CU78zO0Tt37mD37t149dVXUa5cuUzz079/fyQnJ2PdunWGZREREUhLS8u2XygRUXYYgBER2SAgIMDkolZx6tQpvPTSSyhevDi8vLzg4+NjuFB78OBBtulmvBhUgrF79+7ZvK+yv7Lv7du3kZiYiEqVKpltZ2mZJVevXsXAgQNRqlQpQ7+uFi1aADB/f66urmbN6NLnB5D9jPz8/ODh4WGyXZUqVazKT+3atVG1alVEREQYlkVERKB06dJo1aqVYVliYiImTpyIoKAguLi4oHTp0vDx8cH9+/et+lzSsyXPd+/exYgRI+Dr6ws3Nzf4+PigfPnyAKw7HzI7vqVjKSNz/vfffybLc3pOWVtmFy9eRI0aNbJM6+LFi6hSpYpdB49xdHREYGCg2XJrzlEl+Mwu31WrVkWDBg2wcuVKw7KVK1fi2Weftfo7Q0SUGfYBIyKyQfq77Ir79++jRYsW8PLywtSpU1GxYkW4urriyJEjGDNmjFVDmWu1WovLhRB5uq81dDod2rZti7t372LMmDGoWrUqihUrhqioKAwcONDs/WWWH3vr2bMnpk2bhpiYGHh6euLnn39G7969TS723377bSxduhTh4eFo3LgxihcvDo1Gg169euXpEPMvv/wy9u7di3fffRd16tSBh4cH9Ho9OnTokOdD2ytyel6oXWaZ1YRlHLRF4eLiYjY8v63nqDX69++PESNG4Pr160hOTsb+/fvxxRdf2JwOEVFGDMCIiHJp586diI2NRWRkJJo3b25Yfvny5XzMlVGZMmXg6upqcQQ8a0bFO3nyJM6dO4fly5ejf//+huVbt27NcZ6Cg4Oxfft2xMfHm9QonT171uo0evbsiSlTpmD9+vXw9fVFXFwcevXqZbLNunXrMGDAAHz22WeGZUlJSTma+NjaPN+7dw/bt2/HlClTMHHiRMPy8+fPm6VpSzO84OBgi+WjNHENDg62Oq2sWFtmFStWxD///JNlWhUrVsSBAweQmpqa6WAySs1cxvQz1uhlxdpztEKFCgCQbb4BoFevXhg1ahRWr16NxMREODk5mTRvJSLKKTZBJCLKJaWmIX3NQkpKCr788sv8ypIJrVaLNm3aYMOGDbhx44Zh+YULF7Bp0yar9gdM358QAnPnzs1xnjp27Ii0tDQsXLjQsEyn02H+/PlWp1GtWjXUrFkTERERiIiIgJ+fn0kArOQ9Y43P/PnzM61dsUeeLZUXAMyZM8csTWX+KmsCwo4dO+LgwYMmQ6AnJCTg66+/RkhICKpXr27tW8mStWXWrVs3HD9+3OJw7cr+3bp1Q0xMjMWaI2Wb4OBgaLVa7N6922S9Ld8fa89RHx8fNG/eHEuWLMHVq1ct5kdRunRpPP/88/j++++xcuVKdOjQwTBSJRFRbrAGjIgol5o0aYKSJUtiwIABGD58ODQaDb777ju7NQG0h8mTJ2PLli1o2rQp3nzzTeh0OnzxxReoUaMGjh07luW+VatWRcWKFTF69GhERUXBy8sL69evt6p/WmY6d+6Mpk2bYuzYsbhy5QqqV6+OyMhIm/tH9ezZExMnToSrqytee+01s6ZpL7zwAr777jsUL14c1atXx759+7Bt2zbD8Px5kWcvLy80b94cM2fORGpqKgICArBlyxaLNaL16tUDAHzwwQfo1asXnJyc0LlzZ4sTC48dOxarV6/G888/j+HDh6NUqVJYvnw5Ll++jPXr15u995yytszeffddrFu3Dj169MCrr76KevXq4e7du/j555+xaNEi1K5dG/3798eKFSswatQoHDx4EKGhoUhISMC2bdvw1ltvoUuXLihevDh69OiB+fPnQ6PRoGLFivj1119x+/Ztq/Nsyzk6b948NGvWDM888wyGDBmC8uXL48qVK/jtt9/Mvgv9+/dH9+7dAQAffvih7YVJRGQBAzAiolzy9vbGr7/+infeeQfjx49HyZIl8corr6B169aG+ajyW7169bBp0yaMHj0aEyZMQFBQEKZOnYozZ85kO0qjk5MTfvnlFwwfPhwzZsyAq6srXnrpJQwbNgy1a9fOUX4cHBzw888/Izw8HN9//z00Gg1efPFFfPbZZ6hbt67V6fTs2RPjx4/Ho0ePLDYPmzt3LrRaLVauXImkpCQ0bdoU27Zty9HnYkueV61ahbfffhsLFiyAEALt2rXDpk2bTEahBIAGDRrgww8/xKJFi7B582bo9XpcvnzZYgDm6+uLvXv3YsyYMZg/fz6SkpJQq1Yt/PLLL+jUqZPN7ycz1paZh4cH9uzZg0mTJuHHH3/E8uXLUaZMGbRu3dowSIZWq8XGjRsxbdo0rFq1CuvXr4e3tzeaNWuGmjVrGtKaP38+UlNTsWjRIri4uODll1/Gp59+mu1gGQpbztHatWtj//79mDBhAhYuXIikpCQEBwfj5ZdfNku3c+fOKFmyJPR6PV588UVbi5KIyCKNKEi3aImISFVdu3bFqVOnLPZPInrSpaWlwd/fH507d8bixYvzOztEVESwDxgR0RMiMTHR5PX58+exceNGtGzZMn8yRFTAbdiwAXfu3DEZ2IOIKLdYA0ZE9ITw8/PDwIEDUaFCBfz3339YuHAhkpOTcfToUVSuXDm/s0dUYBw4cAAnTpzAhx9+iNKlS+d48mwiIkvYB4yI6AnRoUMHrF69Gjdv3oSLiwsaN26M6dOnM/giymDhwoX4/vvvUadOHSxbtiy/s0NERQxrwIiIiIiIiFTCPmBEREREREQqYQBGRERERESkEvYBs0Cv1+PGjRvw9PSERqPJ7+wQEREREVE+EULg4cOH8Pf3t8uk9wzALLhx4waCgoLyOxtERERERFRAXLt2zTDRfG4wALPA09MTgCxkLy+vfMlDamoqtmzZgnbt2sHJySlf8vCkYZmri+WtLpa3ulje6mOZq4vlrS6Wt7oylndcXByCgoIMMUJuMQCzQGl26OXlla8BmLu7O7y8vPhFUwnLXF0sb3WxvNXF8lYfy1xdLG91sbzVlVl526trEgfhICIiIiIiUgkDMCIiIiIiIpUwACMiIiIiIlIJ+4DlkBACaWlp0Ol0eZJ+amoqHB0dkZSUlGfHIFNqlrlWq4WjoyOnOSAiIiJ6wjAAy4GUlBRER0fj0aNHeXYMIQTKli2La9eu8SJdJWqXubu7O/z8/ODs7JznxyIiIiKigoEBmI30ej0uX74MrVYLf39/ODs758nFul6vR3x8PDw8POwy4RtlT60yF0IgJSUFd+7cweXLl1G5cmV+xkRERERPCAZgNkpJSYFer0dQUBDc3d3z7Dh6vR4pKSlwdXXlxblK1CxzNzc3ODk54b///jMck4iIiIiKPl7Z5xCDIsotnkNERERETx5eARIREREREamETRCJiIiIiEg1Oh2wZw8QHQ34+QGhoYBWm9+5Ug9rwPKJTgfs3AmsXi3/FsaR5kNCQjBnzhyrt9+5cyc0Gg3u37+fZ3kiIiIiooIrMhIICQGeew7o00f+DQ4Gpk4t3NfFtmANWD6IjARGjACuXzcuCwwE5s4FwsLsf7zsRmmcNGkSJk+ebHO6hw4dQrFixazevkmTJoiOjkbx4sVtPhYRERFRUWHvGqDCUKOk0wHTpgGTJpmvi4oyXZ6X18UFAQMwlUVGAt27A0KYLo+KksvXrbP/yRYdHW14HhERgYkTJ+Ls2bOGZR4eHobnQgjodDo4OmZ/avj4+NiUD2dnZ5QtW9amfYiIiIgKktwGO9ndiLeUvnLcXbs0uHMHKFNGLrt9Gzh/HvjmG/ve2LdnQKcEXnPmAPfuWbdPXl4XFwRsgqginU5+4TIGX4BxWXi4/atdy5Yta3gUL14cGo3G8Prff/+Fp6cnNm3ahHr16sHFxQV//vknLl68iC5dusDX1xceHh5o0KABtm3bZpJuxiaIGo0G3377LV566SW4u7ujcuXK+Pnnnw3rMzZBXLZsGUqUKIHff/8d1apVg4eHBzp06GASMKalpWH48OEoUaIEvL29MWbMGAwYMABdu3bN9P3Gxsaid+/eCAgIgLu7O2rWrInVq1ebbKPX6zFz5kxUqlQJLi4uKFeuHKZPn25Yf/36dfTu3RulSpVCsWLFUL9+fRw4cCAHpU9ERFT0FYWuFdnR6WQzuTJlTJvPhYTIoMoayo349MESYAw43nvPvHleSAgwdqwDhgxph7ZtHdGnD9CmjXz06SNrjjKmd/060K2bvO6cMwf47jv5d+VK4+ejfGYrV5puEx4ugy5r3mP6z337dvlIn96rrwIlSsg8Wht8AfK6WAhg8GCZZlE7n1gDpqI9e8y/IOkJAVy7Jrdr3ly9fAHA2LFjMWvWLFSoUAElS5bEtWvX0LFjR0ybNg0uLi5YsWIFOnfujLNnz6JcuXKZpjNlyhTMnDkTn376KebPn4++ffviv//+Q6lSpSxu/+jRI8yaNQvfffcdHBwc8Morr2D06NFYuXIlAOCTTz7BypUrsXTpUlSrVg1z587Fhg0b8Nxzz2Wah6SkJNSrVw9jxoyBl5cXfvvtN/Tr1w8VK1ZEw4YNAQDjxo3DN998g88//xzNmjVDdHQ0Tp8+DQCIj49HixYtEBAQgJ9//hlly5bFkSNHoNfrc1q8RERERYZSE7N7dwCKFdPg/n1g5Mjc18AotS5RUcCdO4CPDxAQYFr7kpuamZzsq+zz00/AkiVAXJz5NlnV1qR/T7duyZqgrG7Ef/qp+brr14HZsx0A2D5n6Lx5lpd7egLOzkBsrHXpKAHdDz8APXrIZZZq8uzt7l0ZaBa5JomCzDx48EAAEA8ePDBbl5iYKE6fPi0SExNtTnfVKiWez/qxapUQOp1O3Lt3T+h0Onu8JYOlS5eK4sWLG17v2LFDABAbNmzIdt+nn35azJ8/3/A6ODhYfP7554bXAMT48eMNr+Pj4wUAsWnTJpNj3bt3z5AXAOLChQuGfRYsWCB8fX0Nr319fcWnn35qeJ2WlibKlSsnunTpYu1bFkII0alTJ/HOO+8IIYSIi4sTLi4u4ptvvjHZRinzhQsXCk9PTxEbG2vTMWyVm3OpKEhJSREbNmwQKSkp+Z2VJwLLW10sb/WxzNWxfr0QgYHWXc8AQoSHC7FjhxDJyfLvqlXyb1qafCjLpkzJPN3AQHlcS8dW1glhmp5yjKzyXaqUPG767RRpaXJdqVLWv9eAACG2bRPi+++F+OwzIcLChPD0tH7/wvIYMECIt99W/7gajfGzzmsZf0+yig1ygjVgKvLzs+929lS/fn2T1/Hx8Zg8eTJ+++03REdHIy0tDYmJibh69WqW6dSqVcvwvFixYvDy8sLt27cz3d7d3R0VK1Y0vPbz8zNs/+DBA9y6dctQawUAWq0W9erVy7I2SqfTYfr06fjhhx8QFRWFlJQUJCcnw93dHQBw5swZJCcno3Xr1hb3P378OOrWrZtprR0REVFBlNt+O9ntn1k/9qzMmSMfWq1pMzJPT5lOfHz2aSi1L1mt69gROHRI1pwpSpWSNTRVqwI9e5rve/eubBr32WfAwIFA+fKAtzewYwewdq11eUsvKkrW1hR1y5fn37HDw4EuXQreACO2YgCmotBQWYUaFWX5x0ujkeuVzpZqyjia4ejRo7F161bMmjULlSpVgpubG7p3746UlJQs03FycjJ5rdFosgyWLG0vbPllt+DTTz/F3LlzMWfOHNSsWRPFihVDeHi4Ie9ubm5Z7p/deiIiopywJUCyNZjKbGCH2bNlU77s0rG0vxLAfPCBfJ1ZP3ZrZOzD8/BhztLJzMaN5suUACs7cXGZN9WjgkMIY1edli3zOze5wwBMRVqtbL/avbsMttL/iCkjxSt3ifK7u9Fff/2FgQMH4qWXXgIga8SuXLmiah6KFy8OX19fHDp0CM0fd4rT6XQ4cuQI6tSpk+l+f/31F7p06YJXXnkFgBxw49y5c6hevToAoHLlynBzc8P27dvx+uuvm+1fs2ZNLF68GHfv3mUtGBFRAZTZKHFqHzN9IJN+ffoR6pRtf/rJ+iloLAVDAQHAkCFA5cqm71npn2RpWs7r14GXXzZdpgRVY8cCe/fK/J4/D0yebB5cKQHMzJnyuHnZ14fIWunGaiu0GICpLCxMdtK09CM8Z07B6VxYuXJlREZGonPnztBoNJgwYUK+DELx9ttvY8aMGahUqRKqVq2K+fPn4969e1nObVa5cmWsW7cOe/fuRcmSJTF79mzcunXLEIC5urpizJgxeO+99+Ds7IymTZvizp07OHnyJHr06IHevXvj448/RteuXTFjxgz4+fnh6NGj8Pf3R+PGjdV660RETwRranrSb5PZkNuffaaBi0v2x7E0wAOQfdO7jP+3S5aUTaHatAEuXjTPU3oeHpabsynN5yZNkgHOnTvApUvA/Pnm22acJ8nVVd68TUzM/D1bogRVlgKuzCQkAMeO2XYcorySH1117I0BWD4IC5M/2gV5wrzZs2fj1VdfRZMmTVC6dGmMGTMGcZaG/sljY8aMwc2bN9G/f39otVoMGTIE7du3hzaLwho/fjwuXbqE9u3bw93dHUOGDEHXrl3x4MEDwzYTJkyAo6MjJk6ciBs3bsDPzw//+9//AMj5yrZs2YJ33nkHHTt2RFpaGqpXr44FCxbk+fslIioM7DVHkDXN3qZNk7VEd+9mnk5UFNCrlxbvveeHjh2tO47CzU3mPX2ApARXrVrJIbAt9Xm5dw9Ytkw+spNdX6IpU7JPI6OkJNv3SS+Xrf2JVJefXXXsTSNy2+GmCIqLi0Px4sXx4MEDeHl5maxLSkrC5cuXUb58ebi62j4cqLX0ej3i4uLg5eUFBwdO16bQ6/WoVq0aXn75ZXz44Yd2T1vNMlfrXCqoUlNTsXHjRnTs2NGsLyDZH8tbXflR3nnZvyj9Pj/9JOf5ST/YQcamdNakv26dcThrS9zcZJBgfaAh4OmZgogILZydHXHzZtY1SkSUPzJ2w7FlP7UmZs74G55VbJATrAGjAu2///7Dli1b0KJFCyQnJ+OLL77A5cuX0adPn/zOGhFRgZHZAAzW9i/Kbo6d7Ob7UeZBiogAzpwxr7EqWRLo3Fkex8FBXkhNn571e7K1aR2gwcOHLhZrwIgo/2Xsf2jpZk7G0TIVQUEFq6tObjEAowLNwcEBy5Ytw+jRoyGEQI0aNbBt2zZUq1Ytv7NGRKSqzGqVMhsa3NLEqZnVOkVFyW2nTAEqVjTtIxUTIwdyyOqOtbKuVy/Lg0jduwesWJGz901EpgIDgaZN5Q2P7CjNaT09gcWLgUePMt922DDZ3++nn7Ju8muLgQNlP8mME2q3bCkfs2aZ/q41aSKDs6wm4y4KGIBRgRYUFIS//vorv7NBRIWUvfoq5Zesmv2VKgW8/ba8qMoqOFKCIgcHoHdvy9so+1sastvBwfrmQvk9gi9RXsnYbM7bG0hOtn6usGLF5M2PVq2A2FjgyhVZU2yN4cOBcuV0uH79KDp1qoPnnnOEVitvjFiqzR482HS0TOU37/PPLfepzFi7lHFEzz17ZDPerIKyjDVX1tZYabXmQ8oX9iHmrcEAjIiIiqTsBniwRyCWmwBPpwN27pQPwHhHWLmQyW7wibt3rRu8Qa+XQVhOMaiizCkRSeYjExd2lobtTz8NgKXvacYmt+m/2+k1b551015vb+Drr2UQk5qqx8aNUWjRorYhHVsHddNqgYkT5e9fVvtkDIpatwYmTDAdRdTbWwaSSg2VUnNVWG92qY0BGBERFQoZg530//AzzruUWbM5ZQjuzz4Dvv3WtDlexmHKM15gpB+uPCpKjo6XsamO0peqc2eZ3q5dGty6ZdqUpkkT4OOPgU8/Nb17/tFH8i55w4bAoUPW31knyi+urmlwd3e0W3O1nBg+XE7qbEuzuXfekRNUA5Zrd7NqNpeRNQFNZtIHUFFRwK1b8jcnq6AtI0s1SNnJq32ehJore2EARkRE+cbaGiRLtVmZddYGsh9lKy5OBmg9e8q+SR9/nP1Q55aGK89I6XfVvbsDduxoh9hY83+zDg6Z1yolJAA7dmSePlFBUKoUMGyYDrVry1Hi9u93ynSOtozfUx8foG9fIDgYGDky+2N99hmwbx/w++8y0FJk1WxOuQkzcqRpXtLv06SJ+W9KTgd6yElAY499qfBiAEZERHkmqwDLUlBVujTwyivyrrBSw/XTT/KiyFLambG2z1JEhBykwprtbRmVb906LQDL00uwSR/ZIqsbDYqMNxwy7qP0FwTM+/JkdrMiKEgGPz4+lgdE0Ov12LjRPIDIWBuUWdM0nU6mHxVl+fjKnE8jRgCjRmV/s8ZSIPPSS5nvUxjmZKWiiwEYEdETytIFDZD7C5KsBo5QRuQqXtxyB/SYGBlszZlj3YWnPeTdbJhFt19MUWXN/ERKMJPdoAQKLy8ZdKevOVVGsdu61TSN4sWBfv3kSJSZ9a1p0kR+v9L3HQwNNd8ms/44Sl+e3I46l9mNBGsHVdBq5W9A9+7m5a55/NVRfgcySzc72e3D2ifKLwzAiIieQJZqn7y95d/YWOMypU9TVv0U0l/8WWqClN69e8CyZdblUY3giwqO7IKfpk2B//7L/NyyVlY1OxmDEW9v+ddSv5xatWTwAFjOd3i4/N5kdWPD2ia4GYOE1q3lI6ttMgssCtKoc2FhcmoESyP5FaU5n4gyYgBGVmvZsiXq1KmDOY/bAoWEhCA8PBzh4eGZ7qPRaPDjjz+ia9euuTq2vdIhKgzsPXS6MhjE7t0BKFZMg/v3LQ9QkT7wUih9mpQBKTL66CPrag2IshMRIc/zjBfjPj7AggVywJT0tatz5lh37g0bZlqjlN33ydpgJLPgIbN+RJnVAj3pNTBsCkhPIgZgT4DOnTsjNTUVmzdvNlu3Z88eNG/eHMePH0etWrVsSvfQoUMoVqyYvbIJAJg8eTI2bNiAY8eOmSyPjo5GyZIl7XosooLIUs2UUgsVFmY+Ul/Gi8qMQ5trtXKeqOvXHQHUx+zZOQuYLAVfCgZflJk1awBfX2PN6V9/yWZ3WQ2mkNXFuBKwKDWvWQ3hndMBFWzB4ME+GIjSk4YB2BPgtddeQ7du3XD9+nUEBgaarFu6dCnq169vc/AFAD4+PvbKYrbKli2r2rGI8ktkpGzSlDGgiYqStVA9e5r3GVGULAnUqWPd8OUMmCg3HBzk0NtPPZX5JK2ZBT85HUzBkozBT6lSaThwYD/Kl38WQUGOqgVCDB6IyFYO+Z2BIkEIOXaw2g8rr6JeeOEF+Pj4YFmGjhfx8fFYu3YtXnvtNcTGxqJ3794ICAiAu7s7atasidWrV2eZbkhIiKE5IgCcP38ezZs3h6urK6pXr46tW7ea7TNmzBg89dRTcHd3R4UKFTBhwgSkpqYCAJYtW4YpU6bg+PHj0Gg00Gg0hjxrNBps2LDBkM7JkyfRqlUruLm5wdvbG0OGDEF8uqvOgQMHomvXrpg1axb8/Pzg7e2NoUOHGo5lycWLF9GnTx/4+fnBw8MDDRo0wLZt20y2SU5OxpgxYxAUFAQXFxdUqlQJixcvNqw/deoUXnjhBXh5ecHT0xOhoaG4ePFiluVIBMiL0hEjLH+tlWUREZl3+r93Tw5fzrmjiiZlUAKFp6f5soy8vOSAEZYEBQHvvitrV9MrVUoG+hpN5umvWSPnUuvdW/ZDmjxZzr+2YwewapX8e/ly5jVPSsDSu7d18xxlJX1arVoJ1K4di169RK7TJSLKS6wBs4dHjwAPD7sm6QCgRHYbxcfLWTuz4ejoiP79+2PZsmX44IMPoHn8X3Xt2rXQ6XTo3bs34uPjUa9ePYwZMwZeXl747bff0K9fP1SsWBENGzbM9hh6vR5hYWHw9fXFgQMH8ODBA4t9wzw9PbFs2TL4+/vj5MmTGDx4MDw9PfHee++hZ8+e+Oeff7B582ZD4FO8eHGzNBISEtC+fXs0btwYhw4dwu3bt/H6669j2LBhJkHmjh074Ofnhx07duDChQvo2bMn6tSpg8GDB2dSnPFo27YtPv74Y7i5uWHFihXo3Lkzzp49i3LlygEA+vfvj3379mHevHmoXbs2Ll++jJiYGABAVFQUmjdvjpYtW+KPP/6Al5cX/vrrL6SlpWVbflQ42NI3K7NJfTPr1D9tWu4HF6DCy83N8jD3pUrJwHzsWPNR7X780XQiaYUSOC1dajp4iqUmqzNmWD6nX37ZtjmSWAtERGQDQWYePHggAIgHDx6YrUtMTBSnT58WiYmJxoXx8ULIm9TqPuLjrX5PZ86cEQDEjh07DMtCQ0PFK6+8kuk+nTp1Eu+8847hdYsWLcSIESMMr4ODg8Xnn38uhBDi999/F46OjiIqKsqwftOmTQKA+PHHHzM9xqeffirq1atneD1p0iRRu3Zts+3Sp/P111+LkiVLivh07/+3334TDg4O4ubNm0IIIQYMGCCCg4NFWlqaYZsePXqInj17ZpoXnU4n7t27J3Q6nWHZ008/LebPny+EEOLs2bMCgNi6davF/ceNGyfKly8vUlJSMj1GehbPpSdISkqK2LBhg9XllZ/S0oSYMkWIUqVMv4KBgUL88IMQO3YIsWqV/JucbHnbrB4uLvnzE/IkPjw9hdBost9uwAAh3n5biOLFLa8vWVKIgQOF+P57+Xl7e+c8Tz/8IM+xHTtkep9/Lv/u2CGXZ2X9enkepk8vKEgut8d5n/7czi4v+a0w/aYUBXYv77Q0IfR6+6SV3vnzQvz6qxAPH+Y8jf/+E+LRI/vlKQcKxfmdkiLEvn1C/PSTEPa4tlm6VIjbt3OfTg5kLO+sYoOcYA2YPbi7273dj16vR1xcHLy8vODgkElLUXd3q9OrWrUqmjRpgiVLlqBly5a4cOEC9uzZg6lTpwIAdDodpk+fjh9++AFRUVFISUlBcnIy3K08xpkzZxAUFAR/f3/DssaNG5ttFxERgXnz5uHixYuIj49HWloavLy8rH4fyrFq165tMgBI06ZNodfrcfbsWfj6+gIAnn76aWjTVU/4+fnh5MmTmaYbHx+PCRMmYNu2bYiOjkZaWhoSExNx9epVAMCxY8eg1WrRokULi/sfO3YMoaGhcHJysun9UMFiaRCLL77IfITAl1/O/TGTk3OfBmVNqRVatkzOX2Sp5kjxww/G9Z9/nnUNkuKDD+Q5s2gR8Pvv5oNM9OoFrF6ddY1STmqQ8nIQiEJdq/Xrr8Dhw8D48WyLWFDdvw8cPw40bw6kpAANGwI3b8o2rYMHA44WLlG3bZNftA8+kNXG2YmLA5o1kyPAuLoC/fvLH3Tl//SDB8B338kvaOnSltPYu1fm8aWXgLVrrXtfbm6Ai0v22+bW0aOyQ+annwJVq9q27+nTwLFjsv1udu2Z16yRP4yLFsmOn5Zs3izbL8fFydfBwcAnn8h/ktmlrzhyBLh2DXjxRflDOmiQ/FH755/M21MXUgzA7EGjsaopoE30enklWKyYbKdkB6+99hrefvttLFiwAEuXLkXFihUNwcSnn36KuXPnYs6cOahZsyaKFSuG8PBwpKSk2OXYALBv3z707dsXU6ZMQfv27VG8eHGsWbMGn332md2OkV7GQEij0UCf2cyRAN59911s2bIFs2bNwlNPPQU3Nzd0797dUAZu2fzYZ7eeCoasmhFGRgJDhmQ94h/lv6wmaM4s2Mk4r9D69dY1sbM2CNFqjXMz6XTAjh1p2LTpGJ5/vg6ee84xy+Z+uVWoA6W8cPWqjKCTkuRIIZ07y4vnSpWAL780XgwuXixHBXn1VTmfgr3/j9vTL78AFSoATz8tT7C//pKTlilBys2bsh3zw4fAyJFyRuft22XgULmydcfQ6eTM6W3byhPUno4cAUJCjBfROh3QoQNw4ACwfDng7AycOCHXvfUW8Ntv8j2nv3BPSwP69pUdDu/ckYHUN9/IC/1OnSwfd9YsGXxptfJ8+PprGSCtWiWXjR4NfPutvDOze7flG9sLFsj8btggg4vMbhoLISeYGzNG/hD8/nvWgcfdu0CDBvJ6b9AgGbRFRQFDh1r/mU2eLG82uLvLTsK26NULOHlStn1+7bXMt7t9WwbE8fHyR3LuXPNt4uNlGnFxsp29o6OctK9XL7n9vHlA/fpZ5+fWLXm+JiQAr78u55oA5A9yEQu+AAB2qUcrYmxugpgHLDWHy62HDx8KDw8PsWjRIhEYGCimTZtmWPfCCy+IV1991eT4lStXFl26dDEss6YJ4o0bNwzrN2/eLABj08FZs2aJChUqmOTptddeE8WLFze8njZtmqhRo4ZZ3tOnY20TxPR5F0KIESNGiBYtWmRWPKJGjRri/fffN5T5w4cPRfHixQ3v+fLly0Kj0WTaBHHy5MlsgmgDa5tTZNUMKuO65OTMX2/bJsSkSeZNA5WmZG+/nf/N49R+VMAFsQuhoi1+V+V4Pj5CDB8uxKBBlptz9uyZ9f7h4ZY/123bzM8Pa5rPpd9m1++JIi3RDk174uKEWLtWpDx6lDfNhVJShDh6VIj79zPf5tQpIRo3FmL16twf78YNIS5fzn06tnrwwLrmaHq9EJGRQsTEGH5TdD16GE+a1q2FmD3b+Pqrr4z7Vq1qXF6xorGp0+7dQnz7rRA//ijEmjVCfP21ENHRxv3OnRNizBgh/vc/Ie7dy9n70+uF2LBBntRdu8p2rL/8IkS/fkK0aiXErVvGbf/4w/gFiosTYuxY+frll2U6X34phIeH5S9NQIAQd+9al6f58+U+NWrIL1k2rG4S9+efMt1y5YRQuil88YUxj5UrC9G8ufHzcnaWz/fsMU3nt99M31v16vKvo6P8fPR6IQ4cEOLff4VITZXnrru73GbdOlneTk7y9eDBsozTt/9++WUhkpJMj3n/vhCursZt1q6V5+aaNfK7KITcZ8MGIV54wTR/e/eal8Xdu0JcuCCff/ml5c+sQQMhLFz7Gcr73j354/XokRBubnIfNzfzJpbJyfIYGctRCPne058jCQmm6xMT5Xu8elWIYcOM27q5CXHxohC9egnRv7+xWeaYMcbvUWKiTG/qVGP5FysmxM2bssxmzJCPn382Pe6IEeZlUauWfZoy5kBeN0GEXVIpYopqACaEDHhKliwptFqtSX+tkSNHiqCgIPHXX3+J06dPi9dff114eXlZHYDpdDpRvXp10bZtW3Hs2DGxe/duUa9ePZE+cPrpp5+Eo6OjWL16tbhw4YKYO3euKFWqlEkAtnLlSlGsWDFx9OhRcefOHZH0+McwfToJCQnCz89PdOvWTZw8eVL88ccfokKFCmLAgAGGdHISgHXt2lXUrFlTHD58WBw7dkx07txZeHp6mrzngQMHiqCgIPHjjz+KS5cuiR07doiIiAghhBAxMTHC29tbhIWFiUOHDolz586JFStWiH///dfi8RiAZf/P21L/lsBAudzSOq3W9LU1fX2e5MdnGCkEIP5AS5v3dXWV/amyKu/AQHldaU3wrKzLyz5NmfrvP3lxWLmy5QvPe/eE+P136wKCN98UAhBpEyaYnt+HDwtx4kTu8nnlihB16xoLu0kTIe7cMd0mLU1ewAEyys0qUEtPr5cXrsr/nPv3hRg9Wl4MOznJKFcIeQH18cfyQ1q4MGfvIzU16/Vr18r3N3589mktXy7fa+vWIiUlReyZNk2+dnAwnpA+PsaTqVgxeQF85ox87eQkhL+/fP7JJ0JcumT+QwIIUbu2vBAcPdp0eZ068sJSCLn+00+FmDdPiJ07sz5flizJ+gv2+H+rEEKI9AHlkCGmQUPr1sbnDRvKIEKjke/fy0su79Mn+3IUQr4XJa1Jk7LeVqcTKYcPiy1ffSVSMgYtGfXqZVqOP/xgzJuDg3Gdg4P8Lg4ZIl937myajnKHxtfXvLymTpVllv7HSEn72WeNn0VkpHF548byb4UKxsDMy0uIt94yBmJffWV6nAEDhHjxRfl89Gj5fWjY0Lje0VGImjXl8969TfOv1wtRr57cZv9+IUJD5XY9e8r32rOnMZD+7juzYkxJSRE7Zs8W+mLFhOjSxTwgXbnSuPGNG/L3QTnnb92Sxz9zRv5GrF9vuu/HHxv3jY+XNwGUH3pHR/lc+Z4onx0gRIcOQnzzjbH8fvnFNNNRUcbymDXLGOQrDx8fIaZNk98XJfB+8035Gbm7C3H6dNbnVh5iAJYPinIAtnfvXgFAdOzY0WR5bGys6NKli/Dw8BBlypQR48ePF/3797c6ABNCDlLRrFkz4ezsLJ566imzGjAhhHj33XeFt7e38PDwED179hSff/65SQCWlJQkunXrJkqUKCEAiKVLlwohhFk6J06cEM8995xwdXUVpUqVEoMHDxYP0939yUkAdvHiRREaGirc3NxEUFCQ+OKLL8zec2Jiohg5cqTw8/MTzs7OolKlSmLJkiWG9cePHxft2rUT7u7uwtPTU4SGhoqLFy9aPN6TEIBlVQuR/sct/XZKjYalm2F8ZP5wRpKYivGiLg5nsZ3e5PVB1BcCEI/gKpyQLIoXF2LFCvlZRERYTkOjkY/167OvgTSrdUpJEeLaNZvOm72rrwjd++PlP/Hnnst5jUNGsbFCbNwoL8bTX3gqgUZ6/fvLdelrTyzR6QwXh/qAALFh/Xr5z/v4cXkR4+IixLFj1uVPp5MXRWvWyNfHjwtRurTMh3KxAwixaJHc9p13hHjtNWPtiPKYPNm64ykXRuPGyQu1Fi1M0/H0lBe5ysUUIN/PuXPy4m7uXCG6dZPBQkxM5seZNEnmf/hwWdbPPSdEmzbGO+HJyUKEhMj0tVoh/vkn63y/9JIhPyn794t75cvL1//7nxDt2hnz6utrrGVp3lzegQeEaN/eeJFdr568YwDIWoFGjWQ5lCwpl9WqZXrhWaaMfF6pkgzc0gcagKzqtRSE3btnDAp79BDis8/kBXhQkLF8e/SQ2968abwATv9Qjq08pkwxBs+3bsnAfP9+YzDZr58Q06fL91OzpqzZSO/oUeMXHJDHPH7cPO9paUJMmCCEn5/h2HovL1lbaMnt28bztUQJ0zw3aCDExInG1506yX3OnjXm49Qpuez+fWPguW+fEN27ywBj0iS5rGxZY/CiXMgr35WMNVHKZ6w81qyRP3jp3pOYNUtuqwRpHTvKv0qNk3Kc8HD53MtL/tM6elSII0eMZZjuRrfYvdu4r3IjBTD9TZw+XS4LDJQ3XO7elcHYypUiJSlJxFapYp6GUkPXubPc/sMPzZsYjBxpzOukScbnwcHGNIYMkTch6sv/CybBcYcOspYv/e9B+rIAZFBoyaJFcn316rKGDBCiWTN5vmc8r1u0kN+Z06fldyofMQDLB0U5AKPMqV3mRTkAy2zUwIAAY43I1q2pYv36DSIiItWsxoOP7B/OzvLaVSnjIZD/5PbiWcP/04z/Hz08koQShHkgTqTCeKe/Mfaa1TJlWRt18qQQb7whL/pHjpRNfLIKjq5dM15cvv66dYHUmTPGoEN5PPecrKlZuFD+Y//lF2NToPT0eiEWLDAGMElJckStmzflOuXuc8ZHuhsuhpNZKeQGDbLO78GDJmntHT9e1g48+6xxeZUqlkewzXihrkTAWq2sPVNqterWlbUEEybI1716yWZXGd9Hp07GC6WFC02bTCni4uT7S0oyXny6ugqxbJnx+U8/CdGypWnaJUvKmgxABq8ZP6MaNYy1QulduGA5mADkhbgQ5s2yWrUyls3Ro/JCX/mNTkkxqYbVPz5Z9cWLywv/9HcRpk+XTSmVL4VyF//LL+W2SqCiBDYrVhjzvXGjaZ6UG4/nzhkvYJWmVo6OsuyVi9eFC+W5fuWKLOvERPm9AWQTyIw1rjt3ynX+/vJ9f/yxfN2woSxXJQ8HDsjvkaOjMViwZPJky+X9wQcy/fHjhXj3XRksAjLw69rVeK5mvA5avNhY3sWKiTTl8/T1NW1OlpIiA/FPP5Xr69eXn1/r1vL70KeP/DxiY42B088/G/dXAuv+/eXrb7+Vr6tVM/2uJCWZ1nA2aiTLOTpaBj9xceZlkpZmvMFQrpyxRlanE2LOHLm8dGkZ+CjfwatXTWt+Mp7H335reoxmzeTy3r2N3/e+fc0/h9BQ0/0SE43nFGDSrECvfOcyPmbONOYz/Y9+jRrGpp7pg6lSpYzn0vffy5sQGdMsUUIG8OvXy8Ds6lVZPs8+K79zu3cLsWWLPO/9/ORNhMxGibx3z7QZZ8mSskxSUmQN9nPPyfXOzvKYBUSRD8C++OILERwcLFxcXETDhg3FgQMHMt02JSVFTJkyRVSoUEG4uLiIWrVqiU2bNuUqTUsYgD2ZGIBlLbParIzL1661fkhuF5cUkbFWhg/rHkpFjVL+l5rIf+46raPYtTFepCUkibTj/xg+m61bU8X6dT+Kg0MWiX7ev4m2+N0kwRP9PrHpczfcEU7/8PU13llPSZH//J95Rl5EK81XlEfZslm3K7x61XiHtGZNWcOSsc2j8njuOWPfmLZtZYCybp3xAuavv4zNmurWNd7JVZqpubnJi1BAiPLl5QVeXJy84Pj7b9NjnTmTeZ6Vu/mPL5qinn1WpH3yiVzm6WkMcpo0kReyyjHCw+WFoPK/SqcT4umnTS+YlDSUfrbKhXrZssbjli4tj92ihbyozHjB1revMXg5dEiOsV+9uvGuu/JQLtZGjpTb3rsnP+/nnpPN627flv1A0l9U1agh764o77FCBXnCbNkiL0K//NLYlK5+fXmRqdHIz0v+GMhmnsp58s47xvS/+krWxigXl02bys9h1y75On0+AJGmBCRJSbJ2yt/f2A/qww9N3+v163K5kg9ANtnK2J/mgw9kfseMMV1+/brpZ6XUkioXxekfykWm8nrLFvNzKCHBGAxevizLEZBNFjdtkp9Nuub22Q6trtfLcn33XRnUKLW5FSsKsXmzeR43bpSfr/Lda9VK9m1q3lzeYChbVi4fP16kPHwofl67VuiVWsdPPpHHi4gwBrJKoPLNN5nn8Y8/5PmRPrBSbio4OMhzVak5mTHDfP9x44zfu4MHsy4PxY0bshwzfgapqUI89ZRpmSg3ZZTz191dBovKekt9tn791bg+JEQG9EoNXvra5S+/NM/bgQMykFTOg6pVTQK+tPBw43fB1VWeM+lrpmvWlD/YqanmN5vS154D8saYXi+/q4MGyRs6U6bIofstSUkxPefi4izfAMuod2/jMceONV+flGR9c2mVFOkAbM2aNcLZ2VksWbJEnDp1SgwePFiUKFFC3Erf+TSd9957T/j7+4vffvtNXLx4UXz55ZfC1dVVHDlyJMdpWsIA7MnEACxza9ea3mQEZM3Iu++a15AU7IdeOCIl1+mUxQ3xM14QwzEnX95HUJCF5n1Ksy1ARmeP+yKJx01kU1JSxJHHnan1Tk7iZus+QgBC5/T4grBTJ3mRunu3dX2dlAvtYcOEGDrUeMHWurW8i1mtmnnGq1WT/T/SX+D07m3e8f3OHeMACU89ZRwcYcsWeQHr4CAvYl580Xj3PH3zpgYNZECjvM7YZ0S5EBo9WgYXd+7IO7LK8vHj5YXKG2/Ii8r0+77/vuzLtXOncd6ic+fk/s88I7d55x3z9z5vnrzISX8B5Otreve5YUOZ3g8/yNdeXqZ33T/7zFhGiYnG/CqfxZIlstZBqVU5eFAGFi+8YLyACw+XtTHp77Irj/RBtaur6cATlixYIC9Gw8ONn+H585bTVh4ajWyGmZRkrI1M348JkJ9dUpLsGwLIzzt98zBABo9Kn6C+fQ01DnGBgSIlfU1MfLxpLUhiojGoSV+j+c03xrT79bP8fjMbzCI2VohXX5W1Jwq93rTvVvrPvWxZGfRmRmkCptSYFC9urF26dSt3E7LFxxtr65SgRjmPAgKMae/fb36xrjwqVhQiKclwgZqq1IqVKCGbcWbcvlSpnM3BFRZm/B4AMpC2dPEbHS2/O1On5rxc0lu92pj3Nm2MNWTbtsnfH6UG9I03ZN7+/ttyOps2mf4OAfIG0I0b8nfL3d10sJWMHj403iDYs0foQ0JETLVqIiU+Xoj33pPpvfiiXH/kiAxE//rL/Pf7wAEZsL32mhAffWTMS0hIjovIZr8/vuHn6Gh8TwVckQ7AGjZsKIYOHWp4rdPphL+/v5hh6Q6HEMLPz0988cUXJsvCwsJE3759c5ymJQzAnkwMwCxTKgby4xGCS6I6/snRvvVwSPghymTZNIwTSXAWHbAxx3nyQJw4DNn2PhlOwh/XRQdsFCdQQ7yCFfI6BtdEa2wVJXBXFCsmR1lcsUL+316xQl5Hh4WZV+i44pEYj6livPtnwhWPzAa1SN//ykRUlOmG771nDEyCgoRIThYpZ8+K1Aw1BQKQfWWUizzlwnT2bPMT4fp12cdn0yYZsCj7Kxe3Z8+at3ksXVpelC5ZIi/WlQvYxEQZyChBQYcOxuYrDx8am9sFBsrarPRu3DDtY7R7t/G4np6mgVi5csY79oCsOVGee3qaD2ChNNtTHg4OxkBSuYucfgCEcuWMdyCUOxQajRC3bgnd42PpPTxkoKdc2J47Jy8UlYtfwLTp0KxZcjAQQPbVWLBAPq9e3fxOc8Z+WulGoTWjNCtM/6hQwRjYFC8uL26V5pIZm2JmxtLv5f37xvPK1VUGNEq1uNKkLL1Tp+T7d3CQF5RKvy+93pgOIAO7o0dNBz0AZDOqv/8WujZtxM5PP81+VL4dO2T5r11rXBYTYzwfMxnp1mapqbKp7oMH8vO/cEHWHGZ3g2P4cPPvsz2l76vm4CD72yxfLvOa3po1stZzyhTTcy0yUgiR7gI1MdF0REknJ3nu3rolL7zPnctZPv/913RAlPSfV17S6WQzzKZNzYPujJ9ddp/lw4fyt0753VCaKp49a+zfZqWU5GSxITJSnt9JSbIJthV9aoUQxt+fmzeNgXVmNxrygtKc1h4js6qkyAZgycnJQqvVmgysIIQQ/fv3Fy8qEX0GpUqVEt9maGfbt29fERwcnOM0hZADPzx48MDwuHbtmgAgYh4Pa5v+ERcXJ06dOiUSEhKETqfLs0daWpq4d++eSEtLy9Pj8JF/ZZ6QkCBOnTol4uLizM6zvH4kJqaIrVtTxYoVqWLr1lSRmGh5/dChaUI2EbRfM8FgXBbBuGxxnRsSRAMcEIBelMZtEYuSIhlOogrO2HSMLvhRCECcRWWhRaoAhKiMs4Y+T1HwE76IFlMxXnyE94UGumzTDMJ/Yjg+FwfQwGTFIgwR0TDWsHyHviIR8p+tDhqhq1lTpL31lkg5cSLTz2HZslSxZPQJcTfQ2JQp3jtIfFUsXEzEZPEtXhW/oJN4vswhERGRapZO6qpVJnnSK3e4Hz/SJk4UaY/vTOsy1EylHD0qg4T0+7u4iNRVq4SuXTuh69lTpDx6JHSPm5DonnlGpG7ZIrd7PO2C8kibO9eQhq5bN5Fy61aW52Hq5s2GvOp69pRpPB7OWO/tLVKOH7fqfE7dsUPoXntNpBw/LlJ//lnoH0euqRERIvVxU0R99eoi5cEDoevXT5bJ5Mnm6aTrf6TPEEymHDgg+xYBQu/gYHguAMPxBCB0DRuKlJQUkXDxotj//vsi4eZNy/mOjxdps2YJXePGIjUyUqSNH2/6Gfj6ipTbt0VKcrJI/eknkfLff2ZppN9HX7du9uX01VdC/zjw07u7i5S//xYpx44JXcuWIvWbb+R258+LtBkzRMr9+7n/rTl1SqTcuCGf374tUteuFSmZ/d5duiRSrl41X56UJNLefFPoK1YUKfv3y2VXrgj94yZueo1GpERFyTJPSBAbNmwQCQkJOcpv6uLFIm3SJJHyuHYnvx6pSt8jQOi1WpFy8aJ901ea5wJC99JL1u2XkCDSpk8XadOni5TkZPPy3r9f6F55RaR++aVIuXbNbnlNexyA655/3nDcQvm4eFGk/vprrt5Dbs9v5aF79VX5+7hmTf6XSwF+ZCzvmJgYuwZgGiGEUG/WMaMbN24gICAAe/fuRePGjQ3L33vvPezatQsHDhww26dPnz44fvw4NmzYgIoVK2L79u3o0qULdDodkpOTc5QmAEyePBlTpkwxW75q1Sq4Z5iUz9HREWXLlkVgYCBc1JjlnIqs5ORkXL9+HTdv3kRaWppqx923zw/fflsTsbHGiaM9PFLQufNFvPTSOURGPoVff62I+Hhnux+7PC7hOGpDDwc8hXO4DV+T9d/gdbyOxfgE78ETD/EWFgIA1qAnBmIZxuATPI9NqI7TGI1Z+AZDDPtWxRk8hXM4iro4jHrwQQwAoB9W4Hv0ww/ogR5YZ9j+ITzgiXiTbQCgG9YhHHMwA2OxEZ0AaNAVP2IF+hu2T4A7ZuI9TMFkQ3oJcEcxPDK8TipREq737xleJ3t5Yes338AhNRXlf/sNV1u1QpKPDwBAm5yMNm+8Add795BUvDj0Tk5wj4kxK78UDw/89dFHiAsJAQCUOHcOGiEQ8OefqPjLL7hTowZ8/vnHsP0jHx+437ljeJ3q7o6ds2ej6urVCNq1C0nFi+P3ZcvQeMoUlDl2DKlubogLCYH3mTMmx73WsiUCd+2CRggIBwf826sXqq1aheiGDXHw/feNGwqBkN9/R7KXF6IbN856EtLHSp84gaYTJ0Lv6IiN332H0HHjUPzKFRweMQLXn3su2/0t8du3D85xcfivXTtAo4Hnf/8h0dsbaR4egE6Hkhcv4l6lSmaT3DvHxaHFO+8gLjgY57t1Q+i4cQCApJIl8fuSJfDbtw9ljh7F5U6dEO/vD9/Dh6F3ckLs008j6I8/ELh7N8727Inbzzxjc54dExPR+o034PrgAWKrVcPhUaOQ+Pj8yIz3yZNoNmECAOBsjx74t2/f7A8kBDyvX0easzMSfX2z376A8j55Eo0//BAxNWpg/8SJ+Z0du3K7cwftBg8GAFwPDcXhd96xa/oOqalo9+qrcHn4ELs//hj3qla1a/r25JCSAv+9e3GzUSOkubllvwNlS5OaCs9r1xBXvrxVv9EkPXr0CH369MGDBw/gldlk3DYoVAHYnTt3MHjwYPzyyy/QaDSoWLEi2rRpgyVLliAxMTHHAVhycjKSk5MNr+Pi4hAUFISYmBizQtbpdLh06RJ8fHzg7e2d22LIlBACDx8+hKenJzT8gqhC7TKPjY3FnTt3UKFCBWi1WssbpaQAzjkMhISAtn9/4OJF6DZvhq6YF2bMcMDUqcpFp6X3KDJZbvPB8Sz2ozH24Vu8jofwAiDwO9qjHbYCAGbhHSzCG/gCw7AC/bEBXXEbZeCBBACAHho4wPjzdAAN0QgHDa/PoxKewjkAGgTiGk6iJkrgAXRwgBZ6JMEFrkjGaVTDaMzCRnSCHhq8hS/xJd6CAwTSoIUjdLiOADTCAUzBJLyOxQCA+5oS2PnFcdQ4tByVlskLPP0z9fBPlTC89UcP7L1VESdRE0/jNABg97hf0dT5EBwiIqAbPRqiXz/g9m1o/vwT2vfeg+baNaQtWgSHnTvhsGYNRN26SPvrL8DREQ6LFkE7fDhEcDDS/vwT8PKCZuVKaC5cgOb+fYiAAGi2bIHDgQMQPj5I27cPcHKC41NPyXOkVCloYmORtmwZtO+8A01sLAAgbfduaHv2hCY6GvpatbBjyBA0HjQITjdvQtu7N0S3btCPHAnNb79B+8EH0H36KUSNGnB85hloYmOhb9AADocOmX+65cpBc/UqdOPGQW/h5pVtp4qAY7Vq0Fy6hLRFi+D4xhsAgNTr14EyZXKXdg7zAwDQaKDt2hUOGzdC36cPdMuW2ZRMamoqtm7dirZt28LJycm6nf79F5p//oHo2hVwdMx++6QkOJYpA01SEtJ274Z49lmb8ljoxcYCnp6G38gclXlBJAQca9UCzp9H2t69QA4C+mwdPQrNrVsQHTrkOIkiU96FBMtbXRnLOy4uDqVLl7ZbAGbFL3zeKF26NLRaLW7dumWy/NatWyhbtqzFfXx8fLBhwwYkJSUhNjYW/v7+GDt2LCpUqJDjNAHAxcXFYm2Wk5OT2Unu5OSEkiVLIiYmBg4ODnB3d8+Ti3W9Xo+UlBQkJyfDIcNdWsobapW5EAKPHj1CTEwMSpYsCVdXV5P1Oh2wZw/g9MNKNP5qAM62exu3Rs9CaEstMovTdDpg505g9/ZU+F8/iEc1GqLhf+vQNCICAPDPO8vRcdsoREUZcpFJ7szP5YY4gHN4CvdRMtv3VhEX0BMR6IU1qAlZE1MNZzAE3+AVfI922GoIkN7Cl+iMX1AF59AQB+GGRHggwRAUOUAgEi8hBc7ohQg0wkHEoxhGYxZmYxQq4wLq4BiOozaWYhBK4IFh32Q4ow224Ve8gOo487gmC1iOAfgKb6CEhw5Dq+9A9JtTUf29Tgi8cwXXtCFw0KVBaDRI8fZDiZgb6DqjKXD9unxzI0bAYdYs1HJ0xK7Hn9H9yInA/F7Qd++B5tM7AegETJ5s/GENDAR69QKiooDRo+H44YdQPgTN0aNwmjsXGD0amDNHLnv3XTgFBsp933zTtHBHjQKeew6aY8fg9NlnMm3lxtHjgMuxZUugWTPgp5+AKlXg2KwZsG0bcOAAdD16IH77dvm7VqEC8PiGlBYAunYFunY15vvwYSA6Gg6NGgE9ewJr18o7pU2aAH/9Bc3Vq3LfunWhtceFwPPPAwsWwFEJ5urWhVNAQO7Tza2vvgI+/RQO4eFwyOH7tPR/JFM1a8qH9YkD330HXL0qP+sn7WZdJv/XbSrzgmrLFiAmBk55EXwBQMOGdkuqSJR3IcLyVpdS3vYu83wLwJydnVGvXj1s374dXbt2BSAvgLdv345hw4Zlua+rqysCAgKQmpqK9evX4+WXX851mrZQgrnbt2/bLc2MhBBITEyEm5sba8BUonaZlyhRwuzGQGQkMGIEcP26wClMgwN0qLZ5Dk5tvoYqAd9j5jxXhIXBbJ8hQ+Q1+DK8jgFYgd0IRXlcMGxTfPlc3MRwAI5ojl3YgK6Yhg/wGUZnmcfO+Bk/owt+Rzt0wO94CwvwMcbiBfyK3WiBEZiDCriE0ZiFhjiI7WgNF6QAgKEGqj9WYB6G43OMBABMwIfoig1oiEOognMAgFK4h3kYDgCYhdHwxS08hx0YjVlwQio64xekwREdsBn70RitsR09sA4v4we0wC60wXY8ghuewREE4jocy3ij3dC6uH50GEpsmAYAiO74Gjy6z8GO8kBo6FBotUMRBADunwA9e8JBlwY8/TQ0CxbApVQpoF49Y/A1ezYwcqShXLRaoGVLAC17Am/WgkPFill/2K++CkycaAi+UKkScOECMHkycOIEcOkS4O0NDBqUeRolSshArWVLYOlSuT0gL6QOHgQqVADKlQP69pUBWHi4vCCvXl0+UlOzzmN6wcHyAQALFwKPHgFNmwJ+fsBffxm3syVYyEqHDsCCBUB0tHzdtq190s2twEBg7tz8zkXWunfP7xxQXihXTj6IqGiyS0+yHFqzZo1wcXERy5YtE6dPnxZDhgwRJUqUEDcfT+DYr18/MTbdfAH79+8X69evFxcvXhS7d+8WrVq1EuXLlxf30k3omV2a1rB2pJO0tDSRmJiYJ4+4uDjx66+/iri4uDw7RpF9PHggEsePF4m7dqlX5vfu2bR9mjIi0aRJcm6WhASxfr1xzsWW+EMIQCTATSRBDhP+M14Qzkg2GQFv7Vpjv/0aOCF0MB027zwqiluQo7P1QIRwQrL4F3II8H/xVLYDT2yFcXjop3HSkNZGdBAVcMFwvM8wUvyD6kIAYh8aidfwjSiOe2IP5Ehwd1FCCEAcQy3hiBTxPH6TA03AXczCKJOD1sRxkzyUKiXEru/+E9X97hqWdYccpvsOvA0Da7yJBWLEiAxzVT16JEde2rkz8y+yXi/n7lm+3DjcsBBCzJ8vR/FbtMjq344sKZOvOjsLcemS+Yh7kyZln4ZebzoCXIkScnjqn382HVHLwuSjKSmmIzrlyMWLxmO7upqWV248fGg6P5K9RqHLR3Ypb7IJy1xdLG91sbzVlbG8i8woiIr58+eLcuXKCWdnZ9GwYUOxP90s2C1atBAD0k04uHPnTlGtWjXh4uIivL29Rb9+/URUVJRNaVrD3oWcE/yi5cKKFfIirlYtm3bLcZlPny6HL1661LrtlYvWU6eMI1F9/a3JfFo/oLsQgFiAN0UrbBOPIIcPX4tuompAnEhLk1MFOTgI4YgU4YA0EYmuQgBiG1qJM6giUuAo2mOTmAw5Ses/qC7mYZjJRX9Z3Mg0+KqI8yYLlABLQI7utwq9zHa6BR9RErGGRZ3xk8k+coRDuSgM68Qz+Fs4IkVcRrDhGMqIixmHXE8foLojXsTDONLfCrwi3h1txdxVtrJmPixrXb4sRJ06xiHeExPlZLz9+8v5jKydhDJ91D18uNWHt8tvil5vHHb9mWdyno4lylxQrq6ybAo5/oarj2WuLpa3ulje6iryAVhBxACskFMmrnJwkDUBly7JeThOn85yt0zLPLuLcGXiSScnIdatkwHZhx+aX0QmJgrx+utC7+oq/h31lbjYYpDhQvp6QAPDNbUfogy1OjVwQgBCtMcmkQw5d0c0fMXSWrNFXRwWn+BdkQgXQ4CWBgdRFaeFI1IMc2CVwU1xD8VNAiVlmPSeWC38ECUGYbEogbvCH9fF72grdqOZiICcRPQ2Spvsq+RNeRyCceLNPvjeJCbTQCdOQ84PMxvhhuWBgUJMnJgmwsMPiVmz0sTyDnIY9dfxtWGboCDz+a7Wrzde/6+GnIT1kGMjse77wn/BbrW0NCFq1pTzypw5Y/VudvtN6SMncBbpbo7Zxeefy3Sff96+6eYT/oarj2WuLpa3ulje6mIAlg8YgBVyzz9vjAD++MPY1MvZWc4Cnz6gSk4W4s03hfjhB/MyT0mRE8S6ugrRvLmcTDajpCTjpIYZH7VqGYO+O3eEaNTIJIhJgaMhaBKAqIMjAhBiJkYLAYjdaGaSXGtsFedQKcs2g9/iVYurKuOsWI5+IhVasRWtxecYIQTkHFbKvFYxKGUyn5Xy6I4fxE3IOXdS4ChGYZZh3RWUE8XwUESgh5iPoQLQiwxTSolWZU+Jo/0/E7t+TxSrVhmbCGYs77SEJLFjhzDZxpK0NLn+x/nXxIUhH4u0m3csb1iU3bsnxJUrNu1it9+UY8eEaNlSiMOHc5dORsnJsnbw0iX7pptP+BuuPpa5ulje6mJ5q4sBWD5gAFZI3L0r+9W0bCnEvn3G5eXKGa/+J0yQAVT6iGDDBuO2P8i+RKJ4cZESF2da5qNGmUcyGSb5Fn//LZeXLGnsm9OsmRCPJwkV3t5C3LghdC/L2ppYlBSb0N6Q3i6EGmpyvsQbwge3DE3rOuJXs8M7IVkMxXyxFa3FQxQTx1BLPI/fRAVcEM2xUzgjKav4THggTjgiRbyIDUIAJs34lMcJ1BBr8LIQgLiACkKLVDEDcnLc1egpXPFIPHQqIQQgxmK6WY2VEiBlF0jxHFcXy1tdLG/1sczVxfJWF8tbXXkdgOXbKIhEufLnn3L0L2XKgSZNgA8+AN59F3g8RDYAObJaUpIczaxzZzmi28qVQJcuxnQA4MEDaH79FXB3l0N7z58vR74D5FDUhw4B334LDB4MXcPG2HPOF9HRwDN/H0YVAKJefex+9xfcuxCLEtX9EVr5JrQd2wMnTiCuYRt4XT+NNGjRBttwGtWxDW3QBHsxFROhgxa9EIFXsQRP4xSK4REOoT42oqPZ206FMxZgGBZgGJBhzq5LyGYkPgDx8AQA7EEo9NAYJg6ej2E4hjoIxn+YifeQAA98hPGIRWno4IjJmIyLqIj9Ad2xcp4bPFIWQv/Lr+jY+y3UeigHxwsNhWGY/JYtrfwciYiIiJ4wDMCo8BECeOMNGXxVrQrUqQOsWQN89BEQEiK30WjkdnfvytedOgGvvy4DsF9+AR4+lBN4phtS2+H77+HduDEchw0zDj/+3ntyjPcBA+RQ3ydOYHOloXghcR0A4Cv8jSoA5v5ZDyO3uQDwBwAEBJTFB11WYvCpevC6LifqnYsROAo5p0sr/IFAXMdlVAAgsB5h6IZINMceAMAUTEL2EyLnfKj8eyiFE6iFOjiOFDjhE4xBFAIN60uVAnqMqImxY4G9e4HoaFf4+Q3GIkOQ1QsOvXohNMc5ICIiInoycYZfKnwOHABOnQLc3IB9+4DVq4GOj2uLZsyQf5s3l5OUKjp2BOrWBSpXljViP/8MxMcDx44ZNtH8/jsaTZ8OzfXrgL+/nHNp+nS50sUF2wZ8Bz006JS4HpVwHgBQD4cBAHuS6ptkMSoKeOvLGnhPJ/NzFUGYhCmG9alwfhx8AYAGPbAWIzEbyXDGVrTBb48nDs5Lm9EBALAMAxGFQPj4AN9/D+zYAdy+LaetcnaWtVm9e8u/mU0ETURERETWYQBG+WPbNuDGDeu3P39eTta6ZAmweLFc1qOHnJwWgGF24osX5d969WTABcgoolUrWSvWu7dctnq1bFao0wFBQUCDBtDodHBKTIS+ZUs5Se6IEYaIQ6cDBn1ey9As8A0sgjOSURMnAQCHUc9itj/HSHTDOrTCH0iAR6ZvT8ABczASxfEAHbERuandAmSwVKpU1tt8hPHoi+8RjrnQaIBFi+Qcvgy0iIiIiPIOmyCSevR6wMEB+O034IUXgKZNjX2wsttv4EDZFu733401W6+9ZtzmxRdl2nq9fP3000Bqqmw22KIF4PE4+OnVC5g6VaZTurRc1rSpjDoOHcKD4GC4rFmL/QfcEB0t+zY1aQJ8+aVslfgl3sIL+A2DsBQb0BXOSEUMvPEfgjPJvAaR6GZ1ESXD1eptMzNliqy90umAPXtkbdydO4CPj4xPv/lGvpcEeGAV+iIoSFb2KTEsEREREeUdBmCU9/bvB159VdZA7d8PLF8ul//1lxwwo1w5+fq99+RAF/v3A089Zdx/8WIZfCn9ulJTZVPC0HQ9kHx85Otdu+TrGjVk4HXuHDBpknG7atVkbdgffxjz0bQpdK8OxokYP3zyZxC21/BGTIxxF61WBjMA8Dva4xLKowIuYwX6A1Bqv3JXY2WJ8nZtERgoxyIBZL4tDYbxwQcyMFMCzPSDZxARERFR3mITRMpby5YBzZoBZ84Ap08Dn38O/Pqrcf2GDfKvXi+Dr3v3gBUrjOtjYoAxY+Tzzz4Dhg+Xz0eNkhFKeumrcKpXBypWBDZvBho3Nt3uu+8AX1/Dy+1JTRFSwQHPjH8REZvrIibGNF0l+AIAPbRYhDcAAOVxBQAsjlZoDxMnWr+tRiMfc+dmH0wpgRn7dRERERGpjwEY5R0hgHHjZARTo4ZcNmUKkJho3CYyUv49flwGX4BpgLZwoVxesybw9tsywrhzB/jf/8yP17277PjUvLmxyeFjOh2wc6fs+rXznD90qyIArRaJJcqi/bs1DYMeWmMehmMyJiEcn6MujmAehlu/sxW0WmDtWmDCBFmjlTHOtCQwEFi3js0IiYiIiAo6NkGknBEi+8jgyhXg5k3A0VG2eatWTb4GgH79ZE3Unj0yoNqxw7jf8ePAtWtAmTJyHi9ABnKOj09Xpe9WRv7+spOTq2k/qshIOZ5G+iArIKAFerQ5gZ9+d4POxq9BMlwxBZNt2scWq1fLWBKQ8Wb37pk3RwwPl1OasRkhERERUeHAGjCyXd++snnfnTvGZWlpcoRCZRRCQA4RD8jRCEuUkFGQYuxY4JlnZNPDn382DcAAOVDH6tVyrq/AQGNEkp0SJUwCsMhIuWvGGq6oKGDO79VxGeWtSzcPZAyYgoKA9evl4I6KsDBZsxUQYHnbzz9nM0IiIiKiwoQ1YGQbnU62j0tNBVaulFUwAPD118DQoTIA2rBBDoCxf79cp/TBeuMNOWHyU0/JPlrdugFHjgCffCIDLUAuW79e1o7Fxsplb79tOqeXlVJSZEtFWweyyEs+PjJ+7dJFjq4oJznOejCMsDC5PQfOICIiIir8GICRba5fl8EXYAzAhJABGADcvw+0ayf7cSk1YEoAVqKEycTHeOst2cTw/Hnj+vHjZQC2d69x2eDBNmVRpwOmTZNzMicl2fwO7apkSRk8tWkja7EyBk6WRim0JLMRDYmIiIiocGEARrZJ38Tw77/lMO8PH8p+W87OQNu2svngm28C//0nt8s4CqGiRAngq6+Azp3l6+bNgdq1ZZPFo0eBrl2BDz+UUYyVIiOBIUOMlWdq8vEB5s+XAyyypoqIiIiILGEARrZJH4ABshZM6QsWFiZrwipWNG7n52ec58uSF14A+veXQ8+/9JIcbWLnTiAhQe6bBWWiYSXYuX0b6Nkz528tpzgQBhERERFZiwEY2SZ9YBUdDcyeLQfgAIDXXwc8PeUEVm+/LZc9+2z2oyUuWSLn9apVS7728pKPdDIGWzExwMiR5oNrqCkoCJgzh0O/ExEREZH1GICRbZQAbOhQ45xcgBxY47nn5PMhQ2RkcvEi0LRp9mlqtbLpYSYsDSOfHwIDZXe0ypXZvJCIiIiIcoYBGNlGCcBq1QLOnAH++Qe4exdo0ABweDyrgbOzjJpWrJDBWC4ow8jnx0iGDLiIiIiIyN4YgJH1hDAGYBUrAt7ecrh5S2rVAmbNytXhdDpZ86VG8OXhAYSH6+DktA/lyz+LoCBHBlxEREREZHcMwMh6sbFAXJx8Xj5vJzDW6eSIgnnd7LBUKRnkffABoNfrsXFjLDp2FDmZdoyIiIiIKFsMwMjUzZuAi4vlod+V2q+AAMDNLU8Or8zhNXeubNlob0rAZalZoV5v/+MREREREaXHAOxJd+YMcOIE8PLLchz3atWAsmWBU6eMfboU6Zsf2okyumFUFLB9O7B2LRAfb7fkDbp1k1OTtWzJZoVERERElH8YgD3pXnsN2LdPRiW3bgH378vH4cNyYA1Ajvn+44/AsWPytZ0CMLVGN/zhB6BHj7w9BhERERGRNRiAPen+/Vf+/eYbICnJuHzjRhmAPXgAtGoFnDxpXGeHAEyN0Q29veW80Jyni4iIiIgKCofsN6EiKz4euHdPPt+6VbYFVGzcCKSkyOjl5Ek5tLyienWbDqPTATt3AqtXy7+JicCgQXkXfJUqBUyZIiv0GHwRERERUUHCGrAn2bVrxudKNPTUU8C5c8ChQzJK+uMPOUb77t1AQoKc9+uFF6w+hKVmhhqN/YOvbt3kg/N1EREREVFBxgDsSZY+AFO8+aacQPnoUWDVKrlszRqgbl35vFkzq5Nft85y36u8qPkaNkwOsEFEREREVJCxCeKTTAnAWrYE/P0Bd3cZMXXsaNzmnXeATp1sTnrtWqBXL/tkMysaDRAUJGu9iIiIiIgKOgZgTzIlAHvqKeDAATnKYUAA0LMn4OgIPPssMH26zclGRspR7XU6+2Y3I41G/p0zh00OiYiIiKhwYBPEJ5kSgAUFAYGBxuU1awJXrgClS5sOvmEFnU72+bKXYsVkpVzx4rJF5J07xnWBgTL44kAbRERERFRYMAB7kqUPwDIKCLApKWVC5S++sM+8XqVKyUDugw+MtVuffSaPER3NwTaIiIiIqHBiAPYku3pV/rUUgNnA3hMqT5liGngptFoOtEFEREREhRv7gD1p1q+XAdf69VnXgFlJmVDZHsGXt7fM1sSJrNkiIiIioqKJAdiT5OBBoG9fGS198AHw6JFcnr7/lw2U/l65HVZeowEmT+bEyURERERU9LEJ4pPi3Dmga1cgOVm+PntW/vXxAdzccpTknj32qfmKiLA8XxgRERERUVHDGrAnwcaNQIMGcvSKp5+WzxU5bH6o0wELFuQuW0pLSAZfRERERPSkYA1YUXf2LNClC5CWBjRtCqxbB/zwA3DokFyfgwAsMhIYMgSIjbVtP29vWdt1+zZHMSQiIiKiJxMDsKJuyRIZfLVsCfz+u5zXKyzMOFlXuXI2JRcZCXTrlrOs9OsHtG6ds32JiIiIiIoCNkEsytLSgO++k8+HDzdOqhwYCDRuLJ8HB1uVlE4HbN8ODB6c8+x06ZLzfYmIiIiIigLWgBVF587JByD7fZUuDXTqZLrNvHnA/PnAwIHZJmePeb6CgmSTQyIiIiKiJxkDsKIoLAw4dcpY49W3r/G5on59YPnybJNS5vnK6VDzGo38O2cO+3sREREREbEJYlGTkgKcOWN8DgCDBuU4qf/9L3fzfAUGynE/OL8XERERERFrwIqeq1cBvV7O7TVqlBx6sHZtm5OJjJRxW1xczrIRHi77fHGkQyIiIiIiIwZgRc3Fi/JvhQrARx/lKIncjHTo7Q18/TVrvIiIiIiILGEAVtQoAVjFijnaXaeTAybmRLducp4v1ngREREREVnGPmBFzaVL8m+FCjnafc8eICoqZ4ceNozBFxERERFRVlgDVtTksgbsp59s30ejkYNtcJh5IiIiIqKssQasqMlFALZunRwu3hYcZp6IiIiIyHoMwIoSIXLcBHHtWqBXL9sPyWHmiYiIiIisxyaIRcnt20BCgqyWCgmxerfISODll207FIeZJyIiIiKyHQOwouD0aWDGDKBVK/k6KAhwcbFqV50OGDHC+kN5eADLl7PGi4iIiIgoJxiAFQWffAJ8/70cAx6wqfnhnj3A9evWH2rDBqB1a9uyR0REREREEvuAFQUHD8q/qanyrw0DcERHW3+YoCCgZUvrtyciIiIiIlMMwAq7uDjg7FnTZVYGYDodsGWL9YfiSIdERERERLnDAKywO3xYjn6YvnqqUaNsd4uMBHx9gWXLsj+EVitHSWS/LyIiIiKi3GEfsMLu0CH5t2FD4LvvgFOngPr1s9wlMhLo1s36Q6xeDXTvnos8EhERERERANaAFX5KANagAeDmlm3wZeuoh1OmAD165CJ/RERERERkwACssEsfgFnB1lEPK1fOQZ6IiIiIiMgiBmCF2Z07wH//yef16lm1y08/2XYIPz8b80RERERERJliAFaY/fCD/Fu1KlC8eLabR0bKkQytFRQEhIbmLGtERERERGSOg3AURno90L8/sHKlfN2xY7a76HTAkCHWH0Kj4bDzRERERET2xhqwwmj3bhl8abXAuHHAtGnZ7vLRR0BsrHXJe3sD69Zx2HkiIiIiInvL9wBswYIFCAkJgaurKxo1aoSDBw9muf2cOXNQpUoVuLm5ISgoCCNHjkRSUpJh/eTJk6HRaEweVatWzeu3oa6rV+XfVq2A6dMBV9csN1+7Vo5maI1u3YBbtxh8ERERERHlhXxtghgREYFRo0Zh0aJFaNSoEebMmYP27dvj7NmzKFOmjNn2q1atwtixY7FkyRI0adIE586dw8CBA6HRaDB79mzDdk8//TS2bdtmeO3oWMRaWt68Kf+WLZvtppGRwMsvW5/0sGFsdkhERERElFfytQZs9uzZGDx4MAYNGoTq1atj0aJFcHd3x5IlSyxuv3fvXjRt2hR9+vRBSEgI2rVrh969e5vVmjk6OqJs2bKGR+nSpdV4O+qJjpZ/swnAbJ3zy9ubg24QEREREeWlfKsaSklJweHDhzFu3DjDMgcHB7Rp0wb79u2zuE+TJk3w/fff4+DBg2jYsCEuXbqEjRs3ol+/fibbnT9/Hv7+/nB1dUXjxo0xY8YMlCtXLtO8JCcnIzk52fA6Li4OAJCamorU1NTcvM0cU45r6fjaGzfgAEBXpgz0WeRv1y4Nrl+3/iMeOlQHvV4Pvd7m7BYJWZU52R/LW10sb3WxvNXHMlcXy1tdLG91ZSxve5e7Rggh7JqilW7cuIGAgADs3bsXjRs3Nix/7733sGvXLhw4cMDifvPmzcPo0aMhhEBaWhreeOMNLFy40LB+06ZNiI+PR5UqVRAdHY0pU6YgKioK//zzDzw9PS2mOXnyZEyx0Elq1apVcHd3z+U7tb8m48fD559/8PeoUYhq3jzT7RYvfhq//FLJihQFPD1TsGzZZjY/JCIiIiJK59GjR+jTpw8ePHgALy+vXKdXqAKwnTt3olevXvjoo4/QqFEjXLhwASNGjMDgwYMxYcIEi8e5f/8+goODMXv2bLz22msWt7FUAxYUFISYmBi7FHJOpKamYuvWrWjbti2cnJxM1jnWqAHNuXNI27IFomVLi/v/+KMGPXtqAWisOJpARIQOL72UL6dCgZFVmZP9sbzVxfJWF8tbfSxzdbG81cXyVlfG8o6Li0Pp0qXtFoDlWxPE0qVLQ6vV4tatWybLb926hbKZ9G2aMGEC+vXrh9dffx0AULNmTSQkJGDIkCH44IMP4OBg3qWtRIkSeOqpp3DhwoVM8+Li4gIXFxez5U5OTvl+klvMw+MycwwKAizkT6cD3nnHuvS1WmDNGg26dy9iA5XkQkH43J8kLG91sbzVxfJWH8tcXSxvdbG81aWUt73LPN8G4XB2dka9evWwfft2wzK9Xo/t27eb1Iil9+jRI7MgS/u4zVxmFXnx8fG4ePEi/Pz87JTzfJaYCDx4IJ9nEqju2QNcv25dcqtXA9272ylvRERERESUpXyt9hg1ahQGDBiA+vXro2HDhpgzZw4SEhIwaNAgAED//v0REBCAGTNmAAA6d+6M2bNno27duoYmiBMmTEDnzp0Ngdjo0aPRuXNnBAcH48aNG5g0aRK0Wi169+6db+/TrpQh6F1cgOLFLW6iDJKYnfBwoEcP+2SLiIiIiIiyl68BWM+ePXHnzh1MnDgRN2/eRJ06dbB582b4+voCAK5evWpS4zV+/HhoNBqMHz8eUVFR8PHxQefOnTFt2jTDNtevX0fv3r0RGxsLHx8fNGvWDPv374ePj4/q7y9PKAGYnx+gsdy/6/x565Lq0sVOeSIiIiIiIqvke8efYcOGYdiwYRbX7dy50+S1o6MjJk2ahEmTJmWa3po1a+yZvYInm0mYIyOBLIoHgIzbAgM55xcRERERkdrydSJmyoEsJmG2ZeLlOXPAIeeJiIiIiFTGAKywSd8EMQNrB9+YPBkIC7NvtoiIiIiIKHsMwAqbLJogWjv4RuXKdswPERERERFZjQFYYZNFE0RrB98oKiPyExEREREVNvk+CAfZKJMaMA6+QURERERU8LEGrLCx0AeMg28QERERERUODMAKE73eYg0YB98gIiIiIiocGIAVFrt2Ae3aAWlp8vXjyaoBDr5BRERERFRYsA9YYdGzJ3DrluzI9b//Ac7OhlXWDqrBwTeIiIiIiPIXA7DCQKeTwRcAHDsG1Kplsjo0VA6uERUFCGG+OwffICIiIiIqGNgEsTB4+ND4/KmnzFZrtcDcufK5RmO6TnnNwTeIiIiIiPIfA7DC4MED+dfZGXB1tbhJWBiwbh0QEGC6PDBQLufgG0RERERE+Y9NEAsDJQArXjzLzcLCgC5d5KiI0dGyz1doKGu+iIiIiIgKCgZghYESgJUokekmOp1p4PXyywy8iIiIiIgKGgZghUE2NWCRkXIi5vRzgQUGyn5hbHpIRERERFRwsA9YYZBFABYZCXTvbj4Rc1SUXB4ZqUL+iIiIiIjIKgzACoNMAjCdTtZ8WRp6XlkWHi63IyIiIiKi/McArDDIJADbs8e85is9IYBr1+R2RERERESU/xiAFQaZBGDR0dbtbu12RERERESUtxiAFQaZBGB+ftbtbu12RERERESUtxiAFQaZBGChoXK0Q43G8m4aDRAUJLcjIiIiIqL8xwCsMMgkANNqgc8/tzwIhxKUzZnD+cCIiIiIiAoKBmCFQSYBWGQkMHKk5V0CA4F16zgPGBERERFRQcKJmAsDCwGYMv+XpdovAPjsMwZfREREREQFDWvACoP79+XfxwFYVvN/AbL54TvvcP4vIiIiIqKChgFYYZChBozzfxERERERFU4MwAo6nQ54+FA+fxyAcf4vIiIiIqLCiQFYQacEX4AhAOP8X0REREREhRMDsIJOaX7o7Ay4ugLg/F9ERERERIUVA7CCzsIIiFotMHeufJ4xCOP8X0REREREBRcDsAJOExcnn2SYAywsTM7zFRBguj3n/yIiIiIiKrg4D1hBl8kkzIAMsrp0kaMdRkfLPl+hoaz5IiIiIiIqqBiAFXRZBGCADLZatlQvO0RERERElHM2N0EMCQnB1KlTcfXq1bzID2WQWRNEQI5Qv3MnsHq1/MuJl4mIiIiICjabA7Dw8HBERkaiQoUKaNu2LdasWYPk5OS8yBsBmdaARUYCISHAc88BffrIvyEhcjkRERERERVMOQrAjh07hoMHD6JatWp4++234efnh2HDhuHIkSN5kccnm4UALDIS6N4duH7ddNOoKLmcQRgRERERUcGU41EQn3nmGcybNw83btzApEmT8O2336JBgwaoU6cOlixZAiGEPfP55MrQBFGnA0aMACwVr7IsPJzNEYmIiIiICqIcB2Cpqan44Ycf8OKLL+Kdd95B/fr18e2336Jbt254//330bdvX3vm84mlyVADtmePec1XekIA167J7YiIiIiIqGCxeRTEI0eOYOnSpVi9ejUcHBzQv39/fP7556hataphm5deegkNGjSwa0afWBlqwKKjrdvN2u2IiIiIiEg9NgdgDRo0QNu2bbFw4UJ07doVTk5OZtuUL18evXr1sksGn3gZasD8/KzbzdrtiIiIiIhIPTYHYJcuXUJwcHCW2xQrVgxLly7NcabISPPwoXzyOAALDQUCA+WAG5b6gWk0cn1oqIqZJCIiIiIiq9jcB+z27ds4cOCA2fIDBw7g77//tkumyCjt77+Bhw8Nsy1rtcDcuXKdRmO6rfJ6zhy5HRERERERFSw2B2BDhw7FtWvXzJZHRUVh6NChdskUpaPRAB4eQLqmnmFhwLp1QECA6aaBgXJ5WJjKeSQiIiIiIqvY3ATx9OnTeOaZZ8yW161bF6dPn7ZLpih7YWFAly5ytMPoaNnnKzSUNV9ERERERAWZzQGYi4sLbt26hQoVKpgsj46OhqOjzclRLmi1hpaJRERERERUCNjcBLFdu3YYN24cHiij8wG4f/8+3n//fbRt29aumSMiIiIiIipKbK6ymjVrFpo3b47g4GDUrVsXAHDs2DH4+vriu+++s3sGiYiIiIiIigqbA7CAgACcOHECK1euxPHjx+Hm5oZBgwahd+/eFucEIyIiIiIiIilHnbaKFSuGIUOG2DsvRERERERERVqOR804ffo0rl69ipSUFJPlL774Yq4zRUREREREVBTZHIBdunQJL730Ek6ePAmNRgMhBABA83gWYJ1OZ98cEhERERERFRE2j4I4YsQIlC9fHrdv34a7uztOnTqF3bt3o379+ti5c2ceZJGIiIiIiKhosLkGbN++ffjjjz9QunRpODg4wMHBAc2aNcOMGTMwfPhwHD16NC/ySenodJyAmYiIiIioMLK5Bkyn08HT0xMAULp0ady4cQMAEBwcjLNnz9o3d2QmMhIICQGeew7o00f+DQmRy4mIiIiIqGCzuQasRo0aOH78OMqXL49GjRph5syZcHZ2xtdff40KFSrkRR7pschIoHt34HG3O4OoKLl83TogLCx/8kZERERERNmzuQZs/Pjx0Ov1AICpU6fi8uXLCA0NxcaNGzFv3jy7Z5AknQ4YMcI8+AKMy8LD5XZERERERFQw2VwD1r59e8PzSpUq4d9//8Xdu3dRsmRJw0iIZH979gDXr2e+Xgjg2jW5XcuWqmWLiIiIiIhsYFMNWGpqKhwdHfHPP/+YLC9VqhSDrzwWHW3f7YiIiIiISH02BWBOTk4oV64c5/rKB35+9t2OiIiIiIjUZ3MfsA8++ADvv/8+7t69mxf5oUyEhgKBgUBmFY0aDRAUJLcjIiIiIqKCyeY+YF988QUuXLgAf39/BAcHo1ixYibrjxw5YrfMkZFWC8ydK0c71GhMB+NQgrI5czgfGBERERFRQWZzANa1a9c8yAZZIyxMDjU/YoTpgByBgTL44hD0REREREQFm80B2KRJk/IiH2SlsDCgSxc52mF0tOzzFRrKmi8iIiIiosLA5j5g9rZgwQKEhITA1dUVjRo1wsGDB7Pcfs6cOahSpQrc3NwQFBSEkSNHIikpKVdpFjZarRxqvndv+ZfBFxERERFR4WBzAObg4ACtVpvpwxYREREYNWoUJk2ahCNHjqB27dpo3749bt++bXH7VatWYezYsZg0aRLOnDmDxYsXIyIiAu+//36O0yQiIiIiIlKLzU0Qf/zxR5PXqampOHr0KJYvX44pU6bYlNbs2bMxePBgDBo0CACwaNEi/Pbbb1iyZAnGjh1rtv3evXvRtGlT9OnTBwAQEhKC3r1748CBAzlOk4iIiIiISC02B2BdunQxW9a9e3c8/fTTiIiIwGuvvWZVOikpKTh8+DDGjRtnWObg4IA2bdpg3759Fvdp0qQJvv/+exw8eBANGzbEpUuXsHHjRvTr1y/HaQJAcnIykpOTDa/j4uIAyOAyNTXVqvdjb8px8+v4TyKWubpY3upieauL5a0+lrm6WN7qYnmrK2N527vcbQ7AMvPss89iyJAhVm8fExMDnU4HX19fk+W+vr74999/Le7Tp08fxMTEoFmzZhBCIC0tDW+88YahCWJO0gSAGTNmWKy927JlC9zd3a1+T3lh69at+Xr8JxHLXF0sb3WxvNXF8lYfy1xdLG91sbzVpZT3o0eP7JquXQKwxMREzJs3DwEBAfZILlM7d+7E9OnT8eWXX6JRo0a4cOECRowYgQ8//BATJkzIcbrjxo3DqFGjDK/j4uIQFBSEdu3awcvLyx5Zt1lqaiq2bt2Ktm3bwsnJKV/y8KRhmauL5a0ulre6WN7qY5mri+WtLpa3ujKWt9I6zl5sDsBKliwJjTLzLwAhBB4+fAh3d3d8//33VqdTunRpaLVa3Lp1y2T5rVu3ULZsWYv7TJgwAf369cPrr78OAKhZsyYSEhIwZMgQfPDBBzlKEwBcXFzg4uJittzJySnfT/KCkIcnDctcXSxvdbG81cXyVh/LXF0sb3WxvNWllLe9y9zmAOzzzz83CcAcHBzg4+ODRo0aoWTJklan4+zsjHr16mH79u2GyZ31ej22b9+OYcOGWdzn0aNHcHAwHbhRGXlRCJGjNImIiIiIiNRicwA2cOBAux181KhRGDBgAOrXr4+GDRtizpw5SEhIMIxg2L9/fwQEBGDGjBkAgM6dO2P27NmoW7euoQnihAkT0LlzZ0Mgll2aRERERERE+cXmAGzp0qXw8PBAjx49TJavXbsWjx49woABA6xOq2fPnrhz5w4mTpyImzdvok6dOti8ebNhEI2rV6+a1HiNHz8eGo0G48ePR1RUFHx8fNC5c2dMmzbN6jSJiIiIiIjyi80B2IwZM/DVV1+ZLS9TpgyGDBliUwAGAMOGDcu0eeDOnTtNXjs6OmLSpEmYNGlSjtMkIiIiIiLKLzYHYFevXkX58uXNlgcHB+Pq1at2yRRZptMBe/YA0dGAnx8QGgo8bnlJRERERESFgEP2m5gqU6YMTpw4Ybb8+PHj8Pb2tkumyFxkJBASAjz3HNCnj/wbEiKXExERERFR4WBzANa7d28MHz4cO3bsgE6ng06nwx9//IERI0agV69eeZHHJ15kJNC9O3D9uunyqCi5nEEYEREREVHhYHMTxA8//BBXrlxB69at4egod9fr9ejfvz+mT59u9ww+6XQ6YMQIQAjzdUIAGg0QHg506cLmiEREREREBZ3NAZizszMiIiLw0Ucf4dixY3Bzc0PNmjURHBycF/l74v35p8as5is9IYBr12TfsJYtVcsWERERERHlgM0BmKJy5cqoXLmyPfNCFkRH23c7IiIiIiLKPzb3AevWrRs++eQTs+UzZ840mxuMcs/Pz77bERERERFR/rE5ANu9ezc6duxotvz555/H7t277ZIpMmrWTCAwUPb1skSjAYKC5JD0RERERERUsNkcgMXHx8PZ2dlsuZOTE+Li4uySKTLSaoG5c+XzjEGY8nrOHA7AQURERERUGNgcgNWsWRMRERFmy9esWYPq1avbJVNkKiwMWLcOCAgwXR4YKJeHheVPvoiIiIiIyDY2D8IxYcIEhIWF4eLFi2jVqhUAYPv27Vi1ahXWrVtn9wySFBYmh5rfs0cOuOHnJ5sdsuaLiIiIiKjwsDkA69y5MzZs2IDp06dj3bp1cHNzQ+3atfHHH3+gVKlSeZFHekyr5VDzRERERESFWY6Goe/UqRM6deoEAIiLi8Pq1asxevRoHD58GDqdzq4ZJCIiIiIiKips7gOm2L17NwYMGAB/f3989tlnaNWqFfbv32/PvBERERERERUpNtWA3bx5E8uWLcPixYsRFxeHl19+GcnJydiwYQMH4CAiIiIiIsqG1TVgnTt3RpUqVXDixAnMmTMHN27cwPz58/Myb0REREREREWK1TVgmzZtwvDhw/Hmm2+icuXKeZknIiIiIiKiIsnqGrA///wTDx8+RL169dCoUSN88cUXiImJycu8ERERERERFSlWB2DPPvssvvnmG0RHR+N///sf1qxZA39/f+j1emzduhUPHz7My3wSEREREREVejaPglisWDG8+uqr+PPPP3Hy5Em88847+Pjjj1GmTBm8+OKLeZFHIiIiIiKiIiHHw9ADQJUqVTBz5kxcv34dq1evtleeiIiIiIiIiqRcBWAKrVaLrl274ueff7ZHckREREREREWSXQIwIiIiIiIiyh4DMCIiIiIiIpUwACMiIiIiIlIJAzAiIiIiIiKVMAAjIiIiIiJSCQMwIiIiIiIilTAAIyIiIiIiUgkDMCIiIiIiIpUwACMiIiIiIlIJAzAiIiIiIiKVMAAjIiIiIiJSCQMwIiIiIiIilTAAIyIiIiIiUoljfmeAsqfTAXv2ANHRgJ8fEBoKaLX5nSsiIiIiIrIVA7AC7scfNXjnHeD6deOywEBg7lwgLCz/8kVERERERLZjE8QCbN8+P/TqpTUJvgAgKgro3h2IjMyffBERERERUc4wACugdDrg229rQgjzdcqy8HC5HRERERERFQ4MwAqoP//UIDbWDYDG4nohgGvXZN8wIiIiIiIqHBiAFVDR0fbdjoiIiIiI8h8DsALKz8++2xERERERUf5jAFZANWsm4O2dCI3GQicwABoNEBQkh6QnIiIiIqLCgQFYAaXVAq+/fhKADLbSU17PmcP5wIiIiIiIChMGYAVY48bRWLNGh4AA0+WBgcC6dZwHjIiIiIiosOFEzAXcSy8JdOsmRzuMjpZ9vkJDWfNFRERERFQYMQArBLRaoGXL/M4FERERERHlFpsgEhERERERqYQBGBERERERkUoYgBEREREREamEARgREREREZFKGIARERERERGphAEYERERERGRShiAERERERERqYQBGBERERERkUoYgBEREREREamEARgREREREZFKGIARERERERGphAEYERERERGRShiAERERERERqYQBGBERERERkUoYgBEREREREamEARgREREREZFKGIARERERERGppEAEYAsWLEBISAhcXV3RqFEjHDx4MNNtW7ZsCY1GY/bo1KmTYZuBAweare/QoYMab4WIiIiIiChTjvmdgYiICIwaNQqLFi1Co0aNMGfOHLRv3x5nz55FmTJlzLaPjIxESkqK4XVsbCxq166NHj16mGzXoUMHLF261PDaxcUl794EERERERGRFfI9AJs9ezYGDx6MQYMGAQAWLVqE3377DUuWLMHYsWPNti9VqpTJ6zVr1sDd3d0sAHNxcUHZsmWtykNycjKSk5MNr+Pi4gAAqampSE1Nten92Ity3Pw6/pOIZa4ulre6WN7qYnmrj2WuLpa3ulje6spY3vYud40QQtg1RRukpKTA3d0d69atQ9euXQ3LBwwYgPv37+Onn37KNo2aNWuicePG+Prrrw3LBg4ciA0bNsDZ2RklS5ZEq1at8NFHH8Hb29tiGpMnT8aUKVPMlq9atQru7u62vzEiIiIiIioSHj16hD59+uDBgwfw8vLKdXr5GoDduHEDAQEB2Lt3Lxo3bmxY/t5772HXrl04cOBAlvsfPHgQjRo1woEDB9CwYUPDcqVWrHz58rh48SLef/99eHh4YN++fdBqtWbpWKoBCwoKQkxMjF0KOSdSU1OxdetWtG3bFk5OTvmShycNy1xdLG91sbzVxfJWH8tcXSxvdbG81ZWxvOPi4lC6dGm7BWD53gQxNxYvXoyaNWuaBF8A0KtXL8PzmjVrolatWqhYsSJ27tyJ1q1bm6Xj4uJisY+Yk5NTvp/kBSEPTxqWubpY3upieauL5a0+lrm6WN7qYnmrSylve5d5vo6CWLp0aWi1Wty6dctk+a1bt7Ltv5WQkIA1a9bgtddey/Y4FSpUQOnSpXHhwoVc5ZeIiIiIiCg38jUAc3Z2Rr169bB9+3bDMr1ej+3bt5s0SbRk7dq1SE5OxiuvvJLtca5fv47Y2Fj4+fnlOs9EREREREQ5le/zgI0aNQrffPMNli9fjjNnzuDNN99EQkKCYVTE/v37Y9y4cWb7LV68GF27djUbWCM+Ph7vvvsu9u/fjytXrmD79u3o0qULKlWqhPbt26vynoiIiIiIiCzJ9z5gPXv2xJ07dzBx4kTcvHkTderUwebNm+Hr6wsAuHr1KhwcTOPEs2fP4s8//8SWLVvM0tNqtThx4gSWL1+O+/fvw9/fH+3atcOHH37IucCIiIiIiChf5XsABgDDhg3DsGHDLK7buXOn2bIqVaogs8Eb3dzc8Pvvv9sze0RERERERHaR700QiYiIiIiInhQMwIiIiIiIiFTCAIyIiIiIiEglDMCIiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCUMwIiIiIiIiFTCAIyIiIiIiEglDMCIiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCUMwIiIiIiIiFTCAIyIiIiIiEglDMCIiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCUMwIiIiIiIiFTCAIyIiIiIiEglDMCIiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCUMwIiIiIiIiFTCAIyIiIiIiEglDMCIiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCUMwIiIiIiIiFTCAIyIiIiIiEglDMCIiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCUMwIiIiIiIiFTCAIyIiIiIiEglDMCIiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCUMwIiIiIiIiFTCAIyIiIiIiEglDMCIiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCUMwIiIiIiIiFTCAIyIiIiIiEglDMCIiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCUMwIiIiIiIiFTCAIyIiIiIiEglDMCIiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCUMwIiIiIiIiFTCAIyIiIiIiEglBSIAW7BgAUJCQuDq6opGjRrh4MGDmW7bsmVLaDQas0enTp0M2wghMHHiRPj5+cHNzQ1t2rTB+fPn1XgrREREREREmcr3ACwiIgKjRo3CpEmTcOTIEdSuXRvt27fH7du3LW4fGRmJ6Ohow+Off/6BVqtFjx49DNvMnDkT8+bNw6JFi3DgwAEUK1YM7du3R1JSklpvi4iIiIiIyEy+B2CzZ8/G4MGDMWjQIFSvXh2LFi2Cu7s7lixZYnH7UqVKoWzZsobH1q1b4e7ubgjAhBCYM2cOxo8fjy5duqBWrVpYsWIFbty4gQ0bNqj4zoiIiIiIiEw55ufBU1JScPjwYYwbN86wzMHBAW3atMG+ffusSmPx4sXo1asXihUrBgC4fPkybt68iTZt2hi2KV68OBo1aoR9+/ahV69eZmkkJycjOTnZ8DouLg4AkJqaitTU1By9t9xSjptfx38SsczVxfJWF8tbXSxv9bHM1cXyVhfLW10Zy9ve5Z6vAVhMTAx0Oh18fX1Nlvv6+uLff//Ndv+DBw/in3/+weLFiw3Lbt68aUgjY5rKuoxmzJiBKVOmmC3fsmUL3N3ds81HXtq6dWu+Hv9JxDJXF8tbXSxvdbG81ccyVxfLW10sb3Up5f3o0SO7ppuvAVhuLV68GDVr1kTDhg1zlc64ceMwatQow+u4uDgEBQWhXbt28PLyym02cyQ1NRVbt25F27Zt4eTklC95eNKwzNXF8lYXy1tdLG/1sczVxfJWF8tbXRnLW2kdZy/5GoCVLl0aWq0Wt27dMll+69YtlC1bNst9ExISsGbNGkydOtVkubLfrVu34OfnZ5JmnTp1LKbl4uICFxcXs+VOTk75fpIXhDw8aVjm6mJ5q4vlrS6Wt/pY5upieauL5a0upbztXeb5OgiHs7Mz6tWrh+3btxuW6fV6bN++HY0bN85y37Vr1yI5ORmvvPKKyfLy5cujbNmyJmnGxcXhwIED2aZJRERERESUl/K9CeKoUaMwYMAA1K9fHw0bNsScOXOQkJCAQYMGAQD69++PgIAAzJgxw2S/xYsXo2vXrvD29jZZrtFoEB4ejo8++giVK1dG+fLlMWHCBPj7+6Nr165qvS0iIiIiIiIz+R6A9ezZE3fu3MHEiRNx8+ZN1KlTB5s3bzYMonH16lU4OJhW1J09exZ//vkntmzZYjHN9957DwkJCRgyZAju37+PZs2aYfPmzXB1dc3z90NERERERJSZfA/AAGDYsGEYNmyYxXU7d+40W1alShUIITJNT6PRYOrUqWb9w4iIiIiIiPJTvk/ETERERERE9KRgAEZERERERKQSBmBEREREREQqYQBGRERERESkEgZgREREREREKmEARkREREREpBIGYERERERERCphAEZERERERKSSAjERM1mm0wG7dmlw5w7g5weEhgJabX7nioiIiIiIcooBWAH1448avPVWO8TGGj+iwEBg7lwgLCwfM0ZERERERDnGJogFUGQk0KuXFrGxribLo6KA7t3leiIiIiIiKnwYgBUwOh0wYgQgBABoTNbJZUB4uNyOiIiIiIgKFwZgBcyePcD160DG4EshBHDtmtyOiIiIiIgKFwZgBUx0tH23IyIiIiKigoMBWAHj52ff7YiIiIiIqOBgAFbAhIbK0Q41GmFxvUYDBAXJ7YiIiIiIqHBhAFbAaLVyqHnJNAjTPO4WNmcO5wMjIiIiIiqMGIAVQGFhwJo1Onh7J5ksDwwE1q3jPGBERERERIUVJ2IuoF56ScDRcQu8vDrhzh1H+PnJZoes+SIiIiIiKrwYgBVgWi3QooWAk1N+54SIiIiIiOyBTRCJiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCUMwIiIiIiIiFTCAIyIiIiIiEglDMCIiIiIiIhUwgCMiIiIiIhIJQzAiIiIiIiIVMIAjIiIiIiISCWO+Z2BgkgIAQCIi4vLtzykpqbi0aNHiIuLg5OTU77l40nCMlcXy1tdLG91sbzVxzJXF8tbXSxvdWUsbyUmUGKE3GIAZsHDhw8BAEFBQfmcEyIiIiIiKggePnyI4sWL5zodjbBXKFeE6PV63LhxA56entBoNPmSh7i4OAQFBeHatWvw8vLKlzw8aVjm6mJ5q4vlrS6Wt/pY5upieauL5a2ujOUthMDDhw/h7+8PB4fc9+BiDZgFDg4OCAwMzO9sAAC8vLz4RVMZy1xdLG91sbzVxfJWH8tcXSxvdbG81ZW+vO1R86XgIBxEREREREQqYQBGRERERESkEgZgBZSLiwsmTZoEFxeX/M7KE4Nlri6Wt7pY3upieauPZa4ulre6WN7qyuvy5iAcREREREREKmENGBERERERkUoYgBEREREREamEARgREREREZFKGIARERERERGphAFYAbVgwQKEhITA1dUVjRo1wsGDB/M7S0XC5MmTodFoTB5Vq1Y1rE9KSsLQoUPh7e0NDw8PdOvWDbdu3crHHBcuu3fvRufOneHv7w+NRoMNGzaYrBdCYOLEifDz84ObmxvatGmD8+fPm2xz9+5d9O3bF15eXihRogRee+01xMfHq/guCo/synvgwIFm53uHDh1MtmF5W2/GjBlo0KABPD09UaZMGXTt2hVnz5412caa35CrV6+iU6dOcHd3R5kyZfDuu+8iLS1NzbdSKFhT3i1btjQ7x9944w2TbVje1lu4cCFq1aplmHy2cePG2LRpk2E9z2/7yq68eX7nrY8//hgajQbh4eGGZWqd4wzACqCIiAiMGjUKkyZNwpEjR1C7dm20b98et2/fzu+sFQlPP/00oqOjDY8///zTsG7kyJH45ZdfsHbtWuzatQs3btxAWFhYPua2cElISEDt2rWxYMECi+tnzpyJefPmYdGiRThw4ACKFSuG9u3bIykpybBN3759cerUKWzduhW//vordu/ejSFDhqj1FgqV7MobADp06GByvq9evdpkPcvbert27cLQoUOxf/9+bN26FampqWjXrh0SEhIM22T3G6LT6dCpUyekpKRg7969WL58OZYtW4aJEyfmx1sq0KwpbwAYPHiwyTk+c+ZMwzqWt20CAwPx8ccf4/Dhw/j777/RqlUrdOnSBadOnQLA89vesitvgOd3Xjl06BC++uor1KpVy2S5aue4oAKnYcOGYujQoYbXOp1O+Pv7ixkzZuRjroqGSZMmidq1a1tcd//+feHk5CTWrl1rWHbmzBkBQOzbt0+lHBYdAMSPP/5oeK3X60XZsmXFp59+alh2//594eLiIlavXi2EEOL06dMCgDh06JBhm02bNgmNRiOioqJUy3thlLG8hRBiwIABokuXLpnuw/LOndu3bwsAYteuXUII635DNm7cKBwcHMTNmzcN2yxcuFB4eXmJ5ORkdd9AIZOxvIUQokWLFmLEiBGZ7sPyzr2SJUuKb7/9lue3SpTyFoLnd155+PChqFy5sti6datJGat5jrMGrIBJSUnB4cOH0aZNG8MyBwcHtGnTBvv27cvHnBUd58+fh7+/PypUqIC+ffvi6tWrAIDDhw8jNTXVpOyrVq2KcuXKsezt4PLly7h586ZJ+RYvXhyNGjUylO++fftQokQJ1K9f37BNmzZt4ODggAMHDqie56Jg586dKFOmDKpUqYI333wTsbGxhnUs79x58OABAKBUqVIArPsN2bdvH2rWrAlfX1/DNu3bt0dcXJzJXW8yl7G8FStXrkTp0qVRo0YNjBs3Do8ePTKsY3nnnE6nw5o1a5CQkIDGjRvz/M5jGctbwfPb/oYOHYpOnTqZnMuAur/hjrl8D2RnMTEx0Ol0Jh8sAPj6+uLff//Np1wVHY0aNcKyZctQpUoVREdHY8qUKQgNDcU///yDmzdvwtnZGSVKlDDZx9fXFzdv3syfDBchShlaOreVdTdv3kSZMmVM1js6OqJUqVL8DHKgQ4cOCAsLQ/ny5XHx4kW8//77eP7557Fv3z5otVqWdy7o9XqEh4ejadOmqFGjBgBY9Rty8+ZNi98BZR1ZZqm8AaBPnz4IDg6Gv78/Tpw4gTFjxuDs2bOIjIwEwPLOiZMnT6Jx48ZISkqCh8f/27n/mKrqP47jr1twrxeMwC5x72wSCDExcYFltx9udRtBW6Wjpe6uXW2LoeD8Q1vqsuzHVn80+7XFVkv7QxdLN9I5tRCELZbmD67QJDYc/mhalKbhL8rx/v7huvve8Acq3gv0fGxnO/d8Dof3efPmsDfnnM9o1dbWKj8/X+FwmPq+CS6Xb4n6vhlqamq0d+9e7dq1q99YLK/hNGD4TyktLY2sFxQUaOrUqcrMzNRXX30lt9sdx8iAwTdr1qzI+qRJk1RQUKDx48ersbFRgUAgjpENf5WVlfrxxx+j3iHFzXO5fP//+4qTJk2Sz+dTIBDQgQMHNH78+FiHOSLk5eUpHA7r1KlTWr9+vUKhkJqamuId1oh1uXzn5+dT34PsyJEjWrhwoerq6jRq1Ki4xsIjiEOMx+PRrbfe2m/GlV9//VVerzdOUY1cqampuueee9TZ2Smv16u//vpLJ0+ejNqH3A+Of3J4pdr2er39Jpu5cOGCTpw4wc9gEGRnZ8vj8aizs1MS+b5eVVVV2rRpk7Zv36677rorsn0g1xCv13vJ34F/xtDf5fJ9KVOnTpWkqBon39fG6XQqJydHRUVFeueddzR58mR9+OGH1PdNcrl8Xwr1fWP27Nmj7u5uFRYWKiEhQQkJCWpqatJHH32khIQEZWRkxKzGacCGGKfTqaKiItXX10e29fX1qb6+PuqZYAyO06dP68CBA/L5fCoqKlJiYmJU7js6OnT48GFyPwiysrLk9Xqj8vvnn39q586dkfz6/X6dPHlSe/bsiezT0NCgvr6+yB8eXL+ff/5Zx48fl8/nk0S+r5WZqaqqSrW1tWpoaFBWVlbU+ECuIX6/X21tbVGNb11dnVJSUiKPHeGiq+X7UsLhsCRF1Tj5vjF9fX3q7e2lvmPkn3xfCvV9YwKBgNra2hQOhyPLlClTFAwGI+sxq/HBmE0Eg6umpsZcLpd98cUXtn//fisvL7fU1NSoGVdwfRYtWmSNjY3W1dVlzc3N9sQTT5jH47Hu7m4zM6uoqLBx48ZZQ0OD7d692/x+v/n9/jhHPXz09PRYS0uLtbS0mCRbuXKltbS02KFDh8zM7N1337XU1FTbsGGDtba22rPPPmtZWVl27ty5yDFKSkrsvvvus507d9p3331nubm5Nnv27Hid0pB2pXz39PTY4sWL7fvvv7euri7btm2bFRYWWm5urp0/fz5yDPI9cPPmzbPbb7/dGhsb7dixY5Hl7NmzkX2udg25cOGC3XvvvVZcXGzhcNi2bt1q6enptnTp0nic0pB2tXx3dnbam2++abt377auri7bsGGDZWdn27Rp0yLHIN/XZsmSJdbU1GRdXV3W2tpqS5YsMYfDYd9++62ZUd+D7Ur5pr5j498zTcaqxmnAhqiPP/7Yxo0bZ06n0x544AHbsWNHvEMaEWbOnGk+n8+cTqeNHTvWZs6caZ2dnZHxc+fO2fz58y0tLc2SkpJsxowZduzYsThGPLxs377dJPVbQqGQmV2cin758uWWkZFhLpfLAoGAdXR0RB3j+PHjNnv2bBs9erSlpKTY3LlzraenJw5nM/RdKd9nz5614uJiS09Pt8TERMvMzLSXXnqp3z9yyPfAXSrXkmz16tWRfQZyDTl48KCVlpaa2+02j8djixYtsr///jvGZzP0XS3fhw8ftmnTptmYMWPM5XJZTk6Ovfzyy3bq1Kmo45DvgXvxxRctMzPTnE6npaenWyAQiDRfZtT3YLtSvqnv2Ph3AxarGneYmV3zPTwAAAAAwDXjHTAAAAAAiBEaMAAAAACIERowAAAAAIgRGjAAAAAAiBEaMAAAAACIERowAAAAAIgRGjAAAAAAiBEaMAAAAACIERowAABukMPh0Ndffx3vMAAAwwANGABgWJszZ44cDke/paSkJN6hAQDQT0K8AwAA4EaVlJRo9erVUdtcLlecogEA4PK4AwYAGPZcLpe8Xm/UkpaWJuni44HV1dUqLS2V2+1Wdna21q9fH/X1bW1tevzxx+V2u3XHHXeovLxcp0+fjtpn1apVmjhxolwul3w+n6qqqqLGf//9d82YMUNJSUnKzc3Vxo0bI2N//PGHgsGg0tPT5Xa7lZub269hBAD8N9CAAQBGvOXLl6usrEz79u1TMBjUrFmz1N7eLkk6c+aMnnzySaWlpWnXrl1at26dtm3bFtVgVVdXq7KyUuXl5Wpra9PGjRuVk5MT9T3eeOMNPf/882ptbdVTTz2lYDCoEydORL7//v37tWXLFrW3t6u6uloejyd2CQAADBkOM7N4BwEAwPWaM2eO1qxZo1GjRkVtX7ZsmZYtWyaHw6GKigpVV1dHxh588EEVFhbqk08+0WeffaZXXnlFR44cUXJysiRp8+bNevrpp3X06FFlZGRo7Nixmjt3rt5+++1LxuBwOPTqq6/qrbfeknSxqRs9erS2bNmikpISPfPMM/J4PFq1atVNygIAYLjgHTAAwLD32GOPRTVYkjRmzJjIut/vjxrz+/0Kh8OSpPb2dk2ePDnSfEnSww8/rL6+PnV0dMjhcOjo0aMKBAJXjKGgoCCynpycrJSUFHV3d0uS5s2bp7KyMu3du1fFxcWaPn26Hnrooes6VwDA8EYDBgAY9pKTk/s9EjhY3G73gPZLTEyM+uxwONTX1ydJKi0t1aFDh7R582bV1dUpEAiosrJS77333qDHCwAY2ngHDAAw4u3YsaPf5wkTJkiSJkyYoH379unMmTOR8ebmZt1yyy3Ky8vTbbfdprvvvlv19fU3FEN6erpCoZDWrFmjDz74QJ9++ukNHQ8AMDxxBwwAMOz19vbql19+idqWkJAQmehi3bp1mjJlih555BGtXbtWP/zwgz7//HNJUjAY1Ouvv65QKKQVK1bot99+04IFC/TCCy8oIyNDkrRixQpVVFTozjvvVGlpqXp6etTc3KwFCxYMKL7XXntNRUVFmjhxonp7e7Vp06ZIAwgA+G+hAQMADHtbt26Vz+eL2paXl6effvpJ0sUZCmtqajR//nz5fD59+eWXys/PlyQlJSXpm2++0cKFC3X//fcrKSlJZWVlWrlyZeRYoVBI58+f1/vvv6/FixfL4/HoueeeG3B8TqdTS5cu1cGDB+V2u/Xoo4+qpqZmEM4cADDcMAsiAGBEczgcqq2t1fTp0+MdCgAAvAMGAAAAALFCAwYAAAAAMcI7YACAEY0n7QEAQwl3wAAAAAAgRmjAAAAAACBGaMAAAAAAIEZowAAAAAAgRmjAAAAAACBGaMAAAAAAIEZowAAAAAAgRmjAAAAAACBG/gf17/SJ9J3ydwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probability_model = tf.keras.Sequential([model,\n",
        "                                         tf.keras.layers.Softmax()])"
      ],
      "metadata": {
        "id": "VzOdKAT_uV-f"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = probability_model.predict(x_test)"
      ],
      "metadata": {
        "id": "f4is3NFruYom",
        "outputId": "ba23e6ec-514d-4502-d294-5584a424b625",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0]"
      ],
      "metadata": {
        "id": "82cigvlZudz_",
        "outputId": "83ee205d-a5fe-420c-ffcd-3d4d7e05f23d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.08533976, 0.08533976, 0.08533976, 0.08533977, 0.08533976,\n",
              "       0.08534399, 0.08533976, 0.08535617, 0.08533976, 0.2319215 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "6RsQPHyYuNGe",
        "outputId": "d0c3ae47-fc07-46a7-a12a-1f17dbc54fda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273802 (1.04 MB)\n",
            "Trainable params: 272010 (1.04 MB)\n",
            "Non-trainable params: 1792 (7.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}